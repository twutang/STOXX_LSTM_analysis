\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.\nobreakspace  {}Introduction}{4}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}\hskip -1em.\nobreakspace  {}Project Motivation}{4}{subsection.1.1}}
\newlabel{Project Motivation}{{1.1}{4}{\hskip -1em.~Project Motivation}{subsection.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}\hskip -1em.\nobreakspace  {}Problem Definition}{4}{subsection.1.2}}
\newlabel{Problem Definition}{{1.2}{4}{\hskip -1em.~Problem Definition}{subsection.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Intended Deliverables}{4}{subsubsection.1.2.1}}
\newlabel{Intended Deliverables}{{1.2.1}{4}{Intended Deliverables}{subsubsection.1.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}\hskip -1em.\nobreakspace  {}Importance in Industry}{4}{subsection.1.3}}
\citation{jupyter_notebook}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}\hskip -1em.\nobreakspace  {}Software Usage}{5}{subsection.1.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}\hskip -1em.\nobreakspace  {}Report Structure}{5}{subsection.1.5}}
\newlabel{Report Structure}{{1.5}{5}{\hskip -1em.~Report Structure}{subsection.1.5}{}}
\citation{Rouwenhorst}
\citation{Graham}
\citation{Treynor}
\citation{Ross}
\citation{Fama}
\citation{Eun}
\citation{Merz}
\citation{Rumelhart}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.\nobreakspace  {}Background}{6}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}\hskip -1em.\nobreakspace  {}History of Investing Methodologies}{6}{subsection.2.1}}
\newlabel{History of Investing Methodologies}{{2.1}{6}{\hskip -1em.~History of Investing Methodologies}{subsection.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}\hskip -1em.\nobreakspace  {}Long Short-Term Memory Networks}{7}{subsection.2.2}}
\newlabel{lstm}{{2.2}{7}{\hskip -1em.~Long Short-Term Memory Networks}{subsection.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Overview}{7}{subsubsection.2.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A classical MLP (LHS) simply generates an output with respect to its input whereas in the RNN (RHS), the output is governed by the input and previous input.\relax }}{7}{figure.caption.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Numerous varying topologies for specific sequential data tasks.\relax }}{7}{figure.caption.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}The Exploding and Vanishing Gradient Problem in RNNs}{7}{subsubsection.2.2.2}}
\citation{Hockreiter}
\citation{Olah}
\citation{Olah}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Breakdown of a LSTM cell depicting the input, forget and update gates.\relax }}{8}{figure.caption.10}}
\citation{Pascanu}
\citation{Reimers}
\citation{Janocha}
\citation{Bergmeir}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Loss Functions}{9}{subsubsection.2.2.3}}
\newlabel{loss functions}{{2.2.3}{9}{Loss Functions}{subsubsection.2.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Graph showing the binary cross entropy loss function given the probability of a correct prediction\relax }}{9}{figure.caption.11}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}Cross Validation}{9}{subsubsection.2.2.4}}
\newlabel{cross validation}{{2.2.4}{9}{Cross Validation}{subsubsection.2.2.4}{}}
\citation{Racine}
\citation{Gregor}
\citation{Man_Group}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.5}Applications}{10}{subsubsection.2.2.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces LHS: DRAW network from Google Deepmind, featuring an attention mechanism formed by an encoding and decoding RNN (with the LSTM architecture). RHS: Simulation of how each iteration improves on the previous when using the network.\relax }}{10}{figure.caption.12}}
\citation{Ahmadi}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces LHS: Single digits generated from the MNIST database, with the right-most column depicting original images from the database. RHS: DRAW's attempts at generating double digit values.\relax }}{11}{figure.caption.13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}\hskip -1em.\nobreakspace  {}Review of Machine Learning Research in Investing}{11}{subsection.2.3}}
\newlabel{ML_research}{{2.3}{11}{\hskip -1em.~Review of Machine Learning Research in Investing}{subsection.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Overview}{11}{subsubsection.2.3.1}}
\citation{Kim}
\citation{Alberg}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Initial Usage}{12}{subsubsection.2.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Formalisation of Experimentation}{12}{subsubsection.2.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Kim's results of SVM compared to BP and CBR.\relax }}{12}{figure.caption.16}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.4}Methodologies}{12}{subsubsection.2.3.4}}
\newlabel{Alberg}{{2.3.4}{12}{Methodologies}{subsubsection.2.3.4}{}}
\citation{Makridakis}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces (LHS) The overview of how the model functions. (RHS) Backtesting results from Alberg with various factor models between 2000-2016. Clairvoyance x-axis equates to the time period difference between the current and future time in the model. \relax }}{13}{figure.caption.17}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.5}Related Works}{13}{subsubsection.2.3.5}}
\citation{Smyl}
\citation{Winters}
\citation{Henrique}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces LHS: Different architectures that Smyl used with respect to time horizon of data. RHS: General structure of 3 layered dilated RNN.\relax }}{14}{figure.caption.18}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{chang_architecture}{{9}{14}{LHS: Different architectures that Smyl used with respect to time horizon of data. RHS: General structure of 3 layered dilated RNN.\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.6}Summary}{14}{subsubsection.2.3.6}}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.\nobreakspace  {}Requirements Capture}{16}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\hskip -1em.\nobreakspace  {}Tasks}{16}{subsection.3.1}}
\newlabel{tasks}{{3.1}{16}{\hskip -1em.~Tasks}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.\nobreakspace  {}Design and Analysis}{17}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}\hskip -1em.\nobreakspace  {}Overview}{17}{subsection.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces High-level overview of the tool pipeline design\relax }}{17}{figure.caption.19}}
\newlabel{pipeline_design}{{10}{17}{High-level overview of the tool pipeline design\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Overview of the processes involved in iterative designing and testing of models for the problem\relax }}{17}{figure.caption.20}}
\newlabel{pipeline_design}{{11}{17}{Overview of the processes involved in iterative designing and testing of models for the problem\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}\hskip -1em.\nobreakspace  {}Data Structuring}{17}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Data Description}{17}{subsubsection.4.2.1}}
\newlabel{data_description}{{4.2.1}{17}{Data Description}{subsubsection.4.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Diagram overview of the database hierarchy.\relax }}{18}{figure.caption.21}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Data Formatting}{18}{subsubsection.4.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}\hskip -1em.\nobreakspace  {}Data Preprocessing}{18}{subsection.4.3}}
\newlabel{data preprocess}{{4.3}{18}{\hskip -1em.~Data Preprocessing}{subsection.4.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Data Transformation}{18}{subsubsection.4.3.1}}
\newlabel{data transformation}{{4.3.1}{18}{Data Transformation}{subsubsection.4.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Histogram plots of returns (LHS) and log returns (RHS) distributions.\relax }}{19}{figure.caption.22}}
\newlabel{returns}{{13}{19}{Histogram plots of returns (LHS) and log returns (RHS) distributions.\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Sparsity}{19}{subsubsection.4.3.2}}
\newlabel{data_analysis}{{4.3.2}{19}{Sparsity}{subsubsection.4.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Box plot indicating the approximate average underlying count numbers for each type of input. Green triangles indicate the mean counts.\relax }}{19}{figure.caption.23}}
\newlabel{input_counts}{{14}{19}{Box plot indicating the approximate average underlying count numbers for each type of input. Green triangles indicate the mean counts.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces LHS: Individual ticker breakdown of datapoint counts. RHS: Boxplot of returns output count.\relax }}{20}{figure.caption.24}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Box plot indicating the approximate average underlying delta counts for each type of input. Green triangles indicate the mean counts. As seen, LTM is particularly lower than the others.\relax }}{20}{figure.caption.25}}
\newlabel{input_delta_counts}{{16}{20}{Box plot indicating the approximate average underlying delta counts for each type of input. Green triangles indicate the mean counts. As seen, LTM is particularly lower than the others.\relax }{figure.caption.25}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Percentages of used and complete input vectors with respect to the entire dataset.\relax }}{20}{table.caption.27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}\hskip -1em.\nobreakspace  {}Architectural Design}{20}{subsection.4.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}Overview}{20}{subsubsection.4.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Heatmaps of nan values (depicted in white) of a few datasets.\relax }}{21}{figure.caption.26}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}Inputs and Outputs}{21}{subsubsection.4.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.3}Loss Function}{22}{subsubsection.4.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.4}Design Iterations}{22}{subsubsection.4.4.4}}
\newlabel{design iterations}{{4.4.4}{22}{Design Iterations}{subsubsection.4.4.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces LHS: Architectural overview of the initial one hidden layer model. RHS: Model summary with number of parameters.\relax }}{22}{figure.caption.28}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces LHS: Architectural overview of the stacked LSTM model. RHS: Model summary with number of parameters.\relax }}{23}{figure.caption.29}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Demonstration of errors introduced into output function of LSTM by missing values.\relax }}{23}{figure.caption.30}}
\citation{Ruder}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Overview of the architecture of the multi output model.\relax }}{24}{figure.caption.31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}\hskip -1em.\nobreakspace  {}Training and Testing}{24}{subsection.4.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}\hskip -1em.\nobreakspace  {}Hyperparameter Optimisation}{24}{subsection.4.6}}
\newlabel{hyperparameters}{{4.6}{24}{\hskip -1em.~Hyperparameter Optimisation}{subsection.4.6}{}}
\citation{Adam}
\citation{brownlee_activation}
\citation{Gal}
\citation{Sak}
\citation{Hagan}
\citation{DeMiguel}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Screenshot indicating an issue with no decreasing loss function during training due to an incorrectly selected activation function.\relax }}{25}{figure.caption.32}}
\citation{Sharpe}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}\hskip -1em.\nobreakspace  {}Benchmark Design}{26}{subsection.4.7}}
\newlabel{benchmark}{{4.7}{26}{\hskip -1em.~Benchmark Design}{subsection.4.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}\hskip -1em.\nobreakspace  {}Implementation}{27}{section.5}}
\newlabel{implementation}{{5}{27}{\hskip -1em.~Implementation}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}\hskip -1em.\nobreakspace  {}Data Structuring}{27}{subsection.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Program flow diagram of data structuring processes.\relax }}{27}{figure.caption.33}}
\newlabel{data_structuring}{{23}{27}{Program flow diagram of data structuring processes.\relax }{figure.caption.33}{}}
\newlabel{file_mount}{{1}{27}{Importing csv file to dataframe}{lstlisting.1}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}Importing csv file to dataframe.}{27}{lstlisting.1}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2}Formation of lists of dataframes according to type of input.}{27}{lstlisting.2}}
\newlabel{datetime_index}{{3}{27}{Function to create datetime index for dataframes}{lstlisting.3}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {3}Function to create datetime index for dataframes.}{27}{lstlisting.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}\hskip -1em.\nobreakspace  {}Data Preprocessing}{28}{subsection.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Program flow diagram of data preprocessing processes.\relax }}{28}{figure.caption.34}}
\newlabel{data_preprocessing}{{24}{28}{Program flow diagram of data preprocessing processes.\relax }{figure.caption.34}{}}
\newlabel{datachange}{{4}{28}{Identifying the available datapoint counts in differences of $x_{t}$ and $x_{t-1}$}{lstlisting.4}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4}Identifying the available datapoint counts in differences of $x_{t}$ and $x_{t-1}$.}{28}{lstlisting.4}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5}Functionality to split original entire dataset into allocated training split size.}{29}{lstlisting.5}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {6}Functionality to scale the input attributes between 0 and 1.}{29}{lstlisting.6}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {7}Function to convert the raw output target to a binary label.}{30}{lstlisting.7}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {8}Formation of the input vectors for the model.}{30}{lstlisting.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Diagram of reshaped input structure for Keras.\relax }}{31}{figure.caption.35}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {9}Reshaping the input \textit  {numpy} arrays to the correct format.}{32}{lstlisting.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}\hskip -1em.\nobreakspace  {}Architecture}{32}{subsection.5.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Single Output Model}{32}{subsubsection.5.3.1}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {10}Model creation, compilation and fitting functionality of the single output model. The initial single hidden layer model is commented out.}{32}{lstlisting.10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}Multi output Model}{33}{subsubsection.5.3.2}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {11}Structuring of the multi output model, with two forks focused on the separate tasks of predicting the target variable, $y$ and the next input vector, $x_{t+1}$.}{33}{lstlisting.11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}\hskip -1em.\nobreakspace  {}Evaluation Metrics}{34}{subsection.5.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Program flow diagram of evaluation processes.\relax }}{34}{figure.caption.36}}
\newlabel{evaluationflow}{{26}{34}{Program flow diagram of evaluation processes.\relax }{figure.caption.36}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {12}Keras predict functions to generate predicted labels from test data.}{35}{lstlisting.12}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Confusion matrix for labelling prediction results.\relax }}{35}{figure.caption.37}}
\newlabel{confusion_matrix}{{27}{35}{Confusion matrix for labelling prediction results.\relax }{figure.caption.37}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {13}Implemented function which evaluates the model prediction performance based on accuracy\tmspace  +\thinmuskip {.1667em} precision and recall.}{35}{lstlisting.13}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {14}Filtering out positively labelled predictions to extract related actual return.}{36}{lstlisting.14}}
\citation{python_testing}
\@writefile{toc}{\contentsline {section}{\numberline {6}\hskip -1em.\nobreakspace  {}Testing}{37}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}\hskip -1em.\nobreakspace  {}Test Plan}{37}{subsection.6.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Levels of software testing from high (Top) to low (Bottom)\relax }}{37}{figure.caption.38}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {15}Example Test.}{37}{lstlisting.15}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces Flow diagram of how an integrated test may be executed.\relax }}{37}{figure.caption.39}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}\hskip -1em.\nobreakspace  {}Test Results}{38}{subsection.6.2}}
\@writefile{toc}{\contentsline {section}{\numberline {7}\hskip -1em.\nobreakspace  {}Results}{39}{section.7}}
\newlabel{results}{{7}{39}{\hskip -1em.~Results}{section.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Evaluation metrics of the model performed on hold out test data.\relax }}{39}{table.caption.40}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Statistical summary of percentage changes i.e. returns of sets of data.\relax }}{39}{table.caption.41}}
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Histogram of the returns and log returns of the selected labels by the model.\relax }}{39}{figure.caption.42}}
\@writefile{toc}{\contentsline {section}{\numberline {8}\hskip -1em.\nobreakspace  {}Conclusions}{40}{section.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}\hskip -1em.\nobreakspace  {}Evaluation}{40}{subsection.8.1}}
\newlabel{evaluation}{{8.1}{40}{\hskip -1em.~Evaluation}{subsection.8.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Feature selection and forecast models by Uber.\relax }}{40}{figure.caption.43}}
\newlabel{data_structuring}{{31}{40}{Feature selection and forecast models by Uber.\relax }{figure.caption.43}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}\hskip -1em.\nobreakspace  {}Objective Completion}{40}{subsection.8.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}\hskip -1em.\nobreakspace  {}Future Work}{41}{subsection.8.3}}
\bibstyle{ieee}
\bibdata{thw116bib}
\bibcite{jupyter_notebook}{1}
\bibcite{Ahmadi}{2}
\bibcite{Alberg}{3}
\bibcite{Bergmeir}{4}
\bibcite{brownlee_activation}{5}
\bibcite{DeMiguel}{6}
\bibcite{Eun}{7}
\bibcite{Fama}{8}
\bibcite{Gal}{9}
\bibcite{Graham}{10}
\bibcite{Gregor}{11}
\bibcite{Hagan}{12}
\bibcite{Henrique}{13}
\bibcite{Hockreiter}{14}
\bibcite{Kim}{15}
\bibcite{Janocha}{16}
\bibcite{Adam}{17}
\bibcite{Makridakis}{18}
\bibcite{Merz}{19}
\bibcite{Olah}{20}
\bibcite{Pascanu}{21}
\bibcite{Racine}{22}
\bibcite{Reimers}{23}
\bibcite{Man_Group}{24}
\bibcite{Ross}{25}
\bibcite{Rouwenhorst}{26}
\bibcite{Ruder}{27}
\bibcite{Rumelhart}{28}
\bibcite{Sak}{29}
\bibcite{Sharpe}{30}
\bibcite{python_testing}{31}
\bibcite{Smyl}{32}
\bibcite{Treynor}{33}
\bibcite{Winters}{34}
\@writefile{toc}{\contentsline {section}{\numberline {9}\hskip -1em.\nobreakspace  {}Bibliography}{42}{section.9}}
\@writefile{toc}{\contentsline {section}{\numberline {10}\hskip -1em.\nobreakspace  {}Appendix}{43}{section.10}}
\newlabel{libraries}{{10}{43}{}{lstlisting.-2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}\hskip -1em.\nobreakspace  {}Source Code}{43}{subsection.10.1}}
