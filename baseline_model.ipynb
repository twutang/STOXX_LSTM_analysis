{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIU13nThWPq4",
        "colab_type": "code",
        "outputId": "7cfc98e3-ac96-4721-cffd-9e702365cd08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout, Masking\n",
        "\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oerk0UaY0wG",
        "colab_type": "text"
      },
      "source": [
        "# Initial Data Importation and Structuring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-vX5NnVkai6",
        "colab_type": "text"
      },
      "source": [
        "## Accessing and loading data from Google Drive \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtzJiK3GZxwf",
        "colab_type": "code",
        "outputId": "d0356ba1-87e1-4b0d-a7b6-b58036e4d912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "# mounting Google Drive which contains the relevant data\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKuXkHkNWbSS",
        "colab_type": "code",
        "outputId": "0f764e26-1e24-45db-cbba-c6641166ee44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        }
      },
      "source": [
        "# Fundamental input data\n",
        "ltm_book = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ltm_book.csv')\n",
        "ltm_div = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ltm_div.csv')\n",
        "ltm_ebit = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ltm_ebit.csv')\n",
        "ltm_ebitda = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ltm_ebitda.csv')\n",
        "ltm_eps = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ltm_eps.csv')\n",
        "ltm_fcf = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ltm_fcf.csv')\n",
        "ltm_pbook = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ltm_pbook.csv')\n",
        "ltm_sales = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ltm_sales.csv')\n",
        "\n",
        "ntm_book = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ntm_book.csv')\n",
        "ntm_div = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ntm_div.csv')\n",
        "ntm_ebit = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ntm_ebit.csv')\n",
        "ntm_ebitda = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ntm_ebitda.csv')\n",
        "ntm_eps = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ntm_eps.csv')\n",
        "ntm_fcf = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ntm_fcf.csv')\n",
        "ntm_pbook = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ntm_pbook.csv')\n",
        "ntm_sales = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ntm_sales.csv')\n",
        "\n",
        "# Technical input data\n",
        "\n",
        "price_high = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/price_high.csv')\n",
        "price_low = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/price_low.csv')\n",
        "price_open = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/price_open.csv')\n",
        "volume = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/volume.csv')\n",
        "enterprise_val = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/enterprise_val.csv')\n",
        "\n",
        "print(ltm_book.head())\n",
        "print(\"**************************************\")\n",
        "print(ltm_book.info())\n",
        "print(\"**************************************\")\n",
        "print(ntm_book.head())\n",
        "print(\"**************************************\")\n",
        "print(ntm_book.info())\n",
        "\n",
        "\n",
        "# Price target output data\n",
        "\n",
        "price_close = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/price_close.csv')\n",
        "\n",
        "print(price_close.head())\n",
        "print(\"**************************************\")\n",
        "print(price_close.info())\n",
        "\n",
        "\n",
        "\n",
        "# Test data\n",
        "\n",
        "# test_data = pd.read_csv(\"/content/drive/My Drive/thw116_FYP/data/test_price.csv\")\n",
        "\n",
        "# print(test_data.head())\n",
        "# print(\"**************************************\")\n",
        "# print(test_data.info())\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Unnamed: 0  ATRS AV  ESSR LN  ...  FABGB SS  926002Q GY  NDA SS\n",
            "0           1      NaN      NaN  ...       NaN         NaN     NaN\n",
            "1           2      NaN      NaN  ...       NaN         NaN     NaN\n",
            "2           3      NaN      NaN  ...       NaN         NaN     NaN\n",
            "3           4      NaN      NaN  ...       NaN         NaN     NaN\n",
            "4           5      NaN      NaN  ...       NaN         NaN     NaN\n",
            "\n",
            "[5 rows x 1185 columns]\n",
            "**************************************\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6313 entries, 0 to 6312\n",
            "Columns: 1185 entries, Unnamed: 0 to NDA SS\n",
            "dtypes: float64(1184), int64(1)\n",
            "memory usage: 57.1 MB\n",
            "None\n",
            "**************************************\n",
            "   Unnamed: 0  ATRS AV  ESSR LN  ...  FABGB SS  926002Q GY  NDA SS\n",
            "0           1      NaN      NaN  ...       NaN         NaN     NaN\n",
            "1           2      NaN      NaN  ...       NaN         NaN     NaN\n",
            "2           3      NaN      NaN  ...       NaN         NaN     NaN\n",
            "3           4      NaN      NaN  ...       NaN         NaN     NaN\n",
            "4           5      NaN      NaN  ...       NaN         NaN     NaN\n",
            "\n",
            "[5 rows x 1185 columns]\n",
            "**************************************\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6313 entries, 0 to 6312\n",
            "Columns: 1185 entries, Unnamed: 0 to NDA SS\n",
            "dtypes: float64(1184), int64(1)\n",
            "memory usage: 57.1 MB\n",
            "None\n",
            "   Unnamed: 0  PAYS LN  CNHI IM     SGSN SW  ...  AMS SM  FER SM  SEV FP    FKI LN\n",
            "0  1995-01-03      NaN      NaN  222.552843  ...     NaN     NaN     NaN  1.896782\n",
            "1  1995-01-04      NaN      NaN  226.835424  ...     NaN     NaN     NaN  1.883390\n",
            "2  1995-01-05      NaN      NaN  228.312320  ...     NaN     NaN     NaN  1.910292\n",
            "3  1995-01-06      NaN      NaN  228.015450  ...     NaN     NaN     NaN  1.923861\n",
            "4  1995-01-09      NaN      NaN  228.680128  ...     NaN     NaN     NaN  1.925099\n",
            "\n",
            "[5 rows x 204 columns]\n",
            "**************************************\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6313 entries, 0 to 6312\n",
            "Columns: 204 entries, Unnamed: 0 to FKI LN\n",
            "dtypes: float64(203), object(1)\n",
            "memory usage: 9.8+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwQDmx99oPzr",
        "colab_type": "code",
        "outputId": "f1277e35-4759-4dca-fc73-497906eb67f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        }
      },
      "source": [
        "# Filtering incorrect datasets to suitable company subsets\n",
        "industrials_subset = price_close.columns.values.tolist()\n",
        "\n",
        "ltm_inputs = [ltm_book, ltm_div, ltm_ebit, ltm_ebitda, ltm_ebitda, ltm_eps, ltm_fcf, ltm_pbook, ltm_sales] \n",
        "ntm_inputs = [ntm_book, ntm_div, ntm_ebit, ntm_ebitda, ntm_ebitda, ntm_eps, ntm_fcf, ntm_pbook, ntm_sales]\n",
        "tech_inputs = [price_high, price_low, price_open, volume, enterprise_val]\n",
        "\n",
        "for i in range(0,len(ltm_inputs)):\n",
        "  ltm_inputs[i] = ltm_inputs[i].loc[:, ltm_inputs[i].columns.str.contains('|'.join(industrials_subset))]\n",
        "  ltm_inputs[i]['Unnamed: 0'] = price_close['Unnamed: 0']\n",
        "  ltm_inputs[i].rename( columns={'Unnamed: 0':'Date'}, inplace=True )\n",
        "\n",
        "for i in range(0,len(ntm_inputs)):\n",
        "  ntm_inputs[i] = ntm_inputs[i].loc[:, ntm_inputs[i].columns.str.contains('|'.join(industrials_subset))]\n",
        "  ntm_inputs[i]['Unnamed: 0'] = price_close['Unnamed: 0']\n",
        "  ntm_inputs[i].rename( columns={'Unnamed: 0':'Date'}, inplace=True )\n",
        "\n",
        "for i in range(0,len(tech_inputs)):\n",
        "  tech_inputs[i] = tech_inputs[i].loc[:, tech_inputs[i].columns.str.contains('|'.join(industrials_subset))]\n",
        "  tech_inputs[i]['Unnamed: 0'] = price_close['Unnamed: 0']\n",
        "  tech_inputs[i].rename( columns={'Unnamed: 0':'Date'}, inplace=True )\n",
        "\n",
        "  \n",
        "price_close.rename( columns={'Unnamed: 0':'Date'}, inplace=True )\n",
        "\n",
        "\n",
        "  \n",
        "print((ltm_inputs[1].head()))\n",
        "  \n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "         Date  PAYS LN  CNHI IM  SGSN SW  ...  AMS SM  FER SM  SEV FP  FKI LN\n",
            "0  1995-01-03      NaN      NaN      NaN  ...     NaN     NaN     NaN     NaN\n",
            "1  1995-01-04      NaN      NaN      NaN  ...     NaN     NaN     NaN     NaN\n",
            "2  1995-01-05      NaN      NaN      NaN  ...     NaN     NaN     NaN     NaN\n",
            "3  1995-01-06      NaN      NaN      NaN  ...     NaN     NaN     NaN     NaN\n",
            "4  1995-01-09      NaN      NaN      NaN  ...     NaN     NaN     NaN     NaN\n",
            "\n",
            "[5 rows x 204 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhYPF4OmJOwm",
        "colab_type": "text"
      },
      "source": [
        "## Data Wrangling\n",
        "\n",
        "In order to produce a dataframe suitable for the model, we must first take the raw *Price.csv*  file and convert it to returns. This can then be maniuplated further in a variety of ways to achieve the neccessary classification for variants of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcygJ5YtWP8H",
        "colab_type": "code",
        "outputId": "54772df0-1362-4f4a-bf0e-86b135220fb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        }
      },
      "source": [
        "# Conversion of TimeAndDate column to DatetimeIndex for ease of use\n",
        "\n",
        "def time_index_generator(dataframe):\n",
        "  dataframe['Date'] = pd.to_datetime(dataframe['Date'], dayfirst=True)\n",
        "  dataframe.set_index('Date', inplace=True)\n",
        "\n",
        "\n",
        "for i in range(0,len(ltm_inputs)):\n",
        "  time_index_generator(ltm_inputs[i])\n",
        "for i in range(0,len(ntm_inputs)):\n",
        "  time_index_generator(ntm_inputs[i])\n",
        "for i in range(0,len(tech_inputs)):\n",
        "  time_index_generator(tech_inputs[i])  \n",
        "\n",
        "time_index_generator(price_close)\n",
        "  \n",
        "print(ltm_inputs[0].head())\n",
        "print(ntm_inputs[0].head())\n",
        "print(tech_inputs[0].head())\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "            PAYS LN  CNHI IM  SGSN SW  PAGE LN  ...  AMS SM  FER SM  SEV FP  FKI LN\n",
            "Date                                            ...                                \n",
            "1995-01-03      NaN      NaN      NaN      NaN  ...     NaN     NaN     NaN     NaN\n",
            "1995-01-04      NaN      NaN      NaN      NaN  ...     NaN     NaN     NaN     NaN\n",
            "1995-01-05      NaN      NaN      NaN      NaN  ...     NaN     NaN     NaN     NaN\n",
            "1995-01-06      NaN      NaN      NaN      NaN  ...     NaN     NaN     NaN     NaN\n",
            "1995-01-09      NaN      NaN      NaN      NaN  ...     NaN     NaN     NaN     NaN\n",
            "\n",
            "[5 rows x 203 columns]\n",
            "            PAYS LN  CNHI IM  SGSN SW  PAGE LN  ...  AMS SM  FER SM  SEV FP  FKI LN\n",
            "Date                                            ...                                \n",
            "1995-01-03      NaN      NaN      NaN      NaN  ...     NaN     NaN     NaN     NaN\n",
            "1995-01-04      NaN      NaN      NaN      NaN  ...     NaN     NaN     NaN     NaN\n",
            "1995-01-05      NaN      NaN      NaN      NaN  ...     NaN     NaN     NaN     NaN\n",
            "1995-01-06      NaN      NaN      NaN      NaN  ...     NaN     NaN     NaN     NaN\n",
            "1995-01-09      NaN      NaN      NaN      NaN  ...     NaN     NaN     NaN     NaN\n",
            "\n",
            "[5 rows x 203 columns]\n",
            "            PAYS LN  CNHI IM     SGSN SW  ...  FER SM  SEV FP    FKI LN\n",
            "Date                                      ...                          \n",
            "1995-01-03      NaN      NaN  222.552843  ...     NaN     NaN  1.916080\n",
            "1995-01-04      NaN      NaN  232.668335  ...     NaN     NaN  1.909070\n",
            "1995-01-05      NaN      NaN  228.312320  ...     NaN     NaN  1.923206\n",
            "1995-01-06      NaN      NaN  228.015450  ...     NaN     NaN  1.936693\n",
            "1995-01-09      NaN      NaN  228.680128  ...     NaN     NaN  1.937940\n",
            "\n",
            "[5 rows x 203 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5fWXKHjLpzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check all columns align correctly\n",
        "print(ltm_inputs[0].columns.difference(price_close.columns))\n",
        "print(ltm_inputs[1].columns.difference(price_close.columns))\n",
        "print(ltm_inputs[2].columns.difference(price_close.columns))\n",
        "print(ltm_inputs[3].columns.difference(price_close.columns))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCGMHTY0zA7O",
        "colab_type": "code",
        "outputId": "4c1af400-8090-4fa5-c194-033aff154bea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "# Anonoymise Tickers \n",
        "\n",
        "# Check that all tickers in the set match\n",
        "\n",
        "# Helper function to generate ticker list\n",
        "def ticker_list_generator(num):\n",
        "  ticker_list = []\n",
        "  for i in range(0, num):\n",
        "    ticker_name = 'Ticker ' + str(i+1)\n",
        "    ticker_list.append(ticker_name)\n",
        "  return ticker_list\n",
        "\n",
        "anon_tickers = ticker_list_generator(len(ltm_inputs[0].columns))\n",
        "\n",
        "for i in range(0,len(ltm_inputs)):\n",
        "  ltm_inputs[0].columns = anon_tickers\n",
        "for i in range(0,len(ntm_inputs)):\n",
        "  ntm_inputs[0].columns = anon_tickers\n",
        "for i in range(0,len(tech_inputs)):\n",
        "  tech_inputs[0].columns = anon_tickers\n",
        "\n",
        "price_close.columns = anon_tickers\n",
        "\n",
        "print(ltm_inputs[0].head())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Ticker 1  Ticker 2  Ticker 3  ...  Ticker 201  Ticker 202  Ticker 203\n",
            "Date                                      ...                                    \n",
            "1995-01-03       NaN       NaN       NaN  ...         NaN         NaN         NaN\n",
            "1995-01-04       NaN       NaN       NaN  ...         NaN         NaN         NaN\n",
            "1995-01-05       NaN       NaN       NaN  ...         NaN         NaN         NaN\n",
            "1995-01-06       NaN       NaN       NaN  ...         NaN         NaN         NaN\n",
            "1995-01-09       NaN       NaN       NaN  ...         NaN         NaN         NaN\n",
            "\n",
            "[5 rows x 203 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3b3tTGWYXjuQ",
        "colab": {}
      },
      "source": [
        "# Selecting a Ticker and plotting\n",
        "\n",
        "# test_data['Ticker 1'].plot(figsize=(16,6))\n",
        "# plt.title('Test Results - Ticker 1')\n",
        "# plt.xlabel('Date')\n",
        "# plt.ylabel('Attribute')\n",
        "\n",
        "# test_data.plot(figsize=(16,6))\n",
        "\n",
        "\n",
        "\n",
        "ltm_inputs[0]['Ticker 1'].plot(figsize=(16,6))\n",
        "plt.title('ltm_book - Ticker 1')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Attribute')\n",
        "\n",
        "ltm_inputs[0]['Ticker 2'].plot(figsize=(16,6))\n",
        "plt.title('ltm_book - Ticker 1')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Attribute')\n",
        "\n",
        "ltm_inputs[0]['Ticker 3'].plot(figsize=(16,6))\n",
        "plt.title('ltm_book - Ticker 1')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Attribute')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gep9h1FNHQJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting Price format to returns format\n",
        "def price_to_returns(timeframe, dataframe):\n",
        "  if timeframe == 'daily':\n",
        "    return dataframe.pct_change(1) # remember to discount all target variables that are NaN\n",
        "  \n",
        "  if timeframe == 'monthly':\n",
        "    return dataframe.resample('BM')\n",
        "  \n",
        "returns = price_to_returns('daily', price_close) \n",
        "\n",
        "# returns_data = price_to_returns(price_data) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guJycK9f5Z1E",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "Several steps are taken in order to structure the data so that it can be proccessed by the model.\n",
        "\n",
        "1.   Data Analysis and Cleaning: Data is analysed for missing values, its properties, smoothed for various time intervals and resolved of any inconsistencies.  \n",
        "\n",
        "2. Training-Test Split: Data is divided into training and test splits according to a selected parameter value. \n",
        "\n",
        "3.  Data Transformation: Data is normalised, aggregated and generalised, both for training and testing\n",
        "\n",
        "4. Data Integration: Data is merged together appropriately to form the input shape of the model.   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfuTGvzQKPue",
        "colab_type": "text"
      },
      "source": [
        "##Data Analysis and Cleaning\n",
        "\n",
        "Something to consider is the fact that returns are more likely to correlate with changes in fundamentals rather than the absolute values of fundamentals. However, there is likely to be a disceprancy in the rate of change of fundamentals and the change in prices. Fundamentals are often only declared quarterly whereas prices are subject to daily fluctuations. We will first analyse the number of times a fundamental changes relative to the price changes. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO_BJonjhHVL",
        "colab_type": "code",
        "outputId": "a1cea12b-0957-4cc0-9f00-c0c2557a9cff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        }
      },
      "source": [
        "def data_change(dataframe, column): \n",
        "  noChange_count = 0\n",
        "  NaN_count = 0\n",
        "  for i in range (0, len(dataframe.index)): \n",
        "    if dataframe[column].diff().iloc[i] == 0:\n",
        "      noChange_count += 1\n",
        "    if dataframe[column].isna().iloc[i]: \n",
        "      NaN_count += 1\n",
        "  \n",
        "  print('Total rows: ', len(dataframe[column]))\n",
        "  print('The number of rows where no change occurs: ', noChange_count)\n",
        "  print('The number of rows which are NaN: ', NaN_count)\n",
        "  print('Useful datapoints:', (len(dataframe[column])-noChange_count-NaN_count))\n",
        "  \n",
        "  \n",
        "print(data_change(ltm_inputs[0], 'Ticker 1'))\n",
        "print(data_change(ltm_inputs[0], 'Ticker 200'))\n",
        "\n",
        "print(data_change(ntm_inputs[0], 'Ticker 1'))\n",
        "print(data_change(ntm_inputs[0], 'Ticker 200'))\n",
        "\n",
        "print(data_change(tech_inputs[0], 'Ticker 1'))\n",
        "print(data_change(tech_inputs[0], 'Ticker 200'))\n",
        "  \n",
        "  \n",
        "# # Some tickers are missing so need to account for KeyError\n",
        "# for i in tickers:\n",
        "#   try:\n",
        "#     print(i)\n",
        "#     data_change(test_data, i)\n",
        "#   except KeyError:\n",
        "#     continue\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total rows:  6313\n",
            "The number of rows where no change occurs:  2659\n",
            "The number of rows which are NaN:  2992\n",
            "Useful datapoints: 662\n",
            "None\n",
            "Total rows:  6313\n",
            "The number of rows where no change occurs:  1017\n",
            "The number of rows which are NaN:  4755\n",
            "Useful datapoints: 541\n",
            "None\n",
            "Total rows:  6313\n",
            "The number of rows where no change occurs:  1487\n",
            "The number of rows which are NaN:  3200\n",
            "Useful datapoints: 1626\n",
            "None\n",
            "Total rows:  6313\n",
            "The number of rows where no change occurs:  10\n",
            "The number of rows which are NaN:  4785\n",
            "Useful datapoints: 1518\n",
            "None\n",
            "Total rows:  6313\n",
            "The number of rows where no change occurs:  4\n",
            "The number of rows which are NaN:  2767\n",
            "Useful datapoints: 3542\n",
            "None\n",
            "Total rows:  6313\n",
            "The number of rows where no change occurs:  222\n",
            "The number of rows which are NaN:  4716\n",
            "Useful datapoints: 1375\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbrJzj6fJqvv",
        "colab_type": "text"
      },
      "source": [
        "## Training Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yfDmdQJcrPp",
        "colab_type": "code",
        "outputId": "f8097a6c-5114-4ceb-c286-f7106084d830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "def training_set(train_percentage, dataframe): \n",
        "  train_size = int(train_percentage*len(dataframe.index)) \n",
        "  train_set = dataframe[:train_size]\n",
        "  return pd.DataFrame(train_set)  \n",
        "\n",
        "training_split = 0.8\n",
        "\n",
        "# INPUTS\n",
        "\n",
        "print(type(ltm_inputs))\n",
        "\n",
        "ltm_trainInputs = []\n",
        "ntm_trainInputs = []\n",
        "tech_trainInputs = []\n",
        "\n",
        "for i in range(0,len(ltm_inputs)):\n",
        "  ltm_trainInputs.append(training_set(training_split, ltm_inputs[i]))\n",
        "  \n",
        "for i in range(0,len(ntm_inputs)):\n",
        "  ntm_trainInputs.append(training_set(training_split, ntm_inputs[i]))\n",
        "\n",
        "for i in range(0,len(tech_inputs)):\n",
        "  tech_trainInputs.append(training_set(training_split, tech_inputs[i]))\n",
        "\n",
        "  \n",
        "returns_trainOutput = training_set(training_split, returns)\n",
        "\n",
        "\n",
        "print(ntm_trainInputs[0].info())\n",
        "print(returns_trainOutput.info())\n",
        "\n",
        "\n",
        "# # TEST INPUT\n",
        "# test_train_set = training_set(training_split, test_data)\n",
        "# print(\"****************INPUT*****************\")\n",
        "# print (test_train_set.head())\n",
        "# print(\"**************************************\")\n",
        "# print(test_train_set.info())\n",
        "\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 5050 entries, 1995-01-03 to 2014-06-25\n",
            "Columns: 203 entries, Ticker 1 to Ticker 203\n",
            "dtypes: float64(203)\n",
            "memory usage: 7.9 MB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 5050 entries, 1995-01-03 to 2014-06-25\n",
            "Columns: 203 entries, Ticker 1 to Ticker 203\n",
            "dtypes: float64(203)\n",
            "memory usage: 7.9 MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47IfciNTutCX",
        "colab_type": "text"
      },
      "source": [
        "## Validation Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ-QTlDF1hOm",
        "colab_type": "code",
        "outputId": "c3abd960-31ce-46cc-cef3-5ba76769f42d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "source": [
        "def validation_set(train_percentage, dataframe): \n",
        "  train_size = int(train_percentage*len(dataframe.index)) \n",
        "  # val_size = len(dataframe.index)-int(train_percentage*len(dataframe.index)) \n",
        "  val_set = dataframe[train_size:]\n",
        "  return pd.DataFrame(val_set)  \n",
        "\n",
        "\n",
        "ltm_valInputs = []\n",
        "ntm_valInputs = []\n",
        "tech_valInputs = []\n",
        "\n",
        "for i in range(0,len(ltm_inputs)):\n",
        "  ltm_valInputs.append(validation_set(training_split, ltm_inputs[i]))\n",
        "  \n",
        "for i in range(0,len(ntm_inputs)):\n",
        "  ntm_valInputs.append(validation_set(training_split, ntm_inputs[i]))\n",
        "\n",
        "for i in range(0,len(tech_inputs)):\n",
        "  tech_valInputs.append(validation_set(training_split, tech_inputs[i]))\n",
        "\n",
        "  \n",
        "returns_valOutput = validation_set(training_split, returns)\n",
        "\n",
        "print(ltm_valInputs[0].info())\n",
        "print(returns_valOutput.info())\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 1263 entries, 2014-06-26 to 2019-05-17\n",
            "Columns: 203 entries, Ticker 1 to Ticker 203\n",
            "dtypes: float64(203)\n",
            "memory usage: 2.0 MB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 1263 entries, 2014-06-26 to 2019-05-17\n",
            "Columns: 203 entries, Ticker 1 to Ticker 203\n",
            "dtypes: float64(203)\n",
            "memory usage: 2.0 MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U79APBT7JwcE",
        "colab_type": "text"
      },
      "source": [
        "## Input and Output Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38KlbkcIfOk4",
        "colab_type": "code",
        "outputId": "ed214faf-423a-4017-aea1-6743ea238704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "def input_scaling(dataframe):\n",
        "  \n",
        "  # This is the MinMax Scaling function \n",
        "  sc = MinMaxScaler(feature_range = (0, 1))\n",
        "  scaled_input_dataframe = sc.fit_transform(dataframe) # This is now an n-dimensional array type\n",
        "  \n",
        "  return scaled_input_dataframe\n",
        "\n",
        "np.warnings.filterwarnings('ignore', r'All-NaN (slice|axis) encountered')\n",
        "\n",
        "for i in range(0,len(ltm_inputs)):\n",
        "  ltm_trainInputs[i] = input_scaling(ltm_trainInputs[i])\n",
        "  \n",
        "for i in range(0,len(ntm_inputs)):\n",
        "  ntm_trainInputs[i] = input_scaling(ntm_trainInputs[i])\n",
        "\n",
        "for i in range(0,len(tech_inputs)):\n",
        "  tech_trainInputs[i] = input_scaling(tech_trainInputs[i])\n",
        " \n",
        "print(type(ltm_trainInputs[0][1000:1001]))\n",
        "print(len(ltm_trainInputs[0]))\n",
        "print(ltm_trainInputs[0][1000:1001][0][3])\n",
        "print(len(ltm_trainInputs[0][:1][0]))\n",
        "\n",
        "print(ltm_trainInputs[0][1000:1001])\n",
        "\n",
        "sample_input = [ltm_trainInputs[0][1000:1001][0][3],ntm_trainInputs[0][1000:1001][0][3], tech_trainInputs[0][1000:1001][0][3] ]\n",
        "\n",
        "print(sample_input)\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "5050\n",
            "nan\n",
            "203\n",
            "[[       nan        nan 0.                nan        nan        nan\n",
            "         nan        nan        nan        nan 0.                nan\n",
            "         nan        nan        nan        nan        nan        nan\n",
            "         nan        nan        nan        nan        nan        nan\n",
            "         nan 0.16727071        nan        nan        nan        nan\n",
            "         nan        nan        nan        nan 0.48700565        nan\n",
            "         nan        nan        nan 0.06077075        nan        nan\n",
            "         nan        nan 0.                nan        nan        nan\n",
            "         nan        nan        nan        nan 0.1138583  0.1756445\n",
            "         nan        nan 0.                nan        nan        nan\n",
            "         nan        nan        nan        nan        nan        nan\n",
            "         nan 0.03453689        nan        nan        nan        nan\n",
            "         nan        nan        nan        nan        nan        nan\n",
            "         nan        nan        nan 0.06724919 0.02761319 0.19720826\n",
            "         nan 0.02459016        nan        nan        nan        nan\n",
            "         nan 0.         0.12025723        nan        nan        nan\n",
            "         nan        nan        nan        nan        nan        nan\n",
            "  0.         0.49403686        nan        nan        nan        nan\n",
            "         nan        nan        nan        nan        nan        nan\n",
            "         nan        nan        nan        nan        nan        nan\n",
            "         nan        nan        nan        nan        nan        nan\n",
            "         nan        nan        nan        nan 0.62559033        nan\n",
            "         nan        nan        nan        nan        nan        nan\n",
            "         nan 0.                nan 0.                nan        nan\n",
            "         nan        nan        nan        nan        nan        nan\n",
            "         nan        nan        nan        nan        nan 0.16330451\n",
            "  0.                nan        nan        nan        nan        nan\n",
            "         nan        nan        nan        nan        nan 0.\n",
            "         nan        nan        nan 0.04910714        nan        nan\n",
            "         nan        nan        nan        nan 0.0157625  0.00752056\n",
            "  0.07918582        nan        nan        nan        nan        nan\n",
            "         nan        nan        nan        nan        nan        nan\n",
            "  0.                nan        nan        nan        nan        nan\n",
            "         nan        nan        nan        nan        nan]]\n",
            "[nan, nan, nan]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spsYzewNmtEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "median = []\n",
        "median = returns_trainOutput.median(axis=1)\n",
        "\n",
        "# for column in range(0,returns_trainOutput.shape[0]):\n",
        "#   for row in range(0, returns_trainOutput.shape[1]): \n",
        "#     if returns_trainOutput.iloc[column, row] >= median[row]: \n",
        "#       returns_trainOutput.iloc[column, row] = 1\n",
        "#     else:\n",
        "#       returns_trainOutput.iloc[column, row] = 0\n",
        "      \n",
        "      \n",
        "# index, row in returns_trainOutput.iterrows():\n",
        "#     print(index, list(returns_trainOutput.columns[row > median[index]]))\n",
        "apply(lambda x: 'true' if x <= 2.5 else 'false')\n",
        "\n",
        "for ticker in range(0,len(returns_trainOutput)):\n",
        "  if returns_trainOutput[anon_tickers[ticker]] >= median[ticker]\n",
        "    df['my_channel'].mask(df['my_channel'] > 20000, 0, inplace=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6snYzXc-yTv",
        "colab_type": "code",
        "outputId": "a84dc6d1-69e1-4e22-b62e-9d92864badfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "def output_classifier(type ,dataframe): \n",
        "  \n",
        "  # No adjustments\n",
        "  if type == 'raw':\n",
        "    scaled_dataframe = dataframe\n",
        "  \n",
        "  # Binary classifier where return>0 is +1, and return<0 is 0 labels\n",
        "  if type == 'binary baseline':\n",
        "    pos_returns = dataframe.values > 0\n",
        "    neg_returns = dataframe.values <= 0 \n",
        "    scaled_dataframe = pd.DataFrame(np.select([pos_returns,neg_returns], [1,0], default='NaN'), index=dataframe.index, columns=dataframe.columns)\n",
        "\n",
        "  return scaled_dataframe\n",
        "\n",
        "returns_trainOutput = output_classifier('binary baseline', returns_trainOutput)\n",
        "\n",
        "print (returns_trainOutput.head())\n",
        "print (returns_trainOutput.info())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in greater\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in less_equal\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "           Ticker 1 Ticker 2 Ticker 3  ... Ticker 201 Ticker 202 Ticker 203\n",
            "Date                                   ...                                 \n",
            "1995-01-03      NaN      NaN      NaN  ...        NaN        NaN        NaN\n",
            "1995-01-04      NaN      NaN        1  ...        NaN        NaN          0\n",
            "1995-01-05      NaN      NaN        1  ...        NaN        NaN          1\n",
            "1995-01-06      NaN      NaN        0  ...        NaN        NaN          1\n",
            "1995-01-09      NaN      NaN        1  ...        NaN        NaN          1\n",
            "\n",
            "[5 rows x 203 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 5050 entries, 1995-01-03 to 2014-06-25\n",
            "Columns: 203 entries, Ticker 1 to Ticker 203\n",
            "dtypes: object(203)\n",
            "memory usage: 7.9+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeMN7TE0Ki1P",
        "colab_type": "text"
      },
      "source": [
        "## Data Integration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYKnA5iUAnmG",
        "colab_type": "code",
        "outputId": "d01fda5f-4a62-42ad-b6a2-752366e80fc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "trainInput = []\n",
        "trainTarget = []\n",
        "\n",
        "# Check that the indices are of the same length \n",
        "if len(ltm_trainInputs[0]) != len(returns_trainOutput):\n",
        "  assert False, \"Incompatible dataframe index lengths!\"\n",
        "\n",
        "for company in range(0, len(ltm_trainInputs[0][:1][0])):\n",
        "  \n",
        "  for time_unit in range(0, len(ltm_trainInputs[0])): \n",
        "    input_unit = []\n",
        "    \n",
        "    for ltm_attribute in range(0, len(ltm_trainInputs)): \n",
        "      input_unit.append(ltm_trainInputs[ltm_attribute][time_unit:time_unit+1][0][company])\n",
        "                        \n",
        "    for ntm_attribute in range(0, len(ntm_trainInputs)):\n",
        "      input_unit.append(ntm_trainInputs[ntm_attribute][time_unit:time_unit+1][0][company])\n",
        "                        \n",
        "    for tech_attribute in range(0, len(tech_trainInputs)): \n",
        "      input_unit.append(tech_trainInputs[tech_attribute][time_unit:time_unit+1][0][company])\n",
        "                        \n",
        "    trainInput.append(input_unit)\n",
        "    \n",
        "for company in range(0, len(returns_trainOutput.columns)):\n",
        "  for time_unit in range(0, len(returns_trainOutput.index)): \n",
        "    trainTarget.append(returns_trainOutput[anon_tickers[company]][time_unit])\n",
        "  \n",
        "\n",
        "# for i in range(0, len(scaled_returns_train_set.index)): # this is the ratio of input data to output data. \n",
        "#     X_train.append(scaled_test_train_set[i-6:i, 0]) # second parameter is the axis - in this case, only 1 dimension\n",
        "#     Y_train.append(scaled_returns_train_set[i, 0])\n",
        "\n",
        "# print(type(input_trainDataset))\n",
        "# print(\"**************************************\")\n",
        "# print(input_trainDataset[0:5])\n",
        "\n",
        "\n",
        "# # Conversion to numpy array for improved memory, performance and functionality\n",
        "# input_trainDataset, output_trainDataset = np.array(input_trainDataset), np.array(output_trainDataset)\n",
        "# print(type(input_trainDataset))\n",
        "# print(\"**************************************\")\n",
        "\n",
        "# print(input_trainDataset[0:5])\n",
        "\n",
        "# print(input_trainDataset.shape[0])\n",
        "# print(input_trainDataset.shape[1])\n",
        "# print(\"**************************************\")\n",
        "\n",
        "\n",
        "print(trainInput[0:1])\n",
        "print(len(trainInput))\n",
        "print(trainTarget[0:1])\n",
        "print(len(trainTarget))\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]\n",
            "1025150\n",
            "['NaN']\n",
            "1025150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uL1FAaxCxMm",
        "colab_type": "text"
      },
      "source": [
        "### Remove redundant data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4J19cJ1_k_8",
        "colab_type": "code",
        "outputId": "9dbf87b1-a7f6-43e9-ec6c-153a052f76c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "def remove_useless_inputs(inputList, outputList):\n",
        "  resultInput = []\n",
        "  resultOutput = []\n",
        "  for i in range (0, len(inputList)):\n",
        "    nancount = 0\n",
        "    for val in range(0, len(inputList[i])):\n",
        "      if str(inputList[i:i+1][0][val]) == 'nan': \n",
        "        nancount += 1\n",
        "#     if nancount < len(inputList[i:i+1][0]): \n",
        "    if nancount < 1:\n",
        "      resultInput.append(inputList[i])\n",
        "      resultOutput.append(outputList[i])\n",
        "      \n",
        "  return resultInput, resultOutput\n",
        "\n",
        "newtrainInput, newtrainTarget = remove_useless_inputs(trainInput, trainTarget)\n",
        "\n",
        "print(newtrainInput[0:1])\n",
        "print(len(newtrainInput))\n",
        "print(newtrainTarget[0:1])\n",
        "print(len(newtrainTarget))\n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.6266094420600858, 0.0, 1.0, 0.9958381502890172, 0.9958381502890172, 1.0, 0.5207100591715976, 0.31240748946329217, 0.8312488990664084, 0.6783756964730511, 0.0, 0.9510436137950052, 0.9664013919880972, 0.9664013919880972, 0.9728392032627367, 0.8090134217422564, 0.5925815391975805, 0.8667654764895871, 0.6718085284562461, 0.6737492896064494, 0.6592660515892512, 0.004701086719940492, 0.6461041370159446]]\n",
            "239637\n",
            "['0']\n",
            "239637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfihFidpCu6B",
        "colab_type": "code",
        "outputId": "d92a8b47-7390-45f7-8f72-a7dffa6f83df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "def remove_useless_outputs(inputList, outputList):\n",
        "  resultInput = []\n",
        "  resultOutput = []\n",
        "  for i in range (0, len(outputList)):\n",
        "    if str(outputList[i:i+1][0]).lower() != 'nan': \n",
        "      resultInput.append(inputList[i])\n",
        "      resultOutput.append(outputList[i])\n",
        "   \n",
        "  if isinstance(resultOutput[0:1][0], str):\n",
        "    for x in range (0, len(resultOutput)):\n",
        "      resultOutput[x:x+1] = list(map(int, resultOutput[x:x+1][0]))\n",
        "  print(type(resultOutput[0:1][0]))\n",
        "\n",
        "  print(type(resultOutput[0:1][0]))\n",
        "  return resultInput, resultOutput\n",
        "\n",
        "trainInput, trainTarget = remove_useless_outputs(newtrainInput, newtrainTarget)\n",
        "\n",
        "print(trainInput[0:1])\n",
        "print(len(trainInput))\n",
        "print(trainTarget[0:1])\n",
        "print(len(trainTarget))\n",
        "\n",
        "\n",
        "print(type(trainTarget[0:1]))\n"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'int'>\n",
            "<class 'int'>\n",
            "[[0.6266094420600858, 0.0, 1.0, 0.9958381502890172, 0.9958381502890172, 1.0, 0.5207100591715976, 0.31240748946329217, 0.8312488990664084, 0.6783756964730511, 0.0, 0.9510436137950052, 0.9664013919880972, 0.9664013919880972, 0.9728392032627367, 0.8090134217422564, 0.5925815391975805, 0.8667654764895871, 0.6718085284562461, 0.6737492896064494, 0.6592660515892512, 0.004701086719940492, 0.6461041370159446]]\n",
            "239635\n",
            "[0]\n",
            "239635\n",
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUQ7AXy-1YmR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "969fefc0-42ea-44ad-94f2-81605169065b"
      },
      "source": [
        "print(trainTarget[0:1])\n",
        "print(trainTarget[0])\n",
        "print(trainTarget[1])\n",
        "\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n",
            "0\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mUBGafrC5PO",
        "colab_type": "text"
      },
      "source": [
        "### Reshaping data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PHQ90cpu0t1",
        "colab_type": "code",
        "outputId": "3b01ca66-f6f7-45fb-dedb-232a61d9916d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        }
      },
      "source": [
        "# Conversion to numpy array for improved memory, performance and functionality\n",
        "trainInput, trainTarget = np.array(trainInput), np.array(trainTarget)\n",
        "print(trainInput[0:1])\n",
        "\n",
        "print(trainInput.shape[0])\n",
        "print(trainInput.shape[1])\n",
        "\n",
        "trainInput = np.reshape(trainInput, (trainInput.shape[0], trainInput.shape[1], 1))\n",
        "\n",
        "print(trainInput[0:1])\n",
        "\n",
        "print(trainInput.shape[0])\n",
        "print(trainInput.shape[1])\n"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.62660944 0.         1.         0.99583815 0.99583815 1.\n",
            "  0.52071006 0.31240749 0.8312489  0.6783757  0.         0.95104361\n",
            "  0.96640139 0.96640139 0.9728392  0.80901342 0.59258154 0.86676548\n",
            "  0.67180853 0.67374929 0.65926605 0.00470109 0.64610414]]\n",
            "239635\n",
            "23\n",
            "[[[0.62660944]\n",
            "  [0.        ]\n",
            "  [1.        ]\n",
            "  [0.99583815]\n",
            "  [0.99583815]\n",
            "  [1.        ]\n",
            "  [0.52071006]\n",
            "  [0.31240749]\n",
            "  [0.8312489 ]\n",
            "  [0.6783757 ]\n",
            "  [0.        ]\n",
            "  [0.95104361]\n",
            "  [0.96640139]\n",
            "  [0.96640139]\n",
            "  [0.9728392 ]\n",
            "  [0.80901342]\n",
            "  [0.59258154]\n",
            "  [0.86676548]\n",
            "  [0.67180853]\n",
            "  [0.67374929]\n",
            "  [0.65926605]\n",
            "  [0.00470109]\n",
            "  [0.64610414]]]\n",
            "239635\n",
            "23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB3brZVQZFM7",
        "colab_type": "text"
      },
      "source": [
        "# Network Implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5CxNAYlLG_S",
        "colab_type": "text"
      },
      "source": [
        "## Core Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8rPOgxzwgCk",
        "colab_type": "code",
        "outputId": "f49a81b9-fc2d-4f51-ac24-78ec283be390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(trainInput.shape[1])\n"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlqU_UHBkfJz",
        "colab_type": "code",
        "outputId": "7afbc574-a280-4ace-cd13-a5d8a3373d4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        }
      },
      "source": [
        "data_dim = trainInput.shape[1]\n",
        "timesteps = trainInput.shape[0]\n",
        "\n",
        "# Sample Code\n",
        "# model parameters:\n",
        "\n",
        "def create_model(train_X, train_Y, data_dim):\n",
        "  lstm_units = 128\n",
        "  \n",
        "#   print('Build baseline binary model...')\n",
        "#   model = Sequential()\n",
        "#   model.add(Masking(mask_value=0., input_shape=(data_dim, 1)))\n",
        "#   model.add(LSTM(lstm_units))\n",
        "#   model.add(Dense(1))\n",
        "#   model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  \n",
        "  \n",
        "  print('Build stacked binary model')\n",
        "  model = Sequential()\n",
        "  model.add(Masking(mask_value=0., input_shape=(data_dim, 1)))\n",
        "  model.add(LSTM(lstm_units, return_sequences=True))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(LSTM(lstm_units, return_sequences=True))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(LSTM(lstm_units))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  \n",
        "  #   model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return(model)\n",
        "\n",
        "  \n",
        "baseline_model = create_model(trainInput, trainTarget, data_dim)\n",
        "SVG(model_to_dot(baseline_model, show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build stacked binary model\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"626pt\" viewBox=\"0.00 0.00 310.00 626.00\" width=\"310pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 622)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-622 306,-622 306,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139855707537248 -->\n<g class=\"node\" id=\"node1\">\n<title>139855707537248</title>\n<polygon fill=\"none\" points=\"5.5,-498.5 5.5,-544.5 296.5,-544.5 296.5,-498.5 5.5,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"74.5\" y=\"-517.8\">masking_9: Masking</text>\n<polyline fill=\"none\" points=\"143.5,-498.5 143.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"172.5\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"143.5,-521.5 201.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"172.5\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"201.5,-498.5 201.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249\" y=\"-529.3\">(None, 23, 1)</text>\n<polyline fill=\"none\" points=\"201.5,-521.5 296.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249\" y=\"-506.3\">(None, 23, 1)</text>\n</g>\n<!-- 139855487731528 -->\n<g class=\"node\" id=\"node2\">\n<title>139855487731528</title>\n<polygon fill=\"none\" points=\"16,-415.5 16,-461.5 286,-461.5 286,-415.5 16,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"67\" y=\"-434.8\">lstm_9: LSTM</text>\n<polyline fill=\"none\" points=\"118,-415.5 118,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"147\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"118,-438.5 176,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"147\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"176,-415.5 176,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"231\" y=\"-446.3\">(None, 23, 1)</text>\n<polyline fill=\"none\" points=\"176,-438.5 286,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"231\" y=\"-423.3\">(None, 23, 128)</text>\n</g>\n<!-- 139855707537248&#45;&gt;139855487731528 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139855707537248-&gt;139855487731528</title>\n<path d=\"M151,-498.3799C151,-490.1745 151,-480.7679 151,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"154.5001,-471.784 151,-461.784 147.5001,-471.784 154.5001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139855424757264 -->\n<g class=\"node\" id=\"node3\">\n<title>139855424757264</title>\n<polygon fill=\"none\" points=\"0,-332.5 0,-378.5 302,-378.5 302,-332.5 0,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"67\" y=\"-351.8\">dropout_1: Dropout</text>\n<polyline fill=\"none\" points=\"134,-332.5 134,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"134,-355.5 192,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"192,-332.5 192,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"247\" y=\"-363.3\">(None, 23, 128)</text>\n<polyline fill=\"none\" points=\"192,-355.5 302,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"247\" y=\"-340.3\">(None, 23, 128)</text>\n</g>\n<!-- 139855487731528&#45;&gt;139855424757264 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139855487731528-&gt;139855424757264</title>\n<path d=\"M151,-415.3799C151,-407.1745 151,-397.7679 151,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"154.5001,-388.784 151,-378.784 147.5001,-388.784 154.5001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139855487731640 -->\n<g class=\"node\" id=\"node4\">\n<title>139855487731640</title>\n<polygon fill=\"none\" points=\"12,-249.5 12,-295.5 290,-295.5 290,-249.5 12,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"67\" y=\"-268.8\">lstm_10: LSTM</text>\n<polyline fill=\"none\" points=\"122,-249.5 122,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"151\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"122,-272.5 180,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"151\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"180,-249.5 180,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235\" y=\"-280.3\">(None, 23, 128)</text>\n<polyline fill=\"none\" points=\"180,-272.5 290,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235\" y=\"-257.3\">(None, 23, 128)</text>\n</g>\n<!-- 139855424757264&#45;&gt;139855487731640 -->\n<g class=\"edge\" id=\"edge4\">\n<title>139855424757264-&gt;139855487731640</title>\n<path d=\"M151,-332.3799C151,-324.1745 151,-314.7679 151,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"154.5001,-305.784 151,-295.784 147.5001,-305.784 154.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139856320023856 -->\n<g class=\"node\" id=\"node5\">\n<title>139856320023856</title>\n<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 302,-212.5 302,-166.5 0,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"67\" y=\"-185.8\">dropout_2: Dropout</text>\n<polyline fill=\"none\" points=\"134,-166.5 134,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"134,-189.5 192,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"192,-166.5 192,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"247\" y=\"-197.3\">(None, 23, 128)</text>\n<polyline fill=\"none\" points=\"192,-189.5 302,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"247\" y=\"-174.3\">(None, 23, 128)</text>\n</g>\n<!-- 139855487731640&#45;&gt;139856320023856 -->\n<g class=\"edge\" id=\"edge5\">\n<title>139855487731640-&gt;139856320023856</title>\n<path d=\"M151,-249.3799C151,-241.1745 151,-231.7679 151,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"154.5001,-222.784 151,-212.784 147.5001,-222.784 154.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139856320024136 -->\n<g class=\"node\" id=\"node6\">\n<title>139856320024136</title>\n<polygon fill=\"none\" points=\"12.5,-83.5 12.5,-129.5 289.5,-129.5 289.5,-83.5 12.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"67\" y=\"-102.8\">lstm_11: LSTM</text>\n<polyline fill=\"none\" points=\"121.5,-83.5 121.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"150.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"121.5,-106.5 179.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"150.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"179.5,-83.5 179.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"234.5\" y=\"-114.3\">(None, 23, 128)</text>\n<polyline fill=\"none\" points=\"179.5,-106.5 289.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"234.5\" y=\"-91.3\">(None, 128)</text>\n</g>\n<!-- 139856320023856&#45;&gt;139856320024136 -->\n<g class=\"edge\" id=\"edge6\">\n<title>139856320023856-&gt;139856320024136</title>\n<path d=\"M151,-166.3799C151,-158.1745 151,-148.7679 151,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"154.5001,-139.784 151,-129.784 147.5001,-139.784 154.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139855470818416 -->\n<g class=\"node\" id=\"node7\">\n<title>139855470818416</title>\n<polygon fill=\"none\" points=\"25,-.5 25,-46.5 277,-46.5 277,-.5 25,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"78.5\" y=\"-19.8\">dense_9: Dense</text>\n<polyline fill=\"none\" points=\"132,-.5 132,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"132,-23.5 190,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"190,-.5 190,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"233.5\" y=\"-31.3\">(None, 128)</text>\n<polyline fill=\"none\" points=\"190,-23.5 277,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"233.5\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 139856320024136&#45;&gt;139855470818416 -->\n<g class=\"edge\" id=\"edge7\">\n<title>139856320024136-&gt;139855470818416</title>\n<path d=\"M151,-83.3799C151,-75.1745 151,-65.7679 151,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"154.5001,-56.784 151,-46.784 147.5001,-56.784 154.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139856665013944 -->\n<g class=\"node\" id=\"node8\">\n<title>139856665013944</title>\n<polygon fill=\"none\" points=\"86.5,-581.5 86.5,-617.5 215.5,-617.5 215.5,-581.5 86.5,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"151\" y=\"-595.8\">139856665013944</text>\n</g>\n<!-- 139856665013944&#45;&gt;139855707537248 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139856665013944-&gt;139855707537248</title>\n<path d=\"M151,-581.4092C151,-573.4308 151,-563.795 151,-554.606\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"154.5001,-554.5333 151,-544.5333 147.5001,-554.5334 154.5001,-554.5333\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYv6OKlT52Pq",
        "colab_type": "code",
        "outputId": "bb70a926-ceae-4a36-b01b-a7c4ab9d8a28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "source": [
        "baseline_model.summary()"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "masking_9 (Masking)          (None, 23, 1)             0         \n",
            "_________________________________________________________________\n",
            "lstm_9 (LSTM)                (None, 23, 128)           66560     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 23, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 23, 128)           131584    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 23, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 329,857\n",
            "Trainable params: 329,857\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQO47iKk0oRU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "7f538752-154b-4593-b9ee-a35da24d5f9e"
      },
      "source": [
        "baseline_model.fit(trainInput, trainTarget, epochs = 100, batch_size = 256, verbose = 1)\n"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "239635/239635 [==============================] - 548s 2ms/step - loss: 0.6942 - acc: 0.5017\n",
            "Epoch 2/100\n",
            " 23296/239635 [=>............................] - ETA: 8:15 - loss: 0.6942 - acc: 0.5006"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-134-9fade3b5e463>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbaseline_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBvqxci1kVZn",
        "colab_type": "text"
      },
      "source": [
        "# Benchmark\n",
        "\n"
      ]
    }
  ]
}