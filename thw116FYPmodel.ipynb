{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "thw116FYPmodel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIU13nThWPq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Activation, Dense, LSTM, Dropout, Masking, Input\n",
        "from keras import optimizers\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "from IPython.display import SVG\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oerk0UaY0wG",
        "colab_type": "text"
      },
      "source": [
        "# Initial Data Importation and Structuring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-vX5NnVkai6",
        "colab_type": "text"
      },
      "source": [
        "## Accessing and loading data from Google Drive \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtzJiK3GZxwf",
        "colab_type": "code",
        "outputId": "45a06056-c9dc-48d4-c0a8-342a584eff0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# mounting Google Drive which contains the relevant data\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 4/ZwFoT8CKuomgNmyvFZMDEuEj_Fjq89ibCm76aAsCKjn-sLxwohkSa1I"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKuXkHkNWbSS",
        "colab_type": "code",
        "outputId": "98bd69ee-740c-4558-fed9-571860702138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        }
      },
      "source": [
        "# Fundamental input data\n",
        "ltm_book = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ltm_book.csv')\n",
        "ltm_div = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ltm_div.csv')\n",
        "ltm_ebit = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ltm_ebit.csv')\n",
        "ltm_eps = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ltm_eps.csv')\n",
        "ltm_fcf = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ltm_fcf.csv')\n",
        "ltm_pbook = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ltm_pbook.csv')\n",
        "ltm_sales = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ltm_sales.csv')\n",
        "\n",
        "ntm_book = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ntm_book.csv')\n",
        "ntm_div = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ntm_div.csv')\n",
        "ntm_ebit = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ntm_ebit.csv')\n",
        "ntm_eps = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ntm_eps.csv')\n",
        "ntm_fcf = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ntm_fcf.csv')\n",
        "ntm_pbook = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ntm_pbook.csv')\n",
        "ntm_sales = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ntm_sales.csv')\n",
        "\n",
        "# Technical input data\n",
        "\n",
        "price_high = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/price_high.csv')\n",
        "price_low = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/price_low.csv')\n",
        "price_open = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/price_open.csv')\n",
        "volume = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/volume.csv')\n",
        "enterprise_val = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/enterprise_val.csv')\n",
        "market_cap = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/market_cap.csv')\n",
        "\n",
        "print(ltm_book.head())\n",
        "print(\"**************************************\")\n",
        "print(ltm_book.info())\n",
        "\n",
        "\n",
        "# Price target output data\n",
        "\n",
        "price_close = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/price_close.csv')\n",
        "\n",
        "print(price_close.head())\n",
        "print(\"**************************************\")\n",
        "print(price_close.info())\n",
        "\n",
        "\n",
        "# Test data\n",
        "\n",
        "# test_data = pd.read_csv(\"/content/drive/My Drive/thw116_FYP/data/test_price.csv\")\n",
        "\n",
        "# print(test_data.head())\n",
        "# print(\"**************************************\")\n",
        "# print(test_data.info())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Unnamed: 0  ATRS AV  ESSR LN  ...  FABGB SS  926002Q GY  NDA SS\n",
            "0           1      NaN      NaN  ...       NaN         NaN     NaN\n",
            "1           2      NaN      NaN  ...       NaN         NaN     NaN\n",
            "2           3      NaN      NaN  ...       NaN         NaN     NaN\n",
            "3           4      NaN      NaN  ...       NaN         NaN     NaN\n",
            "4           5      NaN      NaN  ...       NaN         NaN     NaN\n",
            "\n",
            "[5 rows x 1185 columns]\n",
            "**************************************\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6313 entries, 0 to 6312\n",
            "Columns: 1185 entries, Unnamed: 0 to NDA SS\n",
            "dtypes: float64(1184), int64(1)\n",
            "memory usage: 57.1 MB\n",
            "None\n",
            "   Unnamed: 0  PAYS LN  CNHI IM     SGSN SW  ...  AMS SM  FER SM  SEV FP    FKI LN\n",
            "0  1995-01-03      NaN      NaN  222.552843  ...     NaN     NaN     NaN  1.896782\n",
            "1  1995-01-04      NaN      NaN  226.835424  ...     NaN     NaN     NaN  1.883390\n",
            "2  1995-01-05      NaN      NaN  228.312320  ...     NaN     NaN     NaN  1.910292\n",
            "3  1995-01-06      NaN      NaN  228.015450  ...     NaN     NaN     NaN  1.923861\n",
            "4  1995-01-09      NaN      NaN  228.680128  ...     NaN     NaN     NaN  1.925099\n",
            "\n",
            "[5 rows x 204 columns]\n",
            "**************************************\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6313 entries, 0 to 6312\n",
            "Columns: 204 entries, Unnamed: 0 to FKI LN\n",
            "dtypes: float64(203), object(1)\n",
            "memory usage: 9.8+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM8LCiFbCWVG",
        "colab_type": "text"
      },
      "source": [
        "##Restructuring and Standardising the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwQDmx99oPzr",
        "colab_type": "code",
        "outputId": "01f50606-d54b-49ff-d074-5123d4319d8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "# Filtering incorrect datasets to suitable company subsets\n",
        "industrials_subset = price_close.columns.values.tolist()\n",
        "\n",
        "ltm_inputs = [ltm_book, ltm_div, ltm_ebit, ltm_eps, ltm_fcf, ltm_pbook, ltm_sales] \n",
        "ntm_inputs = [ntm_book, ntm_div, ntm_ebit, ntm_eps, ntm_fcf, ntm_pbook, ntm_sales]\n",
        "tech_inputs = [price_high, price_low, price_open, volume, enterprise_val, market_cap]\n",
        "\n",
        "for i in range(0,len(ltm_inputs)):\n",
        "  ltm_inputs[i] = ltm_inputs[i].loc[:, ltm_inputs[i].columns.str.contains('|'.join(industrials_subset))]\n",
        "  ltm_inputs[i]['Unnamed: 0'] = price_close['Unnamed: 0']\n",
        "  ltm_inputs[i].rename( columns={'Unnamed: 0':'Date'}, inplace=True )\n",
        "\n",
        "for i in range(0,len(ntm_inputs)):\n",
        "  ntm_inputs[i] = ntm_inputs[i].loc[:, ntm_inputs[i].columns.str.contains('|'.join(industrials_subset))]\n",
        "  ntm_inputs[i]['Unnamed: 0'] = price_close['Unnamed: 0']\n",
        "  ntm_inputs[i].rename( columns={'Unnamed: 0':'Date'}, inplace=True )\n",
        "\n",
        "for i in range(0,len(tech_inputs)):\n",
        "  tech_inputs[i] = tech_inputs[i].loc[:, tech_inputs[i].columns.str.contains('|'.join(industrials_subset))]\n",
        "  tech_inputs[i]['Unnamed: 0'] = price_close['Unnamed: 0']\n",
        "  tech_inputs[i].rename( columns={'Unnamed: 0':'Date'}, inplace=True )\n",
        "\n",
        "  \n",
        "price_close.rename( columns={'Unnamed: 0':'Date'}, inplace=True )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhYPF4OmJOwm",
        "colab_type": "text"
      },
      "source": [
        "## Data Wrangling\n",
        "\n",
        "In order to produce a dataframe suitable for the model, we must first take the raw *Price.csv*  file and convert it to returns. This can then be maniuplated further in a variety of ways to achieve the neccessary classification for variants of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHv1OtsgCC2C",
        "colab_type": "text"
      },
      "source": [
        "###Date Index Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcygJ5YtWP8H",
        "colab_type": "code",
        "outputId": "7eabb894-031e-4ca7-8423-02d61eb88e5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "# Conversion of TimeAndDate column to DatetimeIndex for ease of use\n",
        "\n",
        "def time_index_generator(dataframe):\n",
        "  dataframe['Date'] = pd.to_datetime(dataframe['Date'], dayfirst=True)\n",
        "  dataframe.set_index('Date', inplace=True)\n",
        "\n",
        "\n",
        "for i in range(0,len(ltm_inputs)):\n",
        "  time_index_generator(ltm_inputs[i])\n",
        "for i in range(0,len(ntm_inputs)):\n",
        "  time_index_generator(ntm_inputs[i])\n",
        "for i in range(0,len(tech_inputs)):\n",
        "  time_index_generator(tech_inputs[i])  \n",
        "\n",
        "time_index_generator(price_close)\n",
        "  \n",
        "print(ltm_inputs[0].head(2))\n",
        "print(ntm_inputs[0].head(2))\n",
        "print(tech_inputs[0].head(2))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "            PAYS LN  CNHI IM  SGSN SW  PAGE LN  ...  AMS SM  FER SM  SEV FP  FKI LN\n",
            "Date                                            ...                                \n",
            "1995-01-03      NaN      NaN      NaN      NaN  ...     NaN     NaN     NaN     NaN\n",
            "1995-01-04      NaN      NaN      NaN      NaN  ...     NaN     NaN     NaN     NaN\n",
            "\n",
            "[2 rows x 203 columns]\n",
            "            PAYS LN  CNHI IM  SGSN SW  PAGE LN  ...  AMS SM  FER SM  SEV FP  FKI LN\n",
            "Date                                            ...                                \n",
            "1995-01-03      NaN      NaN      NaN      NaN  ...     NaN     NaN     NaN     NaN\n",
            "1995-01-04      NaN      NaN      NaN      NaN  ...     NaN     NaN     NaN     NaN\n",
            "\n",
            "[2 rows x 203 columns]\n",
            "            PAYS LN  CNHI IM     SGSN SW  ...  FER SM  SEV FP   FKI LN\n",
            "Date                                      ...                         \n",
            "1995-01-03      NaN      NaN  222.552843  ...     NaN     NaN  1.91608\n",
            "1995-01-04      NaN      NaN  232.668335  ...     NaN     NaN  1.90907\n",
            "\n",
            "[2 rows x 203 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5fWXKHjLpzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check all columns align correctly\n",
        "print(ltm_inputs[0].columns.difference(price_close.columns))\n",
        "print(ltm_inputs[1].columns.difference(price_close.columns))\n",
        "print(ltm_inputs[2].columns.difference(price_close.columns))\n",
        "print(ltm_inputs[3].columns.difference(price_close.columns))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhIWXVtzB5co",
        "colab_type": "text"
      },
      "source": [
        "###Ticker Anonymisation \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCGMHTY0zA7O",
        "colab_type": "code",
        "outputId": "4728e085-bc4a-41d4-fcd1-223183592807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        }
      },
      "source": [
        "# Check that all tickers in the set match\n",
        "\n",
        "# Helper function to generate ticker list\n",
        "def ticker_list_generator(num):\n",
        "  ticker_list = []\n",
        "  for i in range(0, num):\n",
        "    ticker_name = 'Ticker ' + str(i+1)\n",
        "    ticker_list.append(ticker_name)\n",
        "  return ticker_list\n",
        "\n",
        "anon_tickers = ticker_list_generator(len(ltm_inputs[0].columns))\n",
        "\n",
        "for i in range(0,len(ltm_inputs)):\n",
        "  ltm_inputs[0].columns = anon_tickers\n",
        "for i in range(0,len(ntm_inputs)):\n",
        "  ntm_inputs[0].columns = anon_tickers\n",
        "for i in range(0,len(tech_inputs)):\n",
        "  tech_inputs[0].columns = anon_tickers\n",
        "\n",
        "price_close.columns = anon_tickers\n",
        "\n",
        "print(ltm_inputs[0].head(2))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Ticker 1  Ticker 2  Ticker 3  ...  Ticker 201  Ticker 202  Ticker 203\n",
            "Date                                      ...                                    \n",
            "1995-01-03       NaN       NaN       NaN  ...         NaN         NaN         NaN\n",
            "1995-01-04       NaN       NaN       NaN  ...         NaN         NaN         NaN\n",
            "\n",
            "[2 rows x 203 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3b3tTGWYXjuQ",
        "colab": {}
      },
      "source": [
        "# Selecting a Ticker and plotting\n",
        "\n",
        "# test_data['Ticker 1'].plot(figsize=(16,6))\n",
        "# plt.title('Test Results - Ticker 1')\n",
        "# plt.xlabel('Date')\n",
        "# plt.ylabel('Attribute')\n",
        "\n",
        "# test_data.plot(figsize=(16,6))\n",
        "\n",
        "ltm_inputs[0]['Ticker 1'].plot(figsize=(16,6))\n",
        "plt.title('ltm_book - Ticker 1')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Attribute')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3bt2ejCCjYr",
        "colab_type": "text"
      },
      "source": [
        "###Price to Returns Converter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gep9h1FNHQJ0",
        "colab_type": "code",
        "outputId": "f81e3f33-dac6-42a2-bae4-82ee8165f1b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        }
      },
      "source": [
        "# Converting Price format to returns format\n",
        "def price_to_returns(timeframe, dataframe):\n",
        "  if timeframe == 'daily':\n",
        "    return dataframe.pct_change(1) # remember to discount all target variables that are NaN\n",
        "  \n",
        "  if timeframe == 'monthly':\n",
        "    return dataframe.resample('BM')\n",
        "  \n",
        "returns = price_to_returns('daily', price_close) \n",
        "\n",
        "print(returns.head(2))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Ticker 1  Ticker 2  Ticker 3  ...  Ticker 201  Ticker 202  Ticker 203\n",
            "Date                                      ...                                    \n",
            "1995-01-03       NaN       NaN       NaN  ...         NaN         NaN         NaN\n",
            "1995-01-04       NaN       NaN  0.019243  ...         NaN         NaN    -0.00706\n",
            "\n",
            "[2 rows x 203 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guJycK9f5Z1E",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "Several steps are taken in order to structure the data so that it can be proccessed by the model.\n",
        "\n",
        "1.   Data Analysis and Cleaning: Data is analysed for missing values, its properties, smoothed for various time intervals and resolved of any inconsistencies.  \n",
        "\n",
        "2. Training-Test Split: Data is divided into training and test splits according to a selected parameter value. \n",
        "\n",
        "3.  Data Transformation: Data is normalised, aggregated and generalised, both for training and testing\n",
        "\n",
        "4. Data Integration: Data is merged together appropriately to form the input shape of the model.   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfuTGvzQKPue",
        "colab_type": "text"
      },
      "source": [
        "##Data Analysis and Cleaning\n",
        "\n",
        "Something to consider is the fact that returns are more likely to correlate with changes in fundamentals rather than the absolute values of fundamentals. However, there is likely to be a disceprancy in the rate of change of fundamentals and the change in prices. Fundamentals are often only declared quarterly whereas prices are subject to daily fluctuations. We will first analyse the number of times a fundamental changes relative to the price changes. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-Drzbr-Blq1",
        "colab_type": "text"
      },
      "source": [
        "###Stastical Summaries of Data Count and Boxplots\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqP4Ys_6c7vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# statistical summary of datasets\n",
        "print(tech_inputs[0].describe())\n",
        "\n",
        "# Box plot of dataset's datapoints count\n",
        "tech_inputs[0].count().plot(kind='box', showmeans = True) \n",
        "plt.xlabel('Technical inputs')\n",
        "plt.tight_layout() \n",
        "plt.show()\n",
        "\n",
        "# plt.savefig('tech_box.png')\n",
        "# files.download('tech_box.png') \n",
        "\n",
        "# Individual tickers' datapoint count bar graph\n",
        "\n",
        "# ltm_inputs[0.count().plot(kind='barh', figsize=(20,20)) \n",
        "# plt.xlabel('LTM input')\n",
        "# plt.tight_layout() \n",
        "# plt.show()\n",
        "\n",
        "# plt.savefig('ltmTickerCount.png')\n",
        "# files.download('ltmTickerCount.png') \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsXsCknQBv-l",
        "colab_type": "text"
      },
      "source": [
        "###Stastical Summaries of Delta Data Count and Boxplots\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO_BJonjhHVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_change(dataframe, column): \n",
        "  noChange_count = 0\n",
        "  NaN_count = 0\n",
        "  for i in range (0, len(dataframe.index)): \n",
        "    if dataframe[column].diff().iloc[i] == 0:\n",
        "      noChange_count += 1\n",
        "    if dataframe[column].isna().iloc[i]: \n",
        "      NaN_count += 1\n",
        "  \n",
        "#   print('Total rows: ', len(dataframe[column]))\n",
        "#   print('The number of rows where no change occurs: ', noChange_count)\n",
        "#   print('The number of rows which are NaN: ', NaN_count)\n",
        "#   print('Useful datapoints:', (len(dataframe[column])-noChange_count-NaN_count))\n",
        "  return len(dataframe[column])-noChange_count-NaN_count\n",
        "\n",
        "delta_change = []\n",
        "\n",
        "for companies in range(0, tech_inputs[0].shape[1]):\n",
        "  delta_val = data_change(tech_inputs[0], anon_tickers[companies])\n",
        "  delta_change.append(delta_val)\n",
        "  \n",
        "plt.boxplot(delta_change, showmeans = True)\n",
        "plt.xlabel('Technical inputs')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCfZwIpBQBIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allreturns = returns.stack(dropna=False).reset_index(drop=True).to_frame('new')\n",
        "allreturns.hist(range=(0.75,1.25), figsize=(16,8), bins=200)\n",
        "\n",
        "allreturns = np.log(allreturns) \n",
        "allreturns.hist(range=(-0.75,0.75), figsize=(16,8), bins=200)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtPwvxIHJYUJ",
        "colab_type": "code",
        "outputId": "408bfada-5721-4951-f0fc-87ea1b9f4774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "source": [
        "for i in range(0,len(ltm_inputs)):\n",
        "  ltm_inputs[i] = ltm_inputs[i].loc[ltm_inputs[i].index > pd.to_datetime('2000-1-1')]\n",
        "\n",
        "for i in range(0,len(ntm_inputs)):\n",
        "  ntm_inputs[i] = ntm_inputs[i].loc[ntm_inputs[i].index > pd.to_datetime('2000-1-1')]\n",
        "\n",
        "for i in range(0,len(tech_inputs)):\n",
        "  tech_inputs[i] = tech_inputs[i].loc[tech_inputs[i].index > pd.to_datetime('2000-1-1')]\n",
        "  \n",
        "returns = returns.loc[tech_inputs[i].index > pd.to_datetime('2000-1-1')]\n",
        "\n",
        "print(ltm_inputs[0].head())\n",
        "print(ntm_inputs[0].head())\n",
        "print(tech_inputs[0].head())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Ticker 1  Ticker 2  Ticker 3  ...  Ticker 201  Ticker 202  Ticker 203\n",
            "Date                                      ...                                    \n",
            "2000-01-03       NaN       NaN    117.74  ...         0.0         NaN        0.65\n",
            "2000-01-04       NaN       NaN    117.74  ...         0.0         NaN        0.65\n",
            "2000-01-05       NaN       NaN    117.74  ...         0.0         NaN        0.65\n",
            "2000-01-06       NaN       NaN    117.74  ...         0.0         NaN        0.65\n",
            "2000-01-07       NaN       NaN    117.74  ...         0.0         NaN        0.65\n",
            "\n",
            "[5 rows x 203 columns]\n",
            "            Ticker 1  Ticker 2   Ticker 3  ...  Ticker 201  Ticker 202  Ticker 203\n",
            "Date                                       ...                                    \n",
            "2000-01-03       NaN       NaN  80.346944  ...    7.113631         NaN    0.679508\n",
            "2000-01-04       NaN       NaN  80.206294  ...    7.115123         NaN    0.678316\n",
            "2000-01-05       NaN       NaN  80.065375  ...    7.116613         NaN    0.678082\n",
            "2000-01-06       NaN       NaN  79.924189  ...    7.118100         NaN    0.677842\n",
            "2000-01-07       NaN       NaN  79.782735  ...    7.119585         NaN    0.677597\n",
            "\n",
            "[5 rows x 203 columns]\n",
            "            Ticker 1   Ticker 2    Ticker 3  ...  Ticker 201  Ticker 202  Ticker 203\n",
            "Date                                         ...                                    \n",
            "2000-01-03       NaN  17.126268  311.332257  ...       16.00         NaN    4.010075\n",
            "2000-01-04       NaN  17.354009  311.716559  ...       14.95         NaN    3.984764\n",
            "2000-01-05       NaN  17.058334  304.474022  ...       14.60         NaN    4.249838\n",
            "2000-01-06       NaN  18.773988  306.749617  ...       14.60         NaN    4.219413\n",
            "2000-01-07       NaN  18.883468  307.941172  ...       14.70         NaN    4.202858\n",
            "\n",
            "[5 rows x 203 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbrJzj6fJqvv",
        "colab_type": "text"
      },
      "source": [
        "## Training Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yfDmdQJcrPp",
        "colab_type": "code",
        "outputId": "ff49bd22-aa8b-4aac-b9ca-54d66f720d59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "def training_set(train_percentage, dataframe): \n",
        "  train_size = int(train_percentage*len(dataframe.index)) \n",
        "  train_set = dataframe[:train_size]\n",
        "  return pd.DataFrame(train_set)  \n",
        "\n",
        "training_split = 0.8\n",
        "\n",
        "# INPUTS\n",
        "\n",
        "print(type(ltm_inputs))\n",
        "\n",
        "ltm_trainInputs = []\n",
        "ntm_trainInputs = []\n",
        "tech_trainInputs = []\n",
        "\n",
        "for i in range(0,len(ltm_inputs)):\n",
        "  ltm_trainInputs.append(training_set(training_split, ltm_inputs[i]))\n",
        "  \n",
        "for i in range(0,len(ntm_inputs)):\n",
        "  ntm_trainInputs.append(training_set(training_split, ntm_inputs[i]))\n",
        "\n",
        "for i in range(0,len(tech_inputs)):\n",
        "  tech_trainInputs.append(training_set(training_split, tech_inputs[i]))\n",
        "\n",
        "  \n",
        "returns_trainOutput = training_set(training_split, returns)\n",
        "\n",
        "\n",
        "print(ntm_trainInputs[0].info())\n",
        "print(returns_trainOutput.info())\n",
        "\n",
        "\n",
        "# # TEST INPUT\n",
        "# test_train_set = training_set(training_split, test_data)\n",
        "# print(\"****************INPUT*****************\")\n",
        "# print (test_train_set.head())\n",
        "# print(\"**************************************\")\n",
        "# print(test_train_set.info())\n",
        "\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 4013 entries, 2000-01-03 to 2015-06-26\n",
            "Columns: 203 entries, Ticker 1 to Ticker 203\n",
            "dtypes: float64(203)\n",
            "memory usage: 6.2 MB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 4013 entries, 1995-01-03 to 2010-06-24\n",
            "Columns: 203 entries, Ticker 1 to Ticker 203\n",
            "dtypes: float64(203)\n",
            "memory usage: 6.2 MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47IfciNTutCX",
        "colab_type": "text"
      },
      "source": [
        "## Validation Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ-QTlDF1hOm",
        "colab_type": "code",
        "outputId": "0e58e52e-7807-4333-de1c-e06253fdfff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "source": [
        "def validation_set(train_percentage, dataframe): \n",
        "  train_size = int(train_percentage*len(dataframe.index)) \n",
        "  # val_size = len(dataframe.index)-int(train_percentage*len(dataframe.index)) \n",
        "  val_set = dataframe[train_size:]\n",
        "  return pd.DataFrame(val_set)  \n",
        "\n",
        "\n",
        "ltm_valInputs = []\n",
        "ntm_valInputs = []\n",
        "tech_valInputs = []\n",
        "\n",
        "for i in range(0,len(ltm_inputs)):\n",
        "  ltm_valInputs.append(validation_set(training_split, ltm_inputs[i]))\n",
        "  \n",
        "for i in range(0,len(ntm_inputs)):\n",
        "  ntm_valInputs.append(validation_set(training_split, ntm_inputs[i]))\n",
        "\n",
        "for i in range(0,len(tech_inputs)):\n",
        "  tech_valInputs.append(validation_set(training_split, tech_inputs[i]))\n",
        "\n",
        "  \n",
        "returns_valOutput = validation_set(training_split, returns)\n",
        "\n",
        "print(ltm_valInputs[0].info())\n",
        "print(returns_valOutput.info())\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 1004 entries, 2015-06-29 to 2019-05-17\n",
            "Columns: 203 entries, Ticker 1 to Ticker 203\n",
            "dtypes: float64(203)\n",
            "memory usage: 1.6 MB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 1004 entries, 2010-06-25 to 2014-05-09\n",
            "Columns: 203 entries, Ticker 1 to Ticker 203\n",
            "dtypes: float64(203)\n",
            "memory usage: 1.6 MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMx_2j-80Bfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure()\n",
        "fig.set_figheight(28)\n",
        "\n",
        "plt.subplot(4, 1, 1)\n",
        "sns.heatmap(returns_trainOutput.isnull(), cbar=False)\n",
        "\n",
        "plt.subplot(4, 1, 2)\n",
        "sns.heatmap(returns_valOutput.isnull(), cbar=False)\n",
        "\n",
        "plt.subplot(4, 1, 3)\n",
        "sns.heatmap(tech_trainInputs[1].isnull(), cbar=False)\n",
        "\n",
        "plt.subplot(4, 1, 4)\n",
        "sns.heatmap(tech_valInputs[1].isnull(), cbar=False)\n",
        "\n",
        "# plt.savefig('heatmap.png')\n",
        "# files.download('heatmap.png') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U79APBT7JwcE",
        "colab_type": "text"
      },
      "source": [
        "## Input and Output Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfE-0om8FrZz",
        "colab_type": "text"
      },
      "source": [
        "###Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38KlbkcIfOk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_scaling(dataframe):\n",
        "  \n",
        "  # This is the MinMax Scaling function \n",
        "  sc = MinMaxScaler(feature_range = (0, 1))\n",
        "  scaled_input_dataframe = sc.fit_transform(dataframe) # This is now an n-dimensional array type\n",
        "  \n",
        "  return scaled_input_dataframe\n",
        "\n",
        "np.warnings.filterwarnings('ignore', r'All-NaN (slice|axis) encountered')\n",
        "\n",
        "for i in range(0,len(ltm_inputs)):\n",
        "  ltm_trainInputs[i] = input_scaling(ltm_trainInputs[i])\n",
        "  ltm_valInputs[i] = input_scaling(ltm_valInputs[i])\n",
        "  \n",
        "for i in range(0,len(ntm_inputs)):\n",
        "  ntm_trainInputs[i] = input_scaling(ntm_trainInputs[i])\n",
        "  ntm_valInputs[i] = input_scaling(ntm_valInputs[i])\n",
        "\n",
        "for i in range(0,len(tech_inputs)):\n",
        "  tech_trainInputs[i] = input_scaling(tech_trainInputs[i])\n",
        "  tech_valInputs[i] = input_scaling(tech_valInputs[i])\n",
        " \n",
        "# sample_input = [ltm_trainInputs[0][1000:1001][0][3],ntm_trainInputs[0][1000:1001][0][3], tech_trainInputs[0][1000:1001][0][3] ]\n",
        "# print(sample_input)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spsYzewNmtEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "median = []\n",
        "median = returns_trainOutput.median(axis=1)\n",
        "\n",
        "# for column in range(0,returns_trainOutput.shape[0]):\n",
        "#   for row in range(0, returns_trainOutput.shape[1]): \n",
        "#     if returns_trainOutput.iloc[column, row] >= median[row]: \n",
        "#       returns_trainOutput.iloc[column, row] = 1\n",
        "#     else:\n",
        "#       returns_trainOutput.iloc[column, row] = 0\n",
        "      \n",
        "      \n",
        "# index, row in returns_trainOutput.iterrows():\n",
        "#     print(index, list(returns_trainOutput.columns[row > median[index]]))\n",
        "\n",
        "apply(lambda x: 'true' if x <= 2.5 else 'false')\n",
        "\n",
        "for ticker in range(0,len(returns_trainOutput)):\n",
        "  if returns_trainOutput[anon_tickers[ticker]] >= median[ticker]\n",
        "    df['my_channel'].mask(df['my_channel'] > 20000, 0, inplace=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6snYzXc-yTv",
        "colab_type": "code",
        "outputId": "ffae44ae-651b-435b-fce9-efa4cfaaff10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "def output_classifier(type ,dataframe): \n",
        "  \n",
        "  # No adjustments\n",
        "  if type == 'raw':\n",
        "    scaled_dataframe = dataframe\n",
        "  \n",
        "  # Binary classifier where return>0 is +1, and return<0 is 0 labels\n",
        "  if type == 'binary':\n",
        "    pos_returns = dataframe.values > 0\n",
        "    neg_returns = dataframe.values <= 0 \n",
        "    scaled_dataframe = pd.DataFrame(np.select([pos_returns,neg_returns], [1,0], default='NaN'), index=dataframe.index, columns=dataframe.columns)\n",
        "\n",
        "  return scaled_dataframe\n",
        "\n",
        "returns_trainOutput = output_classifier('binary', returns_trainOutput)\n",
        "returns_valOutput = output_classifier('binary', returns_valOutput)\n",
        "\n",
        "print (returns_trainOutput.head(2))\n",
        "print (returns_trainOutput.info())\n",
        "\n",
        "print (returns_valOutput.head(2))\n",
        "print (returns_valOutput.info())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in greater\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in less_equal\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "           Ticker 1 Ticker 2 Ticker 3  ... Ticker 201 Ticker 202 Ticker 203\n",
            "Date                                   ...                                 \n",
            "1995-01-03      NaN      NaN      NaN  ...        NaN        NaN        NaN\n",
            "1995-01-04      NaN      NaN        1  ...        NaN        NaN          0\n",
            "\n",
            "[2 rows x 203 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 4013 entries, 1995-01-03 to 2010-06-24\n",
            "Columns: 203 entries, Ticker 1 to Ticker 203\n",
            "dtypes: object(203)\n",
            "memory usage: 6.2+ MB\n",
            "None\n",
            "           Ticker 1 Ticker 2 Ticker 3  ... Ticker 201 Ticker 202 Ticker 203\n",
            "Date                                   ...                                 \n",
            "2010-06-25        1        0        1  ...          0          0          0\n",
            "2010-06-28        1        0        1  ...          0          0          0\n",
            "\n",
            "[2 rows x 203 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 1004 entries, 2010-06-25 to 2014-05-09\n",
            "Columns: 203 entries, Ticker 1 to Ticker 203\n",
            "dtypes: object(203)\n",
            "memory usage: 1.6+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeMN7TE0Ki1P",
        "colab_type": "text"
      },
      "source": [
        "## Data Integration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYKnA5iUAnmG",
        "colab_type": "code",
        "outputId": "257f9644-dca3-4535-9aa2-4ad64cec4a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "trainInput = []\n",
        "trainTarget = []\n",
        "\n",
        "valInput = []\n",
        "valTarget = []\n",
        "\n",
        "# Check that the indices are of the same length \n",
        "if len(ltm_trainInputs[0]) != len(returns_trainOutput):\n",
        "  assert False, \"Incompatible dataframe index lengths!\"\n",
        "\n",
        "for company in range(0, len(ltm_trainInputs[0][:1][0])):\n",
        "  \n",
        "  for time_unit in range(0, len(ltm_trainInputs[0])): \n",
        "    input_unit = []\n",
        "    \n",
        "    for ltm_attribute in range(0, len(ltm_trainInputs)): \n",
        "      input_unit.append(ltm_trainInputs[ltm_attribute][time_unit:time_unit+1][0][company])\n",
        "                        \n",
        "    for ntm_attribute in range(0, len(ntm_trainInputs)):\n",
        "      input_unit.append(ntm_trainInputs[ntm_attribute][time_unit:time_unit+1][0][company])\n",
        "                        \n",
        "    for tech_attribute in range(0, len(tech_trainInputs)): \n",
        "      input_unit.append(tech_trainInputs[tech_attribute][time_unit:time_unit+1][0][company])\n",
        "                        \n",
        "    trainInput.append(input_unit)\n",
        "    \n",
        "for company in range(0, len(returns_trainOutput.columns)):\n",
        "  for time_unit in range(0, len(returns_trainOutput.index)): \n",
        "    trainTarget.append(returns_trainOutput[anon_tickers[company]][time_unit])\n",
        "  \n",
        "  \n",
        "for company in range(0, len(ltm_valInputs[0][:1][0])):\n",
        "  \n",
        "  for time_unit in range(0, len(ltm_valInputs[0])): \n",
        "    input_unit = []\n",
        "    \n",
        "    for ltm_attribute in range(0, len(ltm_valInputs)): \n",
        "      input_unit.append(ltm_valInputs[ltm_attribute][time_unit:time_unit+1][0][company])\n",
        "                        \n",
        "    for ntm_attribute in range(0, len(ntm_trainInputs)):\n",
        "      input_unit.append(ntm_valInputs[ntm_attribute][time_unit:time_unit+1][0][company])\n",
        "                        \n",
        "    for tech_attribute in range(0, len(tech_trainInputs)): \n",
        "      input_unit.append(tech_valInputs[tech_attribute][time_unit:time_unit+1][0][company])\n",
        "                        \n",
        "    valInput.append(input_unit)\n",
        "    \n",
        "for company in range(0, len(returns_valOutput.columns)):\n",
        "  for time_unit in range(0, len(returns_valOutput.index)): \n",
        "    valTarget.append(returns_valOutput[anon_tickers[company]][time_unit])\n",
        "\n",
        "# for i in range(0, len(scaled_returns_train_set.index)): # this is the ratio of input data to output data. \n",
        "#     X_train.append(scaled_test_train_set[i-6:i, 0]) # second parameter is the axis - in this case, only 1 dimension\n",
        "#     Y_train.append(scaled_returns_train_set[i, 0])\n",
        "\n",
        "# print(type(input_trainDataset))\n",
        "# print(\"**************************************\")\n",
        "# print(input_trainDataset[0:5])\n",
        "\n",
        "\n",
        "# # Conversion to numpy array for improved memory, performance and functionality\n",
        "# input_trainDataset, output_trainDataset = np.array(input_trainDataset), np.array(output_trainDataset)\n",
        "# print(type(input_trainDataset))\n",
        "# print(\"**************************************\")\n",
        "\n",
        "# print(input_trainDataset[0:5])\n",
        "\n",
        "# print(input_trainDataset.shape[0])\n",
        "# print(input_trainDataset.shape[1])\n",
        "# print(\"**************************************\")\n",
        "\n",
        "\n",
        "print(trainInput[0:1])\n",
        "print(len(trainInput))\n",
        "print(trainTarget[0:1])\n",
        "print(len(trainTarget))\n",
        "\n",
        "print(valInput[0:1])\n",
        "print(len(valInput))\n",
        "print(valTarget[0:1])\n",
        "print(len(valTarget))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]\n",
            "814639\n",
            "['NaN']\n",
            "814639\n",
            "[[0.0, 0.0, 0.0065815202357901725, 1.0, 0.0, 0.6938065083396615, 0.0, 0.0, 0.8572745354873151, 0.0, 0.03858792204402117, 0.004744245124392532, 1.0, 0.0, 0.10158538935168482, 0.14822776636731771, 0.08205817541659854, 0.06307542003573566, 0.059189446644105415, 0.06568607526991788]]\n",
            "203812\n",
            "['1']\n",
            "203812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uL1FAaxCxMm",
        "colab_type": "text"
      },
      "source": [
        "### Remove redundant data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4J19cJ1_k_8",
        "colab_type": "code",
        "outputId": "1a084cd0-4218-4502-c0f0-25850896e69a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "source": [
        "#239637\n",
        "#269977\n",
        "\n",
        "def remove_useless_inputs(inputList, outputList):\n",
        "  resultInput = []\n",
        "  resultOutput = []\n",
        "  for i in range (0, len(inputList)):\n",
        "    nancount = 0\n",
        "    for val in range(0, len(inputList[i])):\n",
        "      if str(inputList[i:i+1][0][val]) == 'nan': \n",
        "        nancount += 1\n",
        "#     if nancount < len(inputList[i:i+1][0]): \n",
        "    if nancount < 1:\n",
        "      resultInput.append(inputList[i])\n",
        "      resultOutput.append(outputList[i])\n",
        "      \n",
        "  return resultInput, resultOutput\n",
        "\n",
        "newtrainInput, newtrainTarget = remove_useless_inputs(trainInput, trainTarget)\n",
        "newvalInput, newvalTarget = remove_useless_inputs(valInput, valTarget)\n",
        "\n",
        "\n",
        "print(newtrainInput[0:1])\n",
        "print(len(newtrainInput))\n",
        "print(newtrainTarget[0:1])\n",
        "print(len(newtrainTarget))\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.6266094420600858, 0.0, 1.0, 1.0, 0.34375, 0.31240748946329217, 0.5576036866359447, 0.6783756964730511, 0.0, 0.9510436137950052, 0.9728392032627367, 0.8090134217422564, 0.5925815391975805, 0.41227896032476175, 0.6718085284562461, 0.6737492896064494, 0.6592660515892512, 0.004701086719940492, 0.5788255341606938, 0.5857316015590015]]\n",
            "269977\n",
            "['NaN']\n",
            "269977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfihFidpCu6B",
        "colab_type": "code",
        "outputId": "81f6f1da-792b-490b-cd8c-efdf4ed4d016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        }
      },
      "source": [
        "# 239635\n",
        "# 253107\n",
        "\n",
        "def remove_useless_outputs(inputList, outputList):\n",
        "  resultInput = []\n",
        "  resultOutput = []\n",
        "  for i in range (0, len(outputList)):\n",
        "    if str(outputList[i:i+1][0]).lower() != 'nan': \n",
        "      resultInput.append(inputList[i])\n",
        "      resultOutput.append(outputList[i])\n",
        "   \n",
        "  if isinstance(resultOutput[0:1][0], str):\n",
        "    for x in range (0, len(resultOutput)):\n",
        "      resultOutput[x:x+1] = list(map(int, resultOutput[x:x+1][0]))\n",
        "  print(type(resultOutput[0:1][0]))\n",
        "\n",
        "  print(type(resultOutput[0:1][0]))\n",
        "  return resultInput, resultOutput\n",
        "\n",
        "trainInput, trainTarget = remove_useless_outputs(newtrainInput, newtrainTarget)\n",
        "valInput, valTarget = remove_useless_outputs(newvalInput, newvalTarget)\n",
        "\n",
        "print(trainInput[0:1])\n",
        "print(len(trainInput))\n",
        "print(trainTarget[0:1])\n",
        "print(len(trainTarget))\n",
        "\n",
        "print(type(trainTarget[0:1]))\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'int'>\n",
            "<class 'int'>\n",
            "<class 'int'>\n",
            "<class 'int'>\n",
            "[[0.4206008583690983, 0.0, 0.0, 0.016949152542372836, 0.34375, 0.004103115052819423, 0.029894836346449252, 0.06642156657878392, 0.3426453288858133, 0.2172412141196171, 0.03628932832862389, 0.061663071180665746, 0.04260140338677475, 0.05126299467180209, 0.01314157250900961, 0.013696510238872937, 0.01398609300982583, 0.003332803768337687, 0.022360756449336678, 0.010628580546095837]]\n",
            "253107\n",
            "[0]\n",
            "253107\n",
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mUBGafrC5PO",
        "colab_type": "text"
      },
      "source": [
        "### Reshaping data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PHQ90cpu0t1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "ab145e74-bf5e-4075-f0bc-5b7134509201"
      },
      "source": [
        "# Conversion to numpy array for improved memory, performance and functionality\n",
        "trainInput, trainTarget = np.array(trainInput), np.array(trainTarget)\n",
        "valInput, valTarget = np.array(valInput), np.array(valTarget)\n",
        "\n",
        "print(trainInput[0:1])\n",
        "\n",
        "print(trainInput.shape[0])\n",
        "print(trainInput.shape[1])\n",
        "\n",
        "trainInput = np.reshape(trainInput, (trainInput.shape[0], trainInput.shape[1], 1))\n",
        "valInput = np.reshape(valInput, (valInput.shape[0], valInput.shape[1], 1))\n",
        "\n",
        "print(trainInput[0:1])\n",
        "\n",
        "print(trainInput.shape[0])\n",
        "print(trainInput.shape[1])\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.42060086 0.         0.         0.01694915 0.34375    0.00410312\n",
            "  0.02989484 0.06642157 0.34264533 0.21724121 0.03628933 0.06166307\n",
            "  0.0426014  0.05126299 0.01314157 0.01369651 0.01398609 0.0033328\n",
            "  0.02236076 0.01062858]]\n",
            "253107\n",
            "20\n",
            "[[[0.42060086]\n",
            "  [0.        ]\n",
            "  [0.        ]\n",
            "  [0.01694915]\n",
            "  [0.34375   ]\n",
            "  [0.00410312]\n",
            "  [0.02989484]\n",
            "  [0.06642157]\n",
            "  [0.34264533]\n",
            "  [0.21724121]\n",
            "  [0.03628933]\n",
            "  [0.06166307]\n",
            "  [0.0426014 ]\n",
            "  [0.05126299]\n",
            "  [0.01314157]\n",
            "  [0.01369651]\n",
            "  [0.01398609]\n",
            "  [0.0033328 ]\n",
            "  [0.02236076]\n",
            "  [0.01062858]]]\n",
            "253107\n",
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB3brZVQZFM7",
        "colab_type": "text"
      },
      "source": [
        "# Network Implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5CxNAYlLG_S",
        "colab_type": "text"
      },
      "source": [
        "## Core Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOVq6YexKjxU",
        "colab_type": "text"
      },
      "source": [
        "### Single Output LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlqU_UHBkfJz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 906
        },
        "outputId": "6bc0635e-a1f1-45fb-c179-0a98f95f10bc"
      },
      "source": [
        "data_dim = trainInput.shape[1]\n",
        "timesteps = trainInput.shape[0]\n",
        "\n",
        "# Sample Code\n",
        "# model parameters:\n",
        "\n",
        "def create_model(train_X, train_Y, data_dim):\n",
        "  lstm_units = 128\n",
        "  \n",
        "#   print('Build baseline binary model...')\n",
        "#   model = Sequential()\n",
        "#   model.add(Masking(mask_value=0., input_shape=(data_dim, 1)))\n",
        "#   model.add(LSTM(lstm_units))\n",
        "#   model.add(Dense(1))\n",
        "#   model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  \n",
        "  \n",
        "  print('Build stacked binary model')\n",
        "  model = Sequential()\n",
        "  model.add(Masking(mask_value=0., input_shape=(data_dim, 1)))\n",
        "  model.add(LSTM(lstm_units, return_sequences=True))\n",
        "  model.add(Dropout(rate=0.2))\n",
        "  model.add(LSTM(lstm_units, return_sequences=True))\n",
        "  model.add(Dropout(rate=0.2))\n",
        "\n",
        "  model.add(LSTM(lstm_units))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  \n",
        "  #   model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return(model)\n",
        "\n",
        "  \n",
        "baseline_model = create_model(trainInput, trainTarget, data_dim)\n",
        "SVG(model_to_dot(baseline_model, show_shapes=True).create(prog='dot', format='svg'))\n",
        "\n",
        "baseline_model.summary()\n",
        "baseline_model.fit(trainInput, trainTarget, epochs = 100, batch_size = 256, verbose = 1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build stacked binary model\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "masking_1 (Masking)          (None, 20, 1)             0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 20, 128)           66560     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 20, 128)           131584    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 20, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 329,857\n",
            "Trainable params: 329,857\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            " 13056/253107 [>.............................] - ETA: 9:23 - loss: 0.8192 - acc: 0.4974"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-152100d274aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mbaseline_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mbaseline_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6lAccHrKrx3",
        "colab_type": "text"
      },
      "source": [
        "### Multi output LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbhiWb-0NDdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dim = trainInput.shape[1]\n",
        "timesteps = trainInput.shape[0]\n",
        "\n",
        "\n",
        "class fypNet: \n",
        "  @staticmethod\n",
        "  def build_input_predictor(inputs, data_dim, lstm_units):\n",
        "    inPred = Masking(mask_value=0., input_shape = (data_dim, 1))(inputs)\n",
        "    inPred = LSTM(lstm_units, return_sequences=True)(inPred)\n",
        "    \n",
        "    inPred = Dense(1)(inPred)\n",
        "    result = Activation('softmax', name= 'inPred_result')(inPred)\n",
        "    \n",
        "    return result\n",
        "    \n",
        "  @staticmethod\n",
        "  def build_output_predictor(inputs, data_dim, lstm_units): \n",
        "    outPred = LSTM(lstm_units, return_sequences=True)(inputs)\n",
        "    outPred = LSTM(lstm_units)(outPred)\n",
        "    \n",
        "    outPred = Dense(1)(outPred)\n",
        "    result = Activation('softmax', name= 'outPred_result')(outPred)\n",
        "\n",
        "    return result\n",
        "  \n",
        "  @staticmethod\n",
        "  def build(data_dim, lstm_units):\n",
        "         \n",
        "    input_shape = (data_dim, 1)\n",
        "    inputs = Input(shape = input_shape)\n",
        "   \n",
        "    inputBranch = fypNet.build_input_predictor(inputs, data_dim, lstm_units)\n",
        "    outputBranch = fypNet.build_output_predictor(inputs, data_dim, lstm_units)\n",
        "    \n",
        "    model = Model(inputs= inputs, outputs= [inputBranch, outputBranch])\n",
        "    \n",
        "    return model\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW6yVBGPUrmk",
        "colab_type": "code",
        "outputId": "a8991933-dda0-47af-ed43-62094fa6bc84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "data_dim = trainInput.shape[1]\n",
        "timesteps = trainInput.shape[0]\n",
        "lstm_units = 1024\n",
        "\n",
        "num_epochs = 10\n",
        "initial_lr = 1e-3\n",
        "batch_size = 32\n",
        "\n",
        "# initialize our fypNet multi-output network\n",
        "model = fypNet.build(data_dim, lstm_units)\n",
        " \n",
        "losses = {'inPred_result': 'mean_absolute_error','outPred_result': 'binary_crossentropy'}\n",
        " \n",
        "# initialize the optimizer and compile the model\n",
        "\n",
        "print('Compiling model...')\n",
        "# opt = Adam(lr=initial_lr, decay=initial_lr/epochs)\n",
        "model.compile(optimizer='adam', loss=losses, metrics=['acc'])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-cc1f0d8c4ea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainInput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtimesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainInput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlstm_units\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trainInput' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiNO04Z3i1cz",
        "colab_type": "code",
        "outputId": "a3b4d0af-8707-48e3-d247-30fe8fa62cd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "# inPred = trainInput.shift(-1)\n",
        "trainInTarget = np.roll(trainInput, -1)\n",
        "trainValTarget = np.roll(valInput, -1)\n",
        "\n",
        "# print(inPred.head())\n",
        "model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 20, 1)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "masking_3 (Masking)             (None, 20, 1)        0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_8 (LSTM)                   (None, 20, 128)      66560       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_7 (LSTM)                   (None, 20, 128)      66560       masking_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_9 (LSTM)                   (None, 128)          131584      lstm_8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 20, 1)        129         lstm_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            129         lstm_9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "inPred_result (Activation)      (None, 20, 1)        0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "outPred_result (Activation)     (None, 1)            0           dense_5[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 264,962\n",
            "Trainable params: 264,962\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCxvCk7J3XQa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "outputId": "379b0b90-03eb-4a3f-dd07-403170554198"
      },
      "source": [
        "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"387pt\" viewBox=\"0.00 0.00 635.50 387.00\" width=\"636pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 383)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-383 631.5,-383 631.5,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139828254680848 -->\n<g class=\"node\" id=\"node1\">\n<title>139828254680848</title>\n<polygon fill=\"none\" points=\"183,-332.5 183,-378.5 469,-378.5 469,-332.5 183,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249.5\" y=\"-351.8\">input_2: InputLayer</text>\n<polyline fill=\"none\" points=\"316,-332.5 316,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"345\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"316,-355.5 374,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"345\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"374,-332.5 374,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421.5\" y=\"-363.3\">(None, 20, 1)</text>\n<polyline fill=\"none\" points=\"374,-355.5 469,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421.5\" y=\"-340.3\">(None, 20, 1)</text>\n</g>\n<!-- 139828254681688 -->\n<g class=\"node\" id=\"node2\">\n<title>139828254681688</title>\n<polygon fill=\"none\" points=\"31.5,-249.5 31.5,-295.5 322.5,-295.5 322.5,-249.5 31.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"100.5\" y=\"-268.8\">masking_3: Masking</text>\n<polyline fill=\"none\" points=\"169.5,-249.5 169.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"169.5,-272.5 227.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"227.5,-249.5 227.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"275\" y=\"-280.3\">(None, 20, 1)</text>\n<polyline fill=\"none\" points=\"227.5,-272.5 322.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"275\" y=\"-257.3\">(None, 20, 1)</text>\n</g>\n<!-- 139828254680848&#45;&gt;139828254681688 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139828254680848-&gt;139828254681688</title>\n<path d=\"M284.4952,-332.3799C266.8092,-322.5279 246.0142,-310.9442 227.4507,-300.6034\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"228.9797,-297.4488 218.5404,-295.6399 225.5732,-303.564 228.9797,-297.4488\" stroke=\"#000000\"/>\n</g>\n<!-- 139828245812280 -->\n<g class=\"node\" id=\"node3\">\n<title>139828245812280</title>\n<polygon fill=\"none\" points=\"342,-249.5 342,-295.5 612,-295.5 612,-249.5 342,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"393\" y=\"-268.8\">lstm_8: LSTM</text>\n<polyline fill=\"none\" points=\"444,-249.5 444,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"473\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"444,-272.5 502,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"473\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"502,-249.5 502,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"557\" y=\"-280.3\">(None, 20, 1)</text>\n<polyline fill=\"none\" points=\"502,-272.5 612,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"557\" y=\"-257.3\">(None, 20, 128)</text>\n</g>\n<!-- 139828254680848&#45;&gt;139828245812280 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139828254680848-&gt;139828245812280</title>\n<path d=\"M368.0619,-332.3799C386.0668,-322.4832 407.2511,-310.8388 426.1285,-300.4625\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"427.8246,-303.5241 434.902,-295.6399 424.4527,-297.3898 427.8246,-303.5241\" stroke=\"#000000\"/>\n</g>\n<!-- 139828254681632 -->\n<g class=\"node\" id=\"node4\">\n<title>139828254681632</title>\n<polygon fill=\"none\" points=\"39,-166.5 39,-212.5 309,-212.5 309,-166.5 39,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"90\" y=\"-185.8\">lstm_7: LSTM</text>\n<polyline fill=\"none\" points=\"141,-166.5 141,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"141,-189.5 199,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"199,-166.5 199,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"254\" y=\"-197.3\">(None, 20, 1)</text>\n<polyline fill=\"none\" points=\"199,-189.5 309,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"254\" y=\"-174.3\">(None, 20, 128)</text>\n</g>\n<!-- 139828254681688&#45;&gt;139828254681632 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139828254681688-&gt;139828254681632</title>\n<path d=\"M176.1643,-249.3799C175.8678,-241.1745 175.5278,-231.7679 175.2065,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"178.7006,-222.651 174.8416,-212.784 171.7052,-222.9039 178.7006,-222.651\" stroke=\"#000000\"/>\n</g>\n<!-- 139828245389832 -->\n<g class=\"node\" id=\"node5\">\n<title>139828245389832</title>\n<polygon fill=\"none\" points=\"342,-166.5 342,-212.5 612,-212.5 612,-166.5 342,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"393\" y=\"-185.8\">lstm_9: LSTM</text>\n<polyline fill=\"none\" points=\"444,-166.5 444,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"473\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"444,-189.5 502,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"473\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"502,-166.5 502,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"557\" y=\"-197.3\">(None, 20, 128)</text>\n<polyline fill=\"none\" points=\"502,-189.5 612,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"557\" y=\"-174.3\">(None, 128)</text>\n</g>\n<!-- 139828245812280&#45;&gt;139828245389832 -->\n<g class=\"edge\" id=\"edge4\">\n<title>139828245812280-&gt;139828245389832</title>\n<path d=\"M477,-249.3799C477,-241.1745 477,-231.7679 477,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"480.5001,-222.784 477,-212.784 473.5001,-222.784 480.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139828250379432 -->\n<g class=\"node\" id=\"node6\">\n<title>139828250379432</title>\n<polygon fill=\"none\" points=\"30.5,-83.5 30.5,-129.5 305.5,-129.5 305.5,-83.5 30.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"84\" y=\"-102.8\">dense_4: Dense</text>\n<polyline fill=\"none\" points=\"137.5,-83.5 137.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"137.5,-106.5 195.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"166.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"195.5,-83.5 195.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250.5\" y=\"-114.3\">(None, 20, 128)</text>\n<polyline fill=\"none\" points=\"195.5,-106.5 305.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250.5\" y=\"-91.3\">(None, 20, 1)</text>\n</g>\n<!-- 139828254681632&#45;&gt;139828250379432 -->\n<g class=\"edge\" id=\"edge5\">\n<title>139828254681632-&gt;139828250379432</title>\n<path d=\"M172.3287,-166.3799C171.7355,-158.1745 171.0555,-148.7679 170.4129,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"173.8952,-139.5056 169.6832,-129.784 166.9134,-140.0104 173.8952,-139.5056\" stroke=\"#000000\"/>\n</g>\n<!-- 139828244082872 -->\n<g class=\"node\" id=\"node7\">\n<title>139828244082872</title>\n<polygon fill=\"none\" points=\"352,-83.5 352,-129.5 604,-129.5 604,-83.5 352,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"405.5\" y=\"-102.8\">dense_5: Dense</text>\n<polyline fill=\"none\" points=\"459,-83.5 459,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"488\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"459,-106.5 517,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"488\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"517,-83.5 517,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"560.5\" y=\"-114.3\">(None, 128)</text>\n<polyline fill=\"none\" points=\"517,-106.5 604,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"560.5\" y=\"-91.3\">(None, 1)</text>\n</g>\n<!-- 139828245389832&#45;&gt;139828244082872 -->\n<g class=\"edge\" id=\"edge6\">\n<title>139828245389832-&gt;139828244082872</title>\n<path d=\"M477.2786,-166.3799C477.3774,-158.1745 477.4907,-148.7679 477.5978,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"481.0986,-139.8255 477.7195,-129.784 474.0992,-139.7411 481.0986,-139.8255\" stroke=\"#000000\"/>\n</g>\n<!-- 139828249401160 -->\n<g class=\"node\" id=\"node8\">\n<title>139828249401160</title>\n<polygon fill=\"none\" points=\"0,-.5 0,-46.5 312,-46.5 312,-.5 0,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"79.5\" y=\"-19.8\">inPred_result: Activation</text>\n<polyline fill=\"none\" points=\"159,-.5 159,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"159,-23.5 217,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"217,-.5 217,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264.5\" y=\"-31.3\">(None, 20, 1)</text>\n<polyline fill=\"none\" points=\"217,-23.5 312,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264.5\" y=\"-8.3\">(None, 20, 1)</text>\n</g>\n<!-- 139828250379432&#45;&gt;139828249401160 -->\n<g class=\"edge\" id=\"edge7\">\n<title>139828250379432-&gt;139828249401160</title>\n<path d=\"M164.6573,-83.3799C163.471,-75.1745 162.111,-65.7679 160.8258,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"164.2613,-56.1803 159.3664,-46.784 157.3334,-57.1819 164.2613,-56.1803\" stroke=\"#000000\"/>\n</g>\n<!-- 139828240317912 -->\n<g class=\"node\" id=\"node9\">\n<title>139828240317912</title>\n<polygon fill=\"none\" points=\"330.5,-.5 330.5,-46.5 627.5,-46.5 627.5,-.5 330.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"414\" y=\"-19.8\">outPred_result: Activation</text>\n<polyline fill=\"none\" points=\"497.5,-.5 497.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"526.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"497.5,-23.5 555.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"526.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"555.5,-.5 555.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"591.5\" y=\"-31.3\">(None, 1)</text>\n<polyline fill=\"none\" points=\"555.5,-23.5 627.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"591.5\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 139828244082872&#45;&gt;139828240317912 -->\n<g class=\"edge\" id=\"edge8\">\n<title>139828244082872-&gt;139828240317912</title>\n<path d=\"M478.2786,-83.3799C478.3774,-75.1745 478.4907,-65.7679 478.5978,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"482.0986,-56.8255 478.7195,-46.784 475.0992,-56.7411 482.0986,-56.8255\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYXPMKKzL1eL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "1841bc13-7710-461d-cf7c-16844f5a05ae"
      },
      "source": [
        "model.fit(trainInput,{\"inPred_result\": trainInTarget, \"outPred_result\": trainTarget}, validation_data=(valInput, {\"inPred_result\": trainValTarget, \"outPred_result\": valTarget}), batch_size = batch_size, epochs=num_epochs, verbose=1)\n",
        "# Input prediction is the input vector shifted by 1"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 253107 samples, validate on 103072 samples\n",
            "Epoch 1/30\n",
            " 31296/253107 [==>...........................] - ETA: 14:29 - loss: 8.6516 - inPred_result_loss: 0.5235 - outPred_result_loss: 8.1281 - inPred_result_acc: 0.0118 - outPred_result_acc: 0.4902"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-ce7aabc2e318>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"inPred_result\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainInTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"outPred_result\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainTarget\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"inPred_result\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainValTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"outPred_result\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalTarget\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Input prediction is the input vector shifted by 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdfWnWD_Ltfs",
        "colab_type": "text"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBvqxci1kVZn",
        "colab_type": "text"
      },
      "source": [
        "# Benchmark\n",
        "\n"
      ]
    }
  ]
}