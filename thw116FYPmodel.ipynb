{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "thw116FYPmodel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIU13nThWPq4",
        "colab_type": "code",
        "outputId": "e60d7c30-eb43-4d64-c9b6-2b517e5ec05c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
        "from scipy import stats\n",
        "\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Activation, Dense, LSTM, Dropout, Masking, Input\n",
        "from keras import optimizers\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "from IPython.display import SVG\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oerk0UaY0wG",
        "colab_type": "text"
      },
      "source": [
        "# Initial Data Importation and Structuring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-vX5NnVkai6",
        "colab_type": "text"
      },
      "source": [
        "## Accessing and loading data from Google Drive \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtzJiK3GZxwf",
        "colab_type": "code",
        "outputId": "a99b469f-1b0a-4bc6-f8c8-7bd5adca1ebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# mounting Google Drive which contains the relevant data\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKuXkHkNWbSS",
        "colab_type": "code",
        "outputId": "14da0e32-0bd9-48bf-9e47-32aae9cf6854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "# Fundamental input data\n",
        "ltm_book = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ltm_book.csv')\n",
        "ltm_div = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ltm_div.csv')\n",
        "ltm_ebit = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ltm_ebit.csv')\n",
        "ltm_eps = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ltm_eps.csv')\n",
        "ltm_fcf = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ltm_fcf.csv')\n",
        "ltm_pbook = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ltm_pbook.csv')\n",
        "ltm_sales = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ltm_sales.csv')\n",
        "\n",
        "ntm_book = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ntm_book.csv')\n",
        "ntm_div = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ntm_div.csv')\n",
        "ntm_ebit = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ntm_ebit.csv')\n",
        "ntm_eps = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ntm_eps.csv')\n",
        "ntm_fcf = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ntm_fcf.csv')\n",
        "ntm_pbook = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ntm_pbook.csv')\n",
        "ntm_sales = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/ntm_sales.csv')\n",
        "\n",
        "# Technical input data\n",
        "\n",
        "price_high = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/price_high.csv')\n",
        "price_low = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/price_low.csv')\n",
        "price_open = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/price_open.csv')\n",
        "volume = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/volume.csv')\n",
        "enterprise_val = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/enterprise_val.csv')\n",
        "market_cap = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/market_cap.csv')\n",
        "\n",
        "print(ltm_book.head())\n",
        "print(\"**************************************\")\n",
        "print(ltm_book.info())\n",
        "\n",
        "# Price target output data\n",
        "\n",
        "price_close = pd.read_csv('/content/drive/My Drive/thw116_FYP/data/price_close.csv')\n",
        "\n",
        "print(price_close.head())\n",
        "print(\"**************************************\")\n",
        "print(price_close.info())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Unnamed: 0  ATRS AV  ESSR LN  ...  FABGB SS  926002Q GY  NDA SS\n",
            "0           1      NaN      NaN  ...       NaN         NaN     NaN\n",
            "1           2      NaN      NaN  ...       NaN         NaN     NaN\n",
            "2           3      NaN      NaN  ...       NaN         NaN     NaN\n",
            "3           4      NaN      NaN  ...       NaN         NaN     NaN\n",
            "4           5      NaN      NaN  ...       NaN         NaN     NaN\n",
            "\n",
            "[5 rows x 1185 columns]\n",
            "**************************************\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6313 entries, 0 to 6312\n",
            "Columns: 1185 entries, Unnamed: 0 to NDA SS\n",
            "dtypes: float64(1184), int64(1)\n",
            "memory usage: 57.1 MB\n",
            "None\n",
            "   Unnamed: 0  PAYS LN  CNHI IM     SGSN SW  ...  AMS SM  FER SM  SEV FP    FKI LN\n",
            "0  1995-01-03      NaN      NaN  222.552843  ...     NaN     NaN     NaN  1.896782\n",
            "1  1995-01-04      NaN      NaN  226.835424  ...     NaN     NaN     NaN  1.883390\n",
            "2  1995-01-05      NaN      NaN  228.312320  ...     NaN     NaN     NaN  1.910292\n",
            "3  1995-01-06      NaN      NaN  228.015450  ...     NaN     NaN     NaN  1.923861\n",
            "4  1995-01-09      NaN      NaN  228.680128  ...     NaN     NaN     NaN  1.925099\n",
            "\n",
            "[5 rows x 204 columns]\n",
            "**************************************\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6313 entries, 0 to 6312\n",
            "Columns: 204 entries, Unnamed: 0 to FKI LN\n",
            "dtypes: float64(203), object(1)\n",
            "memory usage: 9.8+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM8LCiFbCWVG",
        "colab_type": "text"
      },
      "source": [
        "##Restructuring and Standardising the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwQDmx99oPzr",
        "colab_type": "code",
        "outputId": "94eccac5-2a95-49bd-a3c4-cf0b41a94206",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "# Filtering incorrect datasets to suitable company subsets\n",
        "industrials_subset = price_close.columns.values.tolist()\n",
        "\n",
        "ltm_inputs = [ltm_book, ltm_div, ltm_ebit, ltm_eps, ltm_fcf, ltm_pbook, ltm_sales] \n",
        "ntm_inputs = [ntm_book, ntm_div, ntm_ebit, ntm_eps, ntm_fcf, ntm_pbook, ntm_sales]\n",
        "tech_inputs = [price_high, price_low, price_open, volume, enterprise_val, market_cap]\n",
        "\n",
        "for i in range(0,len(ltm_inputs)):\n",
        "  ltm_inputs[i] = ltm_inputs[i].loc[:, ltm_inputs[i].columns.str.contains('|'.join(industrials_subset))]\n",
        "  ltm_inputs[i]['Unnamed: 0'] = price_close['Unnamed: 0']\n",
        "  ltm_inputs[i].rename( columns={'Unnamed: 0':'Date'}, inplace=True )\n",
        "\n",
        "for i in range(0,len(ntm_inputs)):\n",
        "  ntm_inputs[i] = ntm_inputs[i].loc[:, ntm_inputs[i].columns.str.contains('|'.join(industrials_subset))]\n",
        "  ntm_inputs[i]['Unnamed: 0'] = price_close['Unnamed: 0']\n",
        "  ntm_inputs[i].rename( columns={'Unnamed: 0':'Date'}, inplace=True )\n",
        "\n",
        "for i in range(0,len(tech_inputs)):\n",
        "  tech_inputs[i] = tech_inputs[i].loc[:, tech_inputs[i].columns.str.contains('|'.join(industrials_subset))]\n",
        "  tech_inputs[i]['Unnamed: 0'] = price_close['Unnamed: 0']\n",
        "  tech_inputs[i].rename( columns={'Unnamed: 0':'Date'}, inplace=True )\n",
        "\n",
        "  \n",
        "price_close.rename( columns={'Unnamed: 0':'Date'}, inplace=True )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhYPF4OmJOwm",
        "colab_type": "text"
      },
      "source": [
        "## Data Wrangling\n",
        "\n",
        "In order to produce a dataframe suitable for the model, we must first take the raw *Price.csv*  file and convert it to returns. This can then be maniuplated further in a variety of ways to achieve the neccessary classification for variants of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHv1OtsgCC2C",
        "colab_type": "text"
      },
      "source": [
        "###Date Index Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcygJ5YtWP8H",
        "colab_type": "code",
        "outputId": "b61b5afa-3466-40ad-c464-b0445a3449ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Conversion of TimeAndDate column to DatetimeIndex for ease of use\n",
        "\n",
        "def time_index_generator(dataframe):\n",
        "  dataframe['Date'] = pd.to_datetime(dataframe['Date'], dayfirst=True)\n",
        "  dataframe.set_index('Date', inplace=True)\n",
        "\n",
        "\n",
        "for i in range(0,len(ltm_inputs)):\n",
        "  time_index_generator(ltm_inputs[i])\n",
        "for i in range(0,len(ntm_inputs)):\n",
        "  time_index_generator(ntm_inputs[i])\n",
        "for i in range(0,len(tech_inputs)):\n",
        "  time_index_generator(tech_inputs[i])  \n",
        "\n",
        "time_index_generator(price_close)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5fWXKHjLpzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check all columns align correctly\n",
        "print(ltm_inputs[0].columns.difference(price_close.columns))\n",
        "print(ltm_inputs[1].columns.difference(price_close.columns))\n",
        "print(ltm_inputs[2].columns.difference(price_close.columns))\n",
        "print(ltm_inputs[3].columns.difference(price_close.columns))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhIWXVtzB5co",
        "colab_type": "text"
      },
      "source": [
        "###Ticker Anonymisation \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCGMHTY0zA7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check that all tickers in the set match\n",
        "\n",
        "# Helper function to generate ticker list\n",
        "def ticker_list_generator(num):\n",
        "  ticker_list = []\n",
        "  for i in range(0, num):\n",
        "    ticker_name = 'Ticker ' + str(i+1)\n",
        "    ticker_list.append(ticker_name)\n",
        "  return ticker_list\n",
        "\n",
        "anon_tickers = ticker_list_generator(len(ltm_inputs[0].columns))\n",
        "\n",
        "for i in range(0,len(ltm_inputs)):\n",
        "  ltm_inputs[0].columns = anon_tickers\n",
        "for i in range(0,len(ntm_inputs)):\n",
        "  ntm_inputs[0].columns = anon_tickers\n",
        "for i in range(0,len(tech_inputs)):\n",
        "  tech_inputs[0].columns = anon_tickers\n",
        "\n",
        "price_close.columns = anon_tickers\n",
        "\n",
        "# # Selecting a Ticker and plotting\n",
        "\n",
        "# ltm_inputs[0]['Ticker 1'].plot(figsize=(16,6))\n",
        "# plt.title('ltm_book - Ticker 1')\n",
        "# plt.xlabel('Date')\n",
        "# plt.ylabel('Attribute')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3bt2ejCCjYr",
        "colab_type": "text"
      },
      "source": [
        "###Price to Returns Converter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gep9h1FNHQJ0",
        "colab_type": "code",
        "outputId": "c090e1ec-c68e-4738-b9e3-21d7154d8cdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Converting Price format to returns format\n",
        "def price_to_returns(timeframe, dataframe):\n",
        "  if timeframe == 'daily':\n",
        "    return dataframe.pct_change(1) # remember to discount all target variables that are NaN\n",
        "  \n",
        "  if timeframe == 'monthly':\n",
        "    return dataframe.resample('BM')\n",
        "  \n",
        "returns = price_to_returns('daily', price_close) \n",
        "\n",
        "print(returns.head(2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Ticker 1  Ticker 2  Ticker 3  ...  Ticker 201  Ticker 202  Ticker 203\n",
            "Date                                      ...                                    \n",
            "1995-01-03       NaN       NaN       NaN  ...         NaN         NaN         NaN\n",
            "1995-01-04       NaN       NaN  0.019243  ...         NaN         NaN    -0.00706\n",
            "\n",
            "[2 rows x 203 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guJycK9f5Z1E",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "Several steps are taken in order to structure the data so that it can be proccessed by the model.\n",
        "\n",
        "1.   Data Analysis and Cleaning: Data is analysed for missing values, its properties, smoothed for various time intervals and resolved of any inconsistencies.  \n",
        "\n",
        "2. Training-Test Split: Data is divided into training and test splits according to a selected parameter value. \n",
        "\n",
        "3.  Data Transformation: Data is normalised, aggregated and generalised, both for training and testing\n",
        "\n",
        "4. Data Integration: Data is merged together appropriately to form the input shape of the model.   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfuTGvzQKPue",
        "colab_type": "text"
      },
      "source": [
        "##Data Analysis\n",
        "\n",
        "Something to consider is the fact that returns are more likely to correlate with changes in fundamentals rather than the absolute values of fundamentals. However, there is likely to be a disceprancy in the rate of change of fundamentals and the change in prices. Fundamentals are often only declared quarterly whereas prices are subject to daily fluctuations. We will first analyse the number of times a fundamental changes relative to the price changes. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-Drzbr-Blq1",
        "colab_type": "text"
      },
      "source": [
        "###Stastical Summaries of Data Count and Boxplots\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqP4Ys_6c7vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# statistical summary of datasets\n",
        "print(tech_inputs[0].describe())\n",
        "\n",
        "# Box plot of dataset's datapoints count\n",
        "tech_inputs[0].count().plot(kind='box', showmeans = True) \n",
        "plt.xlabel('Technical inputs')\n",
        "plt.tight_layout() \n",
        "plt.show()\n",
        "\n",
        "# plt.savefig('tech_box.png')\n",
        "# files.download('tech_box.png') \n",
        "\n",
        "# Individual tickers' datapoint count bar graph\n",
        "\n",
        "# ltm_inputs[0.count().plot(kind='barh', figsize=(20,20)) \n",
        "# plt.xlabel('LTM input')\n",
        "# plt.tight_layout() \n",
        "# plt.show()\n",
        "\n",
        "# plt.savefig('ltmTickerCount.png')\n",
        "# files.download('ltmTickerCount.png') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsXsCknQBv-l",
        "colab_type": "text"
      },
      "source": [
        "###Stastical Summaries of Delta Data Count and Boxplots\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO_BJonjhHVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_change(dataframe, column): \n",
        "  noChange_count = 0\n",
        "  NaN_count = 0\n",
        "  for i in range (0, len(dataframe.index)): \n",
        "    if dataframe[column].diff().iloc[i] == 0:\n",
        "      noChange_count += 1\n",
        "    if dataframe[column].isna().iloc[i]: \n",
        "      NaN_count += 1\n",
        "  \n",
        "#   print('Total rows: ', len(dataframe[column]))\n",
        "#   print('The number of rows where no change occurs: ', noChange_count)\n",
        "#   print('The number of rows which are NaN: ', NaN_count)\n",
        "#   print('Useful datapoints:', (len(dataframe[column])-noChange_count-NaN_count))\n",
        "\n",
        "  return len(dataframe[column])-noChange_count-NaN_count\n",
        "\n",
        "delta_change = []\n",
        "\n",
        "for companies in range(0, tech_inputs[0].shape[1]):\n",
        "  delta_val = data_change(tech_inputs[0], anon_tickers[companies])\n",
        "  delta_change.append(delta_val)\n",
        "  \n",
        "plt.boxplot(delta_change, showmeans = True)\n",
        "plt.xlabel('Technical inputs')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pzH6OYHsBTw",
        "colab_type": "text"
      },
      "source": [
        "### Returns distribution plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43HmoKYKr_q1",
        "colab_type": "code",
        "outputId": "40aa48df-3dab-450b-c8fc-5874ff0c334c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1080
        }
      },
      "source": [
        "# Plotting the distributions of the returns datapoints. \n",
        "\n",
        "allreturns = returns.stack(dropna=False).reset_index(drop=True).to_frame('Returns Plot')\n",
        "allreturns.hist(range=(-0.2,0.2), figsize=(16,8), bins=200)\n",
        "\n",
        "allreturns = np.log(allreturns) \n",
        "allreturns.hist(range=(-10,0), figsize=(16,8), bins=200)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in log\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f765e1fc240>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7sAAAHiCAYAAAAphNvgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n15MKRqDeuwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA64AAAHiCAYAAADoA5FMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAXRNcAQAA6Nr/B6vbTHYtCvqhAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY93g3OxY7uf",
        "colab_type": "text"
      },
      "source": [
        "## Data Snipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtPwvxIHJYUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Entire dataset\n",
        "# for i in range(0,len(ltm_inputs)):\n",
        "#   ltm_inputs[i] = ltm_inputs[i].loc[ltm_inputs[i].index > pd.to_datetime('2000-1-1')]\n",
        "\n",
        "# for i in range(0,len(ntm_inputs)):\n",
        "#   ntm_inputs[i] = ntm_inputs[i].loc[ntm_inputs[i].index > pd.to_datetime('2000-1-1')]\n",
        "\n",
        "# for i in range(0,len(tech_inputs)):\n",
        "#   tech_inputs[i] = tech_inputs[i].loc[tech_inputs[i].index > pd.to_datetime('2000-1-1')]\n",
        "  \n",
        "# returns = returns.loc[returns.index > pd.to_datetime('2000-1-1')]\n",
        "\n",
        "\n",
        "# Reduced subset for faster training and testing\n",
        "\n",
        "for i in range(0,len(ltm_inputs)):\n",
        "  ltm_inputs[i] = ltm_inputs[i].loc[ltm_inputs[i].index > pd.to_datetime('2010-1-1')]\n",
        "\n",
        "for i in range(0,len(ntm_inputs)):\n",
        "  ntm_inputs[i] = ntm_inputs[i].loc[ntm_inputs[i].index > pd.to_datetime('2010-1-1')]\n",
        "\n",
        "for i in range(0,len(tech_inputs)):\n",
        "  tech_inputs[i] = tech_inputs[i].loc[tech_inputs[i].index > pd.to_datetime('2010-1-1')]\n",
        "  \n",
        "returns = returns.loc[returns.index > pd.to_datetime('2010-1-1')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbrJzj6fJqvv",
        "colab_type": "text"
      },
      "source": [
        "## Data splitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BEO_I7KRqr_",
        "colab_type": "text"
      },
      "source": [
        "### Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yfDmdQJcrPp",
        "colab_type": "code",
        "outputId": "b25a9469-059c-4e62-dea0-62330a93afeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "def training_set(train_percentage, dataframe): \n",
        "  train_size = int(train_percentage*len(dataframe.index)) \n",
        "  train_set = dataframe[:train_size]\n",
        "  return pd.DataFrame(train_set)  \n",
        "\n",
        "training_split = 0.6\n",
        "\n",
        "ltm_trainInputs = []\n",
        "ntm_trainInputs = []\n",
        "tech_trainInputs = []\n",
        "\n",
        "for i in range(0,len(ltm_inputs)):\n",
        "  ltm_trainInputs.append(training_set(training_split, ltm_inputs[i]))\n",
        "  \n",
        "for i in range(0,len(ntm_inputs)):\n",
        "  ntm_trainInputs.append(training_set(training_split, ntm_inputs[i]))\n",
        "\n",
        "for i in range(0,len(tech_inputs)):\n",
        "  tech_trainInputs.append(training_set(training_split, tech_inputs[i]))\n",
        "\n",
        "returns_trainOutput = training_set(training_split, returns)\n",
        "\n",
        "print(ntm_trainInputs[0].info())\n",
        "print(returns_trainOutput.info())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 1454 entries, 2010-01-04 to 2015-08-13\n",
            "Columns: 203 entries, Ticker 1 to Ticker 203\n",
            "dtypes: float64(203)\n",
            "memory usage: 2.3 MB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 1454 entries, 2010-01-04 to 2015-08-13\n",
            "Columns: 203 entries, Ticker 1 to Ticker 203\n",
            "dtypes: float64(203)\n",
            "memory usage: 2.3 MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47IfciNTutCX",
        "colab_type": "text"
      },
      "source": [
        "### Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ-QTlDF1hOm",
        "colab_type": "code",
        "outputId": "396636bc-a667-42a0-8366-8295d3374e20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "def validation_set(train_percentage, val_percentage, dataframe): \n",
        "  train_size = int(train_percentage*len(dataframe.index)) \n",
        "  val_size = int(val_percentage*len(dataframe.index))\n",
        "  # val_size = len(dataframe.index)-int(train_percentage*len(dataframe.index)) \n",
        "  val_set = dataframe[train_size:(train_size+val_size)]\n",
        "  return pd.DataFrame(val_set)  \n",
        "\n",
        "validation_split = 0.2\n",
        "\n",
        "ltm_valInputs = []\n",
        "ntm_valInputs = []\n",
        "tech_valInputs = []\n",
        "\n",
        "for i in range(0,len(ltm_inputs)):\n",
        "  ltm_valInputs.append(validation_set(training_split, validation_split, ltm_inputs[i]))\n",
        "  \n",
        "for i in range(0,len(ntm_inputs)):\n",
        "  ntm_valInputs.append(validation_set(training_split, validation_split, ntm_inputs[i]))\n",
        "\n",
        "for i in range(0,len(tech_inputs)):\n",
        "  tech_valInputs.append(validation_set(training_split, validation_split, tech_inputs[i]))\n",
        "\n",
        "  \n",
        "returns_valOutput = validation_set(training_split, validation_split, returns)\n",
        "\n",
        "print(ltm_valInputs[0].info())\n",
        "print(returns_valOutput.info())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 484 entries, 2015-08-14 to 2017-06-28\n",
            "Columns: 203 entries, Ticker 1 to Ticker 203\n",
            "dtypes: float64(203)\n",
            "memory usage: 771.4 KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 484 entries, 2015-08-14 to 2017-06-28\n",
            "Columns: 203 entries, Ticker 1 to Ticker 203\n",
            "dtypes: float64(203)\n",
            "memory usage: 771.4 KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYvSLMz9RiA9",
        "colab_type": "text"
      },
      "source": [
        "### Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypx6Ia7uRhjS",
        "colab_type": "code",
        "outputId": "0d7d1c64-3884-4ddc-fa37-743225919f3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "def test_set(train_percentage, val_percentage, dataframe): \n",
        "  test_percentage = 1-train_percentage-val_percentage\n",
        "  train_size = int(train_percentage*len(dataframe.index)) \n",
        "  val_size = int(val_percentage*len(dataframe.index))\n",
        "  # val_size = len(dataframe.index)-int(train_percentage*len(dataframe.index)) \n",
        "  test_set = dataframe[(train_size+val_size):]\n",
        "  return pd.DataFrame(test_set) \n",
        "\n",
        "ltm_testInputs = []\n",
        "ntm_testInputs = []\n",
        "tech_testInputs = []\n",
        "\n",
        "for i in range(0,len(ltm_inputs)):\n",
        "  ltm_testInputs.append(test_set(training_split, validation_split, ltm_inputs[i]))\n",
        "  \n",
        "for i in range(0,len(ntm_inputs)):\n",
        "  ntm_testInputs.append(test_set(training_split, validation_split, ntm_inputs[i]))\n",
        "\n",
        "for i in range(0,len(tech_inputs)):\n",
        "  tech_testInputs.append(test_set(training_split, validation_split, tech_inputs[i]))\n",
        "\n",
        "returns_testOutput = test_set(training_split, validation_split, returns)\n",
        "\n",
        "print(ltm_testInputs[0].info())\n",
        "print(returns_testOutput.info())  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 486 entries, 2017-06-29 to 2019-05-17\n",
            "Columns: 203 entries, Ticker 1 to Ticker 203\n",
            "dtypes: float64(203)\n",
            "memory usage: 774.6 KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 486 entries, 2017-06-29 to 2019-05-17\n",
            "Columns: 203 entries, Ticker 1 to Ticker 203\n",
            "dtypes: float64(203)\n",
            "memory usage: 774.6 KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMx_2j-80Bfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure()\n",
        "fig.set_figheight(28)\n",
        "\n",
        "plt.subplot(4, 1, 1)\n",
        "sns.heatmap(returns_trainOutput.isnull(), cbar=False)\n",
        "\n",
        "plt.subplot(4, 1, 2)\n",
        "sns.heatmap(returns_valOutput.isnull(), cbar=False)\n",
        "\n",
        "plt.subplot(4, 1, 3)\n",
        "sns.heatmap(tech_trainInputs[1].isnull(), cbar=False)\n",
        "\n",
        "plt.subplot(4, 1, 4)\n",
        "sns.heatmap(tech_valInputs[1].isnull(), cbar=False)\n",
        "\n",
        "# plt.savefig('heatmap.png')\n",
        "# files.download('heatmap.png') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U79APBT7JwcE",
        "colab_type": "text"
      },
      "source": [
        "## Input and Output Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfE-0om8FrZz",
        "colab_type": "text"
      },
      "source": [
        "###Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38KlbkcIfOk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_scaling(dataframe):\n",
        "  \n",
        "  # This is the MinMax Scaling function \n",
        "  sc = MinMaxScaler(feature_range = (0, 1))\n",
        "  scaled_input_dataframe = sc.fit_transform(dataframe) # This is now an n-dimensional array type\n",
        "  \n",
        "#   transformer = Normalizer().fit(dataframe)\n",
        "#   Normalizer(copy=True, norm='l2')\n",
        "#   transformer.transform(X)\n",
        "  \n",
        "  return scaled_input_dataframe\n",
        "\n",
        "np.warnings.filterwarnings('ignore', r'All-NaN (slice|axis) encountered')\n",
        "\n",
        "for i in range(0,len(ltm_inputs)):\n",
        "  ltm_trainInputs[i] = input_scaling(ltm_trainInputs[i])\n",
        "  ltm_valInputs[i] = input_scaling(ltm_valInputs[i])\n",
        "  ltm_testInputs[i] = input_scaling(ltm_testInputs[i])\n",
        "  \n",
        "for i in range(0,len(ntm_inputs)):\n",
        "  ntm_trainInputs[i] = input_scaling(ntm_trainInputs[i])\n",
        "  ntm_valInputs[i] = input_scaling(ntm_valInputs[i])\n",
        "  ntm_testInputs[i] = input_scaling(ntm_testInputs[i])\n",
        "\n",
        "for i in range(0,len(tech_inputs)):\n",
        "  tech_trainInputs[i] = input_scaling(tech_trainInputs[i])\n",
        "  tech_valInputs[i] = input_scaling(tech_valInputs[i])\n",
        "  tech_testInputs[i] = input_scaling(tech_testInputs[i])\n",
        "  \n",
        "# sample_input = [ltm_trainInputs[0][1000:1001][0][3],ntm_trainInputs[0][1000:1001][0][3], tech_trainInputs[0][1000:1001][0][3] ]\n",
        "# print(sample_input)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEMQtpS8AGLF",
        "colab_type": "text"
      },
      "source": [
        "### Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6snYzXc-yTv",
        "colab_type": "code",
        "outputId": "860b4e34-17ae-4adf-c3a4-00c5f0471aef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "def output_classifier(type ,dataframe): \n",
        "  \n",
        "  # No adjustments\n",
        "  if type == 'raw':\n",
        "    scaled_dataframe = dataframe\n",
        "  \n",
        "  # Binary classifier where return>0 is +1, and return<0 is 0 labels\n",
        "  if type == 'binary':\n",
        "    pos_returns = dataframe.values > 0\n",
        "    neg_returns = dataframe.values <= 0 \n",
        "    scaled_dataframe = pd.DataFrame(np.select([pos_returns,neg_returns], [1,0], default='NaN'), index=dataframe.index, columns=dataframe.columns)\n",
        "\n",
        "  return scaled_dataframe\n",
        "\n",
        "returns_trainOutput = output_classifier('binary', returns_trainOutput)\n",
        "returns_valOutput = output_classifier('binary', returns_valOutput)\n",
        "\n",
        "raw_testOutput = output_classifier('raw', returns_testOutput)\n",
        "returns_testOutput = output_classifier('binary', returns_testOutput)\n",
        "\n",
        "print (returns_trainOutput.head(2))\n",
        "print (returns_trainOutput.info())\n",
        "\n",
        "print (returns_valOutput.head(2))\n",
        "print (returns_valOutput.info())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in greater\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in less_equal\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "           Ticker 1 Ticker 2 Ticker 3  ... Ticker 201 Ticker 202 Ticker 203\n",
            "Date                                   ...                                 \n",
            "2010-01-04        0        1        1  ...          0          1          0\n",
            "2010-01-05        1        1        0  ...          0          1          0\n",
            "\n",
            "[2 rows x 203 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 1454 entries, 2010-01-04 to 2015-08-13\n",
            "Columns: 203 entries, Ticker 1 to Ticker 203\n",
            "dtypes: object(203)\n",
            "memory usage: 2.3+ MB\n",
            "None\n",
            "           Ticker 1 Ticker 2 Ticker 3  ... Ticker 201 Ticker 202 Ticker 203\n",
            "Date                                   ...                                 \n",
            "2015-08-14        1        0        1  ...          0          0          0\n",
            "2015-08-17        0        0        1  ...          0          1          0\n",
            "\n",
            "[2 rows x 203 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 484 entries, 2015-08-14 to 2017-06-28\n",
            "Columns: 203 entries, Ticker 1 to Ticker 203\n",
            "dtypes: object(203)\n",
            "memory usage: 771.4+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeMN7TE0Ki1P",
        "colab_type": "text"
      },
      "source": [
        "## Data Integration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYKnA5iUAnmG",
        "colab_type": "code",
        "outputId": "e5f59c0d-97a7-4f8e-cca2-ea6e3c8e2996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "trainInput = []\n",
        "trainTarget = []\n",
        "\n",
        "valInput = []\n",
        "valTarget = []\n",
        "\n",
        "testInput = []\n",
        "testTarget = []\n",
        "rawtestTarget = []\n",
        "\n",
        "# Check that the indices are of the same length \n",
        "if len(ltm_trainInputs[0]) != len(returns_trainOutput):\n",
        "  print ('training length', len(ltm_trainInputs[0]))\n",
        "  print ('target length', len(returns_trainOutput))\n",
        "  assert False, \"Incompatible dataframe index lengths!\"\n",
        "\n",
        "# Training Set\n",
        "for company in range(0, len(ltm_trainInputs[0][:1][0])):\n",
        "  \n",
        "  for time_unit in range(0, len(ltm_trainInputs[0])): \n",
        "    input_unit = []\n",
        "    \n",
        "    for ltm_attribute in range(0, len(ltm_trainInputs)): \n",
        "      input_unit.append(ltm_trainInputs[ltm_attribute][time_unit:time_unit+1][0][company])\n",
        "                        \n",
        "    for ntm_attribute in range(0, len(ntm_trainInputs)):\n",
        "      input_unit.append(ntm_trainInputs[ntm_attribute][time_unit:time_unit+1][0][company])\n",
        "                        \n",
        "    for tech_attribute in range(0, len(tech_trainInputs)): \n",
        "      input_unit.append(tech_trainInputs[tech_attribute][time_unit:time_unit+1][0][company])\n",
        "                        \n",
        "    trainInput.append(input_unit)\n",
        "    \n",
        "for company in range(0, len(returns_trainOutput.columns)):\n",
        "  for time_unit in range(0, len(returns_trainOutput.index)): \n",
        "    trainTarget.append(returns_trainOutput[anon_tickers[company]][time_unit])\n",
        "  \n",
        "# Validation Set \n",
        "for company in range(0, len(ltm_valInputs[0][:1][0])):\n",
        "  \n",
        "  for time_unit in range(0, len(ltm_valInputs[0])): \n",
        "    input_unit = []\n",
        "    \n",
        "    for ltm_attribute in range(0, len(ltm_valInputs)): \n",
        "      input_unit.append(ltm_valInputs[ltm_attribute][time_unit:time_unit+1][0][company])\n",
        "                        \n",
        "    for ntm_attribute in range(0, len(ntm_trainInputs)):\n",
        "      input_unit.append(ntm_valInputs[ntm_attribute][time_unit:time_unit+1][0][company])\n",
        "                        \n",
        "    for tech_attribute in range(0, len(tech_trainInputs)): \n",
        "      input_unit.append(tech_valInputs[tech_attribute][time_unit:time_unit+1][0][company])\n",
        "                        \n",
        "    valInput.append(input_unit)\n",
        "    \n",
        "for company in range(0, len(returns_valOutput.columns)):\n",
        "  for time_unit in range(0, len(returns_valOutput.index)): \n",
        "    valTarget.append(returns_valOutput[anon_tickers[company]][time_unit])\n",
        "\n",
        "# Test Set\n",
        "for company in range(0, len(ltm_testInputs[0][:1][0])):\n",
        "  \n",
        "  for time_unit in range(0, len(ltm_testInputs[0])): \n",
        "    input_unit = []\n",
        "    \n",
        "    for ltm_attribute in range(0, len(ltm_testInputs)): \n",
        "      input_unit.append(ltm_testInputs[ltm_attribute][time_unit:time_unit+1][0][company])\n",
        "                        \n",
        "    for ntm_attribute in range(0, len(ntm_testInputs)):\n",
        "      input_unit.append(ntm_testInputs[ntm_attribute][time_unit:time_unit+1][0][company])\n",
        "                        \n",
        "    for tech_attribute in range(0, len(tech_testInputs)): \n",
        "      input_unit.append(tech_testInputs[tech_attribute][time_unit:time_unit+1][0][company])\n",
        "                        \n",
        "    testInput.append(input_unit)\n",
        "    \n",
        "for company in range(0, len(returns_testOutput.columns)):\n",
        "  for time_unit in range(0, len(returns_testOutput.index)): \n",
        "    testTarget.append(returns_testOutput[anon_tickers[company]][time_unit])\n",
        "\n",
        "for company in range(0, len(raw_testOutput.columns)):\n",
        "  for time_unit in range(0, len(raw_testOutput.index)): \n",
        "    rawtestTarget.append(raw_testOutput[anon_tickers[company]][time_unit])\n",
        "\n",
        "print(trainInput[0:1])\n",
        "print(len(trainInput))\n",
        "print(trainTarget[0:1])\n",
        "print(len(trainTarget))\n",
        "\n",
        "print(valInput[0:1])\n",
        "print(len(valInput))\n",
        "print(valTarget[0:1])\n",
        "print(len(valTarget))\n",
        "\n",
        "print(testInput[0:1])\n",
        "print(len(testInput))\n",
        "print(testTarget[0:1])\n",
        "print(len(testTarget))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.3287671232876711, 0.0, 0.0034439322249904397, 0.0, 0.27587890625, 0.024924571101988854, 0.0013178703215603604, 0.023927191685372606, 0.0, 0.16577420722121472, 0.15657919955906302, 0.07080194831886986, 0.06567425221342738, 0.06785172510001797, 0.01701016959638503, 0.022328109127080567, 0.02119637478718763, 7.721563054542674e-05, 0.0011800881756525248, 0.007578283773109033]]\n",
            "295162\n",
            "['0']\n",
            "295162\n",
            "[[0.0, 0.0, 0.006616800920598409, 1.0, 0.0, 1.0, 0.0, 0.0, 0.9782756086911765, 0.0, 0.0, 0.0, 1.0, 0.0, 0.212430052227369, 0.382723829490314, 0.2704902616832283, 0.0561259051719461, 0.23309289364037244, 0.22129841273113016]]\n",
            "98252\n",
            "['1']\n",
            "98252\n",
            "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.03575449848301826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26105637662522807, 0.0964890882613485, 0.0, 0.1188318300971618, 0.05611671045839817, 0.18879781256027162, 0.14282616915785304, 0.006907985192873944, 0.006135475514882138]]\n",
            "98658\n",
            "['0']\n",
            "98658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uL1FAaxCxMm",
        "colab_type": "text"
      },
      "source": [
        "### Remove redundant data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4J19cJ1_k_8",
        "colab_type": "code",
        "outputId": "40a58e72-895c-4242-8188-231369deeadc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "#239637\n",
        "#269977\n",
        "#166449\n",
        "\n",
        "def remove_useless_inputs(inputList, outputList):\n",
        "  resultInput = []\n",
        "  resultOutput = []\n",
        "  for i in range (0, len(inputList)):\n",
        "    nancount = 0\n",
        "    for val in range(0, len(inputList[i])):\n",
        "      if str(inputList[i:i+1][0][val]) == 'nan': \n",
        "        nancount += 1\n",
        "#     if nancount < len(inputList[i:i+1][0]): \n",
        "    if nancount < 1:\n",
        "      resultInput.append(inputList[i])\n",
        "      resultOutput.append(outputList[i])\n",
        "      \n",
        "  return resultInput, resultOutput\n",
        "\n",
        "newtrainInput, newtrainTarget = remove_useless_inputs(trainInput, trainTarget)\n",
        "newvalInput, newvalTarget = remove_useless_inputs(valInput, valTarget)\n",
        "newtestInput, newtestTarget = remove_useless_inputs(testInput, testTarget)\n",
        "newtestInput, newrawtestTarget = remove_useless_inputs(testInput, rawtestTarget)\n",
        "\n",
        "\n",
        "print(newtrainInput[0:1])\n",
        "print(len(newtrainInput))\n",
        "print(newtrainTarget[0:1])\n",
        "print(len(newtrainTarget))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.3287671232876711, 0.0, 0.0034439322249904397, 0.0, 0.27587890625, 0.024924571101988854, 0.0013178703215603604, 0.023927191685372606, 0.0, 0.16577420722121472, 0.15657919955906302, 0.07080194831886986, 0.06567425221342738, 0.06785172510001797, 0.01701016959638503, 0.022328109127080567, 0.02119637478718763, 7.721563054542674e-05, 0.0011800881756525248, 0.007578283773109033]]\n",
            "166449\n",
            "['0']\n",
            "166449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfihFidpCu6B",
        "colab_type": "code",
        "outputId": "c055a78f-71e3-4da2-c5a4-d94943ea05a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "# 239635\n",
        "# 253107\n",
        "# 166448\n",
        "\n",
        "def remove_useless_outputs(inputList, outputList):\n",
        "  resultInput = []\n",
        "  resultOutput = []\n",
        "  for i in range (0, len(outputList)):\n",
        "    if str(outputList[i:i+1][0]).lower() != 'nan': \n",
        "      resultInput.append(inputList[i])\n",
        "      resultOutput.append(outputList[i])\n",
        "   \n",
        "  if isinstance(resultOutput[0:1][0], str):\n",
        "    for x in range (0, len(resultOutput)):\n",
        "      resultOutput[x:x+1] = list(map(int, resultOutput[x:x+1][0]))\n",
        "  print(type(resultOutput[0:1][0]))\n",
        "\n",
        "  print(type(resultOutput[0:1][0]))\n",
        "  return resultInput, resultOutput\n",
        "\n",
        "trainInput, trainTarget = remove_useless_outputs(newtrainInput, newtrainTarget)\n",
        "valInput, valTarget = remove_useless_outputs(newvalInput, newvalTarget)\n",
        "testInput, testTarget = remove_useless_inputs(newtestInput, newtestTarget)\n",
        "testInput, rawtestTarget = remove_useless_inputs(newtestInput, newrawtestTarget)\n",
        "\n",
        "\n",
        "print(trainInput[0:1])\n",
        "print(len(trainInput))\n",
        "print(trainTarget[0:1])\n",
        "print(len(trainTarget))\n",
        "print(type(trainTarget[0:1]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'int'>\n",
            "<class 'int'>\n",
            "<class 'int'>\n",
            "<class 'int'>\n",
            "[[0.3287671232876711, 0.0, 0.0034439322249904397, 0.0, 0.27587890625, 0.024924571101988854, 0.0013178703215603604, 0.023927191685372606, 0.0, 0.16577420722121472, 0.15657919955906302, 0.07080194831886986, 0.06567425221342738, 0.06785172510001797, 0.01701016959638503, 0.022328109127080567, 0.02119637478718763, 7.721563054542674e-05, 0.0011800881756525248, 0.007578283773109033]]\n",
            "166448\n",
            "[0]\n",
            "166448\n",
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mUBGafrC5PO",
        "colab_type": "text"
      },
      "source": [
        "### Reshaping data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PHQ90cpu0t1",
        "colab_type": "code",
        "outputId": "3534ad5b-fb70-4664-da5e-c92004f887f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "# Conversion to numpy array for improved memory, performance and functionality\n",
        "trainInput, trainTarget = np.array(trainInput), np.array(trainTarget)\n",
        "valInput, valTarget = np.array(valInput), np.array(valTarget)\n",
        "testInput, testTarget = np.array(testInput), np.array(testTarget)\n",
        "\n",
        "print(trainInput[0:1])\n",
        "\n",
        "trainInput = np.reshape(trainInput, (trainInput.shape[0], trainInput.shape[1], 1))\n",
        "valInput = np.reshape(valInput, (valInput.shape[0], valInput.shape[1], 1))\n",
        "testInput = np.reshape(testInput, (testInput.shape[0], testInput.shape[1], 1))\n",
        "\n",
        "print(trainInput[0:1])\n",
        "print(trainInput.shape[0])\n",
        "print(trainInput.shape[1])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.28767123e-01 0.00000000e+00 3.44393222e-03 0.00000000e+00\n",
            "  2.75878906e-01 2.49245711e-02 1.31787032e-03 2.39271917e-02\n",
            "  0.00000000e+00 1.65774207e-01 1.56579200e-01 7.08019483e-02\n",
            "  6.56742522e-02 6.78517251e-02 1.70101696e-02 2.23281091e-02\n",
            "  2.11963748e-02 7.72156305e-05 1.18008818e-03 7.57828377e-03]]\n",
            "[[[3.28767123e-01]\n",
            "  [0.00000000e+00]\n",
            "  [3.44393222e-03]\n",
            "  [0.00000000e+00]\n",
            "  [2.75878906e-01]\n",
            "  [2.49245711e-02]\n",
            "  [1.31787032e-03]\n",
            "  [2.39271917e-02]\n",
            "  [0.00000000e+00]\n",
            "  [1.65774207e-01]\n",
            "  [1.56579200e-01]\n",
            "  [7.08019483e-02]\n",
            "  [6.56742522e-02]\n",
            "  [6.78517251e-02]\n",
            "  [1.70101696e-02]\n",
            "  [2.23281091e-02]\n",
            "  [2.11963748e-02]\n",
            "  [7.72156305e-05]\n",
            "  [1.18008818e-03]\n",
            "  [7.57828377e-03]]]\n",
            "166448\n",
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7--EOzAFCB1n",
        "colab_type": "code",
        "outputId": "9aba7e79-1002-4b19-f261-9589f7a5ccf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "print(trainInTarget[0:1])\n",
        "print(trainInTarget.shape[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0.00000000e+00]\n",
            "  [3.44393222e-03]\n",
            "  [0.00000000e+00]\n",
            "  [2.75878906e-01]\n",
            "  [2.49245711e-02]\n",
            "  [1.31787032e-03]\n",
            "  [2.39271917e-02]\n",
            "  [0.00000000e+00]\n",
            "  [1.65774207e-01]\n",
            "  [1.56579200e-01]\n",
            "  [7.08019483e-02]\n",
            "  [6.56742522e-02]\n",
            "  [6.78517251e-02]\n",
            "  [1.70101696e-02]\n",
            "  [2.23281091e-02]\n",
            "  [2.11963748e-02]\n",
            "  [7.72156305e-05]\n",
            "  [1.18008818e-03]\n",
            "  [7.57828377e-03]\n",
            "  [3.28767123e-01]]]\n",
            "166448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB3brZVQZFM7",
        "colab_type": "text"
      },
      "source": [
        "# Network Implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5CxNAYlLG_S",
        "colab_type": "text"
      },
      "source": [
        "## Core Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOVq6YexKjxU",
        "colab_type": "text"
      },
      "source": [
        "### Single Output LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlqU_UHBkfJz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dim = trainInput.shape[1]\n",
        "timesteps = trainInput.shape[0]\n",
        "\n",
        "\n",
        "# Sample Code\n",
        "# model parameters:\n",
        "\n",
        "def create_model(train_X, train_Y, data_dim):\n",
        "  lstm_units = 1024\n",
        "  \n",
        "#   print('Build baseline binary model...')\n",
        "#   model = Sequential()\n",
        "#   model.add(Masking(mask_value=0., input_shape=(data_dim, 1)))\n",
        "#   model.add(LSTM(lstm_units))\n",
        "#   model.add(Dense(1, activation='sigmoid'))\n",
        "#   model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  \n",
        "    \n",
        "  print('Build stacked binary model')\n",
        "  lstm_units = int(lstm_units/4)\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Masking(mask_value=0., input_shape=(data_dim, 1)))\n",
        "  model.add(LSTM(lstm_units, return_sequences=True))\n",
        "  model.add(Dropout(rate=0.2))\n",
        "  model.add(LSTM(lstm_units, return_sequences=True))\n",
        "  model.add(Dropout(rate=0.2))\n",
        "  model.add(LSTM(lstm_units, return_sequences=True))\n",
        "  model.add(Dropout(rate=0.2))\n",
        "  model.add(LSTM(lstm_units))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "  return(model)\n",
        "\n",
        "baseline_model = create_model(trainInput, trainTarget, data_dim)\n",
        "print(baseline_model.summary())\n",
        "SVG(model_to_dot(baseline_model, show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXmP9FbSJ6D0",
        "colab_type": "code",
        "outputId": "94f3d7a1-0786-4c6f-ccf8-72b529315b06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "source": [
        "history = baseline_model.fit(trainInput, trainTarget, epochs = 30, batch_size = 1024, verbose = 1)\n",
        "baseline_model.save('baseline.h5') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "166448/166448 [==============================] - 990s 6ms/step - loss: 0.5107 - acc: 0.7444\n",
            "Epoch 2/30\n",
            " 93184/166448 [===============>..............] - ETA: 7:15 - loss: 0.5094 - acc: 0.7450"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-cac413baf96b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbaseline_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6lAccHrKrx3",
        "colab_type": "text"
      },
      "source": [
        "### Multi output LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbhiWb-0NDdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class fypNet: \n",
        "  @staticmethod\n",
        "  def build_input_predictor(inputs, data_dim, lstm_units):\n",
        "    lstm_units = int(lstm_units/8)\n",
        "\n",
        "    inPred = Masking(mask_value=-1., input_shape = (data_dim, 1))(inputs)\n",
        "    \n",
        "    inPred = LSTM(lstm_units, return_sequences=True)(inputs)\n",
        "    inPred = Dropout(rate=0.2)(inPred)\n",
        "    inPred = LSTM(lstm_units, return_sequences=True)(inPred)\n",
        "    inPred = Dropout(rate=0.2)(inPred)\n",
        "    inPred = LSTM(lstm_units, return_sequences=True)(inPred)\n",
        "    inPred = Dropout(rate=0.2)(inPred)\n",
        "    inPred = LSTM(lstm_units)(inPred)    \n",
        "    inPred = Dense(20)(inPred)\n",
        "    \n",
        "    result = Activation('softmax', name= 'inPred_result')(inPred)\n",
        "    \n",
        "    return result\n",
        "    \n",
        "  @staticmethod\n",
        "  def build_output_predictor(inputs, data_dim, lstm_units): \n",
        "    lstm_units = int(lstm_units/4)\n",
        "    \n",
        "    outPred = LSTM(lstm_units, return_sequences=True)(inputs)\n",
        "    outPred = Dropout(rate=0.2)(outPred)\n",
        "    outPred = LSTM(lstm_units, return_sequences=True)(outPred)\n",
        "    outPred = Dropout(rate=0.2)(outPred)\n",
        "    outPred = LSTM(lstm_units, return_sequences=True)(outPred)\n",
        "    outPred = Dropout(rate=0.2)(outPred)\n",
        "    outPred = LSTM(lstm_units)(outPred)    \n",
        "    outPred = Dense(1)(outPred)\n",
        "    result = Activation('sigmoid', name= 'outPred_result')(outPred)\n",
        "\n",
        "    return result\n",
        "  \n",
        "  @staticmethod\n",
        "  def build(data_dim, lstm_units):\n",
        "         \n",
        "    input_shape = (data_dim, 1)\n",
        "    inputs = Input(shape = input_shape)\n",
        "   \n",
        "    inputBranch = fypNet.build_input_predictor(inputs, data_dim, lstm_units)\n",
        "    outputBranch = fypNet.build_output_predictor(inputs, data_dim, lstm_units)\n",
        "    \n",
        "    model = Model(inputs= inputs, outputs= [inputBranch, outputBranch])\n",
        "    \n",
        "    return model\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW6yVBGPUrmk",
        "colab_type": "code",
        "outputId": "8857432b-b667-4c3d-973e-ad0c8184068b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_dim = trainInput.shape[1]\n",
        "timesteps = trainInput.shape[0]\n",
        "lstm_units = 1024\n",
        "num_epochs = 30\n",
        "# initial_lr = 1e-3\n",
        "batch_sizes = 1024\n",
        "\n",
        "# initialize our fypNet multi-output network\n",
        "model = fypNet.build(data_dim, lstm_units)\n",
        " \n",
        "losses = {'inPred_result': 'mean_squared_error','outPred_result': 'binary_crossentropy'}\n",
        " \n",
        "# initialize the optimizer and compile the model\n",
        "\n",
        "print('Compiling model...')\n",
        "# opt = Adam(lr=initial_lr, decay=initial_lr/epochs)\n",
        "model.compile(optimizer='adam', loss=losses, metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiling model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiNO04Z3i1cz",
        "colab_type": "code",
        "outputId": "c4f32753-a70c-4480-9257-48f99138c3d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1872
        }
      },
      "source": [
        "# inPred = trainInput.shift(-1)\n",
        "trainInTarget = np.roll(trainInput, -1)\n",
        "trainValTarget = np.roll(valInput, -1)\n",
        "\n",
        "# print(inPred.head())\n",
        "print(model.summary())\n",
        "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 20, 1)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_33 (LSTM)                  (None, 20, 128)      66560       input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_37 (LSTM)                  (None, 20, 256)      264192      input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 20, 128)      0           lstm_33[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_28 (Dropout)            (None, 20, 256)      0           lstm_37[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_34 (LSTM)                  (None, 20, 128)      131584      dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lstm_38 (LSTM)                  (None, 20, 256)      525312      dropout_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 20, 128)      0           lstm_34[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_29 (Dropout)            (None, 20, 256)      0           lstm_38[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_35 (LSTM)                  (None, 20, 128)      131584      dropout_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lstm_39 (LSTM)                  (None, 20, 256)      525312      dropout_29[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 20, 128)      0           lstm_35[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 20, 256)      0           lstm_39[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_36 (LSTM)                  (None, 128)          131584      dropout_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lstm_40 (LSTM)                  (None, 256)          525312      dropout_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 20)           2580        lstm_36[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 1)            257         lstm_40[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "inPred_result (Activation)      (None, 20)           0           dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "outPred_result (Activation)     (None, 1)            0           dense_10[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,304,277\n",
            "Trainable params: 2,304,277\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"802pt\" viewBox=\"0.00 0.00 644.00 802.00\" width=\"644pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 798)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-798 640,-798 640,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140707241602072 -->\n<g class=\"node\" id=\"node1\">\n<title>140707241602072</title>\n<polygon fill=\"none\" points=\"174.5,-747.5 174.5,-793.5 460.5,-793.5 460.5,-747.5 174.5,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241\" y=\"-766.8\">input_5: InputLayer</text>\n<polyline fill=\"none\" points=\"307.5,-747.5 307.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"336.5\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"307.5,-770.5 365.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"336.5\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"365.5,-747.5 365.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"413\" y=\"-778.3\">(None, 20, 1)</text>\n<polyline fill=\"none\" points=\"365.5,-770.5 460.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"413\" y=\"-755.3\">(None, 20, 1)</text>\n</g>\n<!-- 140707241601624 -->\n<g class=\"node\" id=\"node2\">\n<title>140707241601624</title>\n<polygon fill=\"none\" points=\"30.5,-664.5 30.5,-710.5 308.5,-710.5 308.5,-664.5 30.5,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85.5\" y=\"-683.8\">lstm_33: LSTM</text>\n<polyline fill=\"none\" points=\"140.5,-664.5 140.5,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169.5\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"140.5,-687.5 198.5,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169.5\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"198.5,-664.5 198.5,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"253.5\" y=\"-695.3\">(None, 20, 1)</text>\n<polyline fill=\"none\" points=\"198.5,-687.5 308.5,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"253.5\" y=\"-672.3\">(None, 20, 128)</text>\n</g>\n<!-- 140707241602072&#45;&gt;140707241601624 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140707241602072-&gt;140707241601624</title>\n<path d=\"M276.2737,-747.3799C258.7064,-737.5279 238.051,-725.9442 219.6121,-715.6034\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"221.1957,-712.4787 210.7616,-710.6399 217.7716,-718.5841 221.1957,-712.4787\" stroke=\"#000000\"/>\n</g>\n<!-- 140707490511056 -->\n<g class=\"node\" id=\"node3\">\n<title>140707490511056</title>\n<polygon fill=\"none\" points=\"334.5,-664.5 334.5,-710.5 612.5,-710.5 612.5,-664.5 334.5,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"389.5\" y=\"-683.8\">lstm_37: LSTM</text>\n<polyline fill=\"none\" points=\"444.5,-664.5 444.5,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"473.5\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"444.5,-687.5 502.5,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"473.5\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"502.5,-664.5 502.5,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"557.5\" y=\"-695.3\">(None, 20, 1)</text>\n<polyline fill=\"none\" points=\"502.5,-687.5 612.5,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"557.5\" y=\"-672.3\">(None, 20, 256)</text>\n</g>\n<!-- 140707241602072&#45;&gt;140707490511056 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140707241602072-&gt;140707490511056</title>\n<path d=\"M360.9547,-747.3799C379.5558,-737.4832 401.4415,-725.8388 420.944,-715.4625\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"422.8238,-718.427 430.008,-710.6399 419.5358,-712.2472 422.8238,-718.427\" stroke=\"#000000\"/>\n</g>\n<!-- 140707507339216 -->\n<g class=\"node\" id=\"node4\">\n<title>140707507339216</title>\n<polygon fill=\"none\" points=\"0,-581.5 0,-627.5 309,-627.5 309,-581.5 0,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"70.5\" y=\"-600.8\">dropout_25: Dropout</text>\n<polyline fill=\"none\" points=\"141,-581.5 141,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"141,-604.5 199,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"199,-581.5 199,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"254\" y=\"-612.3\">(None, 20, 128)</text>\n<polyline fill=\"none\" points=\"199,-604.5 309,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"254\" y=\"-589.3\">(None, 20, 128)</text>\n</g>\n<!-- 140707241601624&#45;&gt;140707507339216 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140707241601624-&gt;140707507339216</title>\n<path d=\"M165.3217,-664.3799C163.8388,-656.1745 162.1388,-646.7679 160.5323,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"163.9307,-637.0021 158.708,-627.784 157.0422,-638.2471 163.9307,-637.0021\" stroke=\"#000000\"/>\n</g>\n<!-- 140707488450152 -->\n<g class=\"node\" id=\"node5\">\n<title>140707488450152</title>\n<polygon fill=\"none\" points=\"327,-581.5 327,-627.5 636,-627.5 636,-581.5 327,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397.5\" y=\"-600.8\">dropout_28: Dropout</text>\n<polyline fill=\"none\" points=\"468,-581.5 468,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"497\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"468,-604.5 526,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"497\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"526,-581.5 526,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"581\" y=\"-612.3\">(None, 20, 256)</text>\n<polyline fill=\"none\" points=\"526,-604.5 636,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"581\" y=\"-589.3\">(None, 20, 256)</text>\n</g>\n<!-- 140707490511056&#45;&gt;140707488450152 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140707490511056-&gt;140707488450152</title>\n<path d=\"M475.7284,-664.3799C476.5193,-656.1745 477.426,-646.7679 478.2828,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"481.7801,-638.0737 479.2558,-627.784 474.8124,-637.4021 481.7801,-638.0737\" stroke=\"#000000\"/>\n</g>\n<!-- 140707507336920 -->\n<g class=\"node\" id=\"node6\">\n<title>140707507336920</title>\n<polygon fill=\"none\" points=\"15.5,-498.5 15.5,-544.5 293.5,-544.5 293.5,-498.5 15.5,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"70.5\" y=\"-517.8\">lstm_34: LSTM</text>\n<polyline fill=\"none\" points=\"125.5,-498.5 125.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"154.5\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"125.5,-521.5 183.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"154.5\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"183.5,-498.5 183.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-529.3\">(None, 20, 128)</text>\n<polyline fill=\"none\" points=\"183.5,-521.5 293.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-506.3\">(None, 20, 128)</text>\n</g>\n<!-- 140707507339216&#45;&gt;140707507336920 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140707507339216-&gt;140707507336920</title>\n<path d=\"M154.5,-581.3799C154.5,-573.1745 154.5,-563.7679 154.5,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"158.0001,-554.784 154.5,-544.784 151.0001,-554.784 158.0001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140707488451720 -->\n<g class=\"node\" id=\"node7\">\n<title>140707488451720</title>\n<polygon fill=\"none\" points=\"342.5,-498.5 342.5,-544.5 620.5,-544.5 620.5,-498.5 342.5,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397.5\" y=\"-517.8\">lstm_38: LSTM</text>\n<polyline fill=\"none\" points=\"452.5,-498.5 452.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"481.5\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"452.5,-521.5 510.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"481.5\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"510.5,-498.5 510.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"565.5\" y=\"-529.3\">(None, 20, 256)</text>\n<polyline fill=\"none\" points=\"510.5,-521.5 620.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"565.5\" y=\"-506.3\">(None, 20, 256)</text>\n</g>\n<!-- 140707488450152&#45;&gt;140707488451720 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140707488450152-&gt;140707488451720</title>\n<path d=\"M481.5,-581.3799C481.5,-573.1745 481.5,-563.7679 481.5,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"485.0001,-554.784 481.5,-544.784 478.0001,-554.784 485.0001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140707500627112 -->\n<g class=\"node\" id=\"node8\">\n<title>140707500627112</title>\n<polygon fill=\"none\" points=\"0,-415.5 0,-461.5 309,-461.5 309,-415.5 0,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"70.5\" y=\"-434.8\">dropout_26: Dropout</text>\n<polyline fill=\"none\" points=\"141,-415.5 141,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"141,-438.5 199,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"199,-415.5 199,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"254\" y=\"-446.3\">(None, 20, 128)</text>\n<polyline fill=\"none\" points=\"199,-438.5 309,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"254\" y=\"-423.3\">(None, 20, 128)</text>\n</g>\n<!-- 140707507336920&#45;&gt;140707500627112 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140707507336920-&gt;140707500627112</title>\n<path d=\"M154.5,-498.3799C154.5,-490.1745 154.5,-480.7679 154.5,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"158.0001,-471.784 154.5,-461.784 151.0001,-471.784 158.0001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140707487028784 -->\n<g class=\"node\" id=\"node9\">\n<title>140707487028784</title>\n<polygon fill=\"none\" points=\"327,-415.5 327,-461.5 636,-461.5 636,-415.5 327,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397.5\" y=\"-434.8\">dropout_29: Dropout</text>\n<polyline fill=\"none\" points=\"468,-415.5 468,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"497\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"468,-438.5 526,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"497\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"526,-415.5 526,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"581\" y=\"-446.3\">(None, 20, 256)</text>\n<polyline fill=\"none\" points=\"526,-438.5 636,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"581\" y=\"-423.3\">(None, 20, 256)</text>\n</g>\n<!-- 140707488451720&#45;&gt;140707487028784 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140707488451720-&gt;140707487028784</title>\n<path d=\"M481.5,-498.3799C481.5,-490.1745 481.5,-480.7679 481.5,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"485.0001,-471.784 481.5,-461.784 478.0001,-471.784 485.0001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140707497241064 -->\n<g class=\"node\" id=\"node10\">\n<title>140707497241064</title>\n<polygon fill=\"none\" points=\"15.5,-332.5 15.5,-378.5 293.5,-378.5 293.5,-332.5 15.5,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"70.5\" y=\"-351.8\">lstm_35: LSTM</text>\n<polyline fill=\"none\" points=\"125.5,-332.5 125.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"154.5\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"125.5,-355.5 183.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"154.5\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"183.5,-332.5 183.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-363.3\">(None, 20, 128)</text>\n<polyline fill=\"none\" points=\"183.5,-355.5 293.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-340.3\">(None, 20, 128)</text>\n</g>\n<!-- 140707500627112&#45;&gt;140707497241064 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140707500627112-&gt;140707497241064</title>\n<path d=\"M154.5,-415.3799C154.5,-407.1745 154.5,-397.7679 154.5,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"158.0001,-388.784 154.5,-378.784 151.0001,-388.784 158.0001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140707485157360 -->\n<g class=\"node\" id=\"node11\">\n<title>140707485157360</title>\n<polygon fill=\"none\" points=\"342.5,-332.5 342.5,-378.5 620.5,-378.5 620.5,-332.5 342.5,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397.5\" y=\"-351.8\">lstm_39: LSTM</text>\n<polyline fill=\"none\" points=\"452.5,-332.5 452.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"481.5\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"452.5,-355.5 510.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"481.5\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"510.5,-332.5 510.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"565.5\" y=\"-363.3\">(None, 20, 256)</text>\n<polyline fill=\"none\" points=\"510.5,-355.5 620.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"565.5\" y=\"-340.3\">(None, 20, 256)</text>\n</g>\n<!-- 140707487028784&#45;&gt;140707485157360 -->\n<g class=\"edge\" id=\"edge10\">\n<title>140707487028784-&gt;140707485157360</title>\n<path d=\"M481.5,-415.3799C481.5,-407.1745 481.5,-397.7679 481.5,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"485.0001,-388.784 481.5,-378.784 478.0001,-388.784 485.0001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140707495840232 -->\n<g class=\"node\" id=\"node12\">\n<title>140707495840232</title>\n<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 309,-295.5 309,-249.5 0,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"70.5\" y=\"-268.8\">dropout_27: Dropout</text>\n<polyline fill=\"none\" points=\"141,-249.5 141,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"141,-272.5 199,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"170\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"199,-249.5 199,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"254\" y=\"-280.3\">(None, 20, 128)</text>\n<polyline fill=\"none\" points=\"199,-272.5 309,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"254\" y=\"-257.3\">(None, 20, 128)</text>\n</g>\n<!-- 140707497241064&#45;&gt;140707495840232 -->\n<g class=\"edge\" id=\"edge11\">\n<title>140707497241064-&gt;140707495840232</title>\n<path d=\"M154.5,-332.3799C154.5,-324.1745 154.5,-314.7679 154.5,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"158.0001,-305.784 154.5,-295.784 151.0001,-305.784 158.0001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140707484580832 -->\n<g class=\"node\" id=\"node13\">\n<title>140707484580832</title>\n<polygon fill=\"none\" points=\"327,-249.5 327,-295.5 636,-295.5 636,-249.5 327,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397.5\" y=\"-268.8\">dropout_30: Dropout</text>\n<polyline fill=\"none\" points=\"468,-249.5 468,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"497\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"468,-272.5 526,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"497\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"526,-249.5 526,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"581\" y=\"-280.3\">(None, 20, 256)</text>\n<polyline fill=\"none\" points=\"526,-272.5 636,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"581\" y=\"-257.3\">(None, 20, 256)</text>\n</g>\n<!-- 140707485157360&#45;&gt;140707484580832 -->\n<g class=\"edge\" id=\"edge12\">\n<title>140707485157360-&gt;140707484580832</title>\n<path d=\"M481.5,-332.3799C481.5,-324.1745 481.5,-314.7679 481.5,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"485.0001,-305.784 481.5,-295.784 478.0001,-305.784 485.0001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140707497353288 -->\n<g class=\"node\" id=\"node14\">\n<title>140707497353288</title>\n<polygon fill=\"none\" points=\"15.5,-166.5 15.5,-212.5 293.5,-212.5 293.5,-166.5 15.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"70.5\" y=\"-185.8\">lstm_36: LSTM</text>\n<polyline fill=\"none\" points=\"125.5,-166.5 125.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"154.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"125.5,-189.5 183.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"154.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"183.5,-166.5 183.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-197.3\">(None, 20, 128)</text>\n<polyline fill=\"none\" points=\"183.5,-189.5 293.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"238.5\" y=\"-174.3\">(None, 128)</text>\n</g>\n<!-- 140707495840232&#45;&gt;140707497353288 -->\n<g class=\"edge\" id=\"edge13\">\n<title>140707495840232-&gt;140707497353288</title>\n<path d=\"M154.5,-249.3799C154.5,-241.1745 154.5,-231.7679 154.5,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"158.0001,-222.784 154.5,-212.784 151.0001,-222.784 158.0001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140707485613808 -->\n<g class=\"node\" id=\"node15\">\n<title>140707485613808</title>\n<polygon fill=\"none\" points=\"342.5,-166.5 342.5,-212.5 620.5,-212.5 620.5,-166.5 342.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"397.5\" y=\"-185.8\">lstm_40: LSTM</text>\n<polyline fill=\"none\" points=\"452.5,-166.5 452.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"481.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"452.5,-189.5 510.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"481.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"510.5,-166.5 510.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"565.5\" y=\"-197.3\">(None, 20, 256)</text>\n<polyline fill=\"none\" points=\"510.5,-189.5 620.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"565.5\" y=\"-174.3\">(None, 256)</text>\n</g>\n<!-- 140707484580832&#45;&gt;140707485613808 -->\n<g class=\"edge\" id=\"edge14\">\n<title>140707484580832-&gt;140707485613808</title>\n<path d=\"M481.5,-249.3799C481.5,-241.1745 481.5,-231.7679 481.5,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"485.0001,-222.784 481.5,-212.784 478.0001,-222.784 485.0001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140707491834736 -->\n<g class=\"node\" id=\"node16\">\n<title>140707491834736</title>\n<polygon fill=\"none\" points=\"28.5,-83.5 28.5,-129.5 280.5,-129.5 280.5,-83.5 28.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"82\" y=\"-102.8\">dense_9: Dense</text>\n<polyline fill=\"none\" points=\"135.5,-83.5 135.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"164.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"135.5,-106.5 193.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"164.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"193.5,-83.5 193.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237\" y=\"-114.3\">(None, 128)</text>\n<polyline fill=\"none\" points=\"193.5,-106.5 280.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237\" y=\"-91.3\">(None, 20)</text>\n</g>\n<!-- 140707497353288&#45;&gt;140707491834736 -->\n<g class=\"edge\" id=\"edge15\">\n<title>140707497353288-&gt;140707491834736</title>\n<path d=\"M154.5,-166.3799C154.5,-158.1745 154.5,-148.7679 154.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"158.0001,-139.784 154.5,-129.784 151.0001,-139.784 158.0001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140707477974264 -->\n<g class=\"node\" id=\"node17\">\n<title>140707477974264</title>\n<polygon fill=\"none\" points=\"352,-83.5 352,-129.5 611,-129.5 611,-83.5 352,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"409\" y=\"-102.8\">dense_10: Dense</text>\n<polyline fill=\"none\" points=\"466,-83.5 466,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"495\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"466,-106.5 524,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"495\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"524,-83.5 524,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"567.5\" y=\"-114.3\">(None, 256)</text>\n<polyline fill=\"none\" points=\"524,-106.5 611,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"567.5\" y=\"-91.3\">(None, 1)</text>\n</g>\n<!-- 140707485613808&#45;&gt;140707477974264 -->\n<g class=\"edge\" id=\"edge16\">\n<title>140707485613808-&gt;140707477974264</title>\n<path d=\"M481.5,-166.3799C481.5,-158.1745 481.5,-148.7679 481.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"485.0001,-139.784 481.5,-129.784 478.0001,-139.784 485.0001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140707490397544 -->\n<g class=\"node\" id=\"node18\">\n<title>140707490397544</title>\n<polygon fill=\"none\" points=\"6,-.5 6,-46.5 303,-46.5 303,-.5 6,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85.5\" y=\"-19.8\">inPred_result: Activation</text>\n<polyline fill=\"none\" points=\"165,-.5 165,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"165,-23.5 223,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"223,-.5 223,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263\" y=\"-31.3\">(None, 20)</text>\n<polyline fill=\"none\" points=\"223,-23.5 303,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"263\" y=\"-8.3\">(None, 20)</text>\n</g>\n<!-- 140707491834736&#45;&gt;140707490397544 -->\n<g class=\"edge\" id=\"edge17\">\n<title>140707491834736-&gt;140707490397544</title>\n<path d=\"M154.5,-83.3799C154.5,-75.1745 154.5,-65.7679 154.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"158.0001,-56.784 154.5,-46.784 151.0001,-56.784 158.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140707464072552 -->\n<g class=\"node\" id=\"node19\">\n<title>140707464072552</title>\n<polygon fill=\"none\" points=\"333,-.5 333,-46.5 630,-46.5 630,-.5 333,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"416.5\" y=\"-19.8\">outPred_result: Activation</text>\n<polyline fill=\"none\" points=\"500,-.5 500,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"529\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"500,-23.5 558,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"529\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"558,-.5 558,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"594\" y=\"-31.3\">(None, 1)</text>\n<polyline fill=\"none\" points=\"558,-23.5 630,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"594\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 140707477974264&#45;&gt;140707464072552 -->\n<g class=\"edge\" id=\"edge18\">\n<title>140707477974264-&gt;140707464072552</title>\n<path d=\"M481.5,-83.3799C481.5,-75.1745 481.5,-65.7679 481.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"485.0001,-56.784 481.5,-46.784 478.0001,-56.784 485.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYXPMKKzL1eL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "6e001711-a4e4-412b-b5c0-df4fc6c04b5d"
      },
      "source": [
        "trainInTarget = np.reshape(trainInTarget, (trainInTarget.shape[0], trainInTarget.shape[1]))\n",
        "trainValTarget = np.reshape(trainValTarget, (trainValTarget.shape[0], trainValTarget.shape[1]))\n",
        "\n",
        "history = model.fit(trainInput,{\"inPred_result\": trainInTarget, \"outPred_result\": trainTarget}, validation_data=(valInput, {\"inPred_result\": trainValTarget, \"outPred_result\": valTarget}), batch_size = batch_sizes, epochs=num_epochs, verbose=1)\n",
        "# Input prediction is the input vector shifted by 1"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 166448 samples, validate on 57083 samples\n",
            "Epoch 1/30\n",
            " 26624/166448 [===>..........................] - ETA: 14:23 - loss: 0.7466 - inPred_result_loss: 0.2381 - outPred_result_loss: 0.5085 - inPred_result_acc: 0.7421 - outPred_result_acc: 0.7456"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-c060a3d41633>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainValTarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainValTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainValTarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainValTarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"inPred_result\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainInTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"outPred_result\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainTarget\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"inPred_result\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainValTarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"outPred_result\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalTarget\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Input prediction is the input vector shifted by 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH22r2NUCJNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('multioutput.h5') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUP6joUiBdwt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4892
        },
        "outputId": "8c93c6cf-ea21-44a6-a7be-fa9071e96e88"
      },
      "source": [
        "history.history"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'inPred_result_acc': [0.14302965490437353,\n",
              "  0.21291334233948167,\n",
              "  0.3696409689455345,\n",
              "  0.44674012304715993,\n",
              "  0.5034004613652568,\n",
              "  0.5429263193309622,\n",
              "  0.5709290588279075,\n",
              "  0.5923291358892292,\n",
              "  0.6073788811836657,\n",
              "  0.6192084014455848,\n",
              "  0.6301547631121457,\n",
              "  0.6404462655175251,\n",
              "  0.649584254450286,\n",
              "  0.6565053350682741,\n",
              "  0.6669830817804077,\n",
              "  0.6738681149152704,\n",
              "  0.6805368643603187,\n",
              "  0.6859559741751753,\n",
              "  0.6940606075686284,\n",
              "  0.6992994809877204,\n",
              "  0.7044722676380293,\n",
              "  0.712066230923582,\n",
              "  0.7154186291957284,\n",
              "  0.7206454868329485,\n",
              "  0.7259504468890436,\n",
              "  0.7302881379511612,\n",
              "  0.733832788693152,\n",
              "  0.7390536383506279,\n",
              "  0.7424240602869879,\n",
              "  0.7442865039847808],\n",
              " 'inPred_result_loss': [0.25683692534829544,\n",
              "  0.24786148053069051,\n",
              "  0.24362291991825255,\n",
              "  0.24188909667834035,\n",
              "  0.24097198363933198,\n",
              "  0.24039359167855623,\n",
              "  0.23997073242048525,\n",
              "  0.2396355468063965,\n",
              "  0.2393702542058186,\n",
              "  0.23915032789470667,\n",
              "  0.2389706472823176,\n",
              "  0.23881728865946072,\n",
              "  0.23867409368134526,\n",
              "  0.2385587574947938,\n",
              "  0.23844963206868325,\n",
              "  0.23836206170007562,\n",
              "  0.23828045630797645,\n",
              "  0.23820622647214276,\n",
              "  0.23814235172437428,\n",
              "  0.2380846749944984,\n",
              "  0.23803162239731865,\n",
              "  0.23798164655689458,\n",
              "  0.2379418357363071,\n",
              "  0.23789874200068975,\n",
              "  0.2378581625362961,\n",
              "  0.23782467713616598,\n",
              "  0.23779365722719184,\n",
              "  0.23776666822197873,\n",
              "  0.23774241803386378,\n",
              "  0.23772164990033803],\n",
              " 'loss': [0.9500514191067655,\n",
              "  0.9410283954329391,\n",
              "  0.9367788290102,\n",
              "  0.9350554999463617,\n",
              "  0.9340903465992829,\n",
              "  0.9332620338111111,\n",
              "  0.9320331086141151,\n",
              "  0.9307403846920586,\n",
              "  0.9289314175218181,\n",
              "  0.9251720626732598,\n",
              "  0.9097238328495152,\n",
              "  0.8831326697842841,\n",
              "  0.8581328237559788,\n",
              "  0.84053154246321,\n",
              "  0.8287670513385651,\n",
              "  0.8187546698586202,\n",
              "  0.8119114341557536,\n",
              "  0.8041627144831872,\n",
              "  0.7972449915553244,\n",
              "  0.7950539822579805,\n",
              "  0.7886954674947196,\n",
              "  0.7832281369091765,\n",
              "  0.7772215414503314,\n",
              "  0.7764334207565226,\n",
              "  0.7711024941142609,\n",
              "  0.7652349305773978,\n",
              "  0.7633757280074988,\n",
              "  0.759432218194661,\n",
              "  0.754551361286215,\n",
              "  0.7536918167126909],\n",
              " 'outPred_result_acc': [0.5005587330864196,\n",
              "  0.5012556474094011,\n",
              "  0.5025052869364607,\n",
              "  0.50383302888526,\n",
              "  0.5042595885487047,\n",
              "  0.5095285013565866,\n",
              "  0.5184081515807045,\n",
              "  0.5266689896400211,\n",
              "  0.5399283860310287,\n",
              "  0.5511931654731551,\n",
              "  0.5836537537707236,\n",
              "  0.6206502932133061,\n",
              "  0.6498726328943574,\n",
              "  0.6684009420989764,\n",
              "  0.6803806594079771,\n",
              "  0.6905339804908512,\n",
              "  0.6944811592809766,\n",
              "  0.7016846102257823,\n",
              "  0.7074822167198348,\n",
              "  0.7096029991749719,\n",
              "  0.7138265403809254,\n",
              "  0.7189452562735056,\n",
              "  0.7250132173182333,\n",
              "  0.724532586753821,\n",
              "  0.7283475920235688,\n",
              "  0.7330157165858283,\n",
              "  0.7333641737559135,\n",
              "  0.736674517040744,\n",
              "  0.741234499606263,\n",
              "  0.7401350572695242],\n",
              " 'outPred_result_loss': [0.6932144958755436,\n",
              "  0.6931669139855186,\n",
              "  0.6931559079417378,\n",
              "  0.6931664046846558,\n",
              "  0.6931183634097217,\n",
              "  0.6928684444745137,\n",
              "  0.6920623743601697,\n",
              "  0.6911048383354327,\n",
              "  0.6895611631827872,\n",
              "  0.6860217350120328,\n",
              "  0.6707531871342332,\n",
              "  0.6443153833249756,\n",
              "  0.6194587297580751,\n",
              "  0.601972785876552,\n",
              "  0.590317417111269,\n",
              "  0.5803926092586208,\n",
              "  0.5736309798144497,\n",
              "  0.5659564879609108,\n",
              "  0.5591026379559506,\n",
              "  0.5569693085884436,\n",
              "  0.5506638454139594,\n",
              "  0.5452464873270726,\n",
              "  0.5392797044306022,\n",
              "  0.5385346771558523,\n",
              "  0.5332443322698096,\n",
              "  0.5274102511078672,\n",
              "  0.5255820700884621,\n",
              "  0.521665547130819,\n",
              "  0.516808943302485,\n",
              "  0.5159701648370859],\n",
              " 'val_inPred_result_acc': [0.10775537366003157,\n",
              "  0.22553124400508506,\n",
              "  0.2931520768167637,\n",
              "  0.3132105880978125,\n",
              "  0.3464253806028708,\n",
              "  0.34915824322653155,\n",
              "  0.37871170050275627,\n",
              "  0.39332200479532925,\n",
              "  0.3921482752831551,\n",
              "  0.4101396211585039,\n",
              "  0.4101045846261939,\n",
              "  0.40565492343607507,\n",
              "  0.4321251511177005,\n",
              "  0.4178827323227426,\n",
              "  0.43095142150398036,\n",
              "  0.43194996748089115,\n",
              "  0.4302682060438806,\n",
              "  0.45211358896357773,\n",
              "  0.4430916385811187,\n",
              "  0.46360562697248475,\n",
              "  0.47113851776477317,\n",
              "  0.47001734312624455,\n",
              "  0.4625194892729724,\n",
              "  0.465042131552484,\n",
              "  0.4708757421688565,\n",
              "  0.46796769603016336,\n",
              "  0.45582747935294404,\n",
              "  0.46430636088225324,\n",
              "  0.4699647881641052,\n",
              "  0.4544960845781877],\n",
              " 'val_inPred_result_loss': [0.24586499725594688,\n",
              "  0.23771208692215762,\n",
              "  0.23570438393062443,\n",
              "  0.2346310887873458,\n",
              "  0.23394950367764183,\n",
              "  0.23355838474921747,\n",
              "  0.23317100812096428,\n",
              "  0.2329516692760123,\n",
              "  0.2325910863668886,\n",
              "  0.2324131725268631,\n",
              "  0.23216794201908722,\n",
              "  0.23196180550375636,\n",
              "  0.23186918381526717,\n",
              "  0.231579582331798,\n",
              "  0.2314624902700665,\n",
              "  0.23131955146174532,\n",
              "  0.2310576613542087,\n",
              "  0.2309226007850858,\n",
              "  0.23073973730729883,\n",
              "  0.23062846356049033,\n",
              "  0.23049470619910747,\n",
              "  0.2302796495374696,\n",
              "  0.23020228797275968,\n",
              "  0.23010894562309997,\n",
              "  0.22996932001773643,\n",
              "  0.22989538762833103,\n",
              "  0.22980562146677566,\n",
              "  0.22976694991257882,\n",
              "  0.22970330083114177,\n",
              "  0.22959929645356994],\n",
              " 'val_loss': [0.9389854315679113,\n",
              "  0.930825656042339,\n",
              "  0.9287994684251738,\n",
              "  0.927705208186568,\n",
              "  0.9269634331385557,\n",
              "  0.925669607483714,\n",
              "  0.9235226906569899,\n",
              "  0.9199758713993397,\n",
              "  0.9163032748521553,\n",
              "  0.9001545898768111,\n",
              "  0.8675980631814759,\n",
              "  0.8478137911563727,\n",
              "  0.8444024023611164,\n",
              "  0.8403321477642737,\n",
              "  0.853729752142223,\n",
              "  0.8523539629952039,\n",
              "  0.8439127181011244,\n",
              "  0.8672124384933662,\n",
              "  0.8596676756744952,\n",
              "  0.873383143244571,\n",
              "  0.8915127032820116,\n",
              "  0.8853671775582506,\n",
              "  0.8971103682087889,\n",
              "  0.8933002390189981,\n",
              "  0.9077046615907474,\n",
              "  0.9057886661140072,\n",
              "  0.8965428220200985,\n",
              "  0.9070218603606356,\n",
              "  0.9144216865359084,\n",
              "  0.9183713853021954],\n",
              " 'val_outPred_result_acc': [0.5050540440161866,\n",
              "  0.5046686403057999,\n",
              "  0.5046686403057999,\n",
              "  0.5049839706142981,\n",
              "  0.505054044424459,\n",
              "  0.5202774909450523,\n",
              "  0.5337140655869674,\n",
              "  0.5574864673875128,\n",
              "  0.5599915914141826,\n",
              "  0.6206050841072343,\n",
              "  0.6456913616711011,\n",
              "  0.6617907257038144,\n",
              "  0.6728097683888495,\n",
              "  0.6666257902242402,\n",
              "  0.6731250989155803,\n",
              "  0.671758666821728,\n",
              "  0.6685528089745666,\n",
              "  0.6650491391892185,\n",
              "  0.6735455389186387,\n",
              "  0.6721791075421347,\n",
              "  0.6712681533374238,\n",
              "  0.6701469791964446,\n",
              "  0.6764886214492003,\n",
              "  0.6706900477916832,\n",
              "  0.6735980938906977,\n",
              "  0.6736856860711701,\n",
              "  0.6755776675138866,\n",
              "  0.6745090483846451,\n",
              "  0.6741586810462876,\n",
              "  0.6772944662485874],\n",
              " 'val_outPred_result_loss': [0.6931204371160965,\n",
              "  0.6931135670498434,\n",
              "  0.6930950866330199,\n",
              "  0.6930741170615753,\n",
              "  0.6930139287271198,\n",
              "  0.6921112236045553,\n",
              "  0.6903516838725696,\n",
              "  0.6870242041255331,\n",
              "  0.6837121862157522,\n",
              "  0.667741419556551,\n",
              "  0.6354301222997564,\n",
              "  0.6158519870572928,\n",
              "  0.6125332197461284,\n",
              "  0.608752568708314,\n",
              "  0.6222672647444211,\n",
              "  0.6210344089285029,\n",
              "  0.6128550523337098,\n",
              "  0.6362898395794421,\n",
              "  0.6289279405737993,\n",
              "  0.6427546766074189,\n",
              "  0.6610179990851098,\n",
              "  0.6550875316320605,\n",
              "  0.6669080788994851,\n",
              "  0.6631912944651334,\n",
              "  0.6777353338210552,\n",
              "  0.6758932791565586,\n",
              "  0.6667372019579993,\n",
              "  0.6772549093106891,\n",
              "  0.6847183832308549,\n",
              "  0.6887720917890224]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG_FkPfUGFGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('hi')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfJvuKXjvZhY",
        "colab_type": "text"
      },
      "source": [
        "#Results Interpretations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5f5lkhBv6Fd",
        "colab_type": "text"
      },
      "source": [
        "## Model Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YGMCoclHAxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new = load_model('multioutput.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TahaSvmBHKar",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "8d84b005-f306-4842-9538-189c9cd3ed0f"
      },
      "source": [
        "new.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 20, 1)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_33 (LSTM)                  (None, 20, 128)      66560       input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_37 (LSTM)                  (None, 20, 256)      264192      input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 20, 128)      0           lstm_33[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_28 (Dropout)            (None, 20, 256)      0           lstm_37[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_34 (LSTM)                  (None, 20, 128)      131584      dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lstm_38 (LSTM)                  (None, 20, 256)      525312      dropout_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 20, 128)      0           lstm_34[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_29 (Dropout)            (None, 20, 256)      0           lstm_38[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_35 (LSTM)                  (None, 20, 128)      131584      dropout_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lstm_39 (LSTM)                  (None, 20, 256)      525312      dropout_29[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 20, 128)      0           lstm_35[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 20, 256)      0           lstm_39[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_36 (LSTM)                  (None, 128)          131584      dropout_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lstm_40 (LSTM)                  (None, 256)          525312      dropout_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 20)           2580        lstm_36[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 1)            257         lstm_40[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "inPred_result (Activation)      (None, 20)           0           dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "outPred_result (Activation)     (None, 1)            0           dense_10[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 2,304,277\n",
            "Trainable params: 2,304,277\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDbr0MxLZWCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trained_stack = load_model('/content/drive/My Drive/thw116_FYP/saved_models/stacked_model.h5')\n",
        "                           \n",
        "stack_pred = trained_stack.predict(testInput, verbose=1)\n",
        "print(stack_pred)\n",
        "\n",
        "stack_classPred = trained_stack.predict_classes(testInput, verbose=1)\n",
        "print(stack_classPred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiyXn-lKv8z5",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NcEC7mQWIB_",
        "colab_type": "code",
        "outputId": "71f956bb-470b-4287-be99-fe85c137bf7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "def evaluation_metrics(prediction, actual):\n",
        "  TP = 0\n",
        "  TN = 0\n",
        "  FP = 0\n",
        "  FN = 0\n",
        "  for i in range (0, len(actual)):\n",
        "    if actual[i][0] == '1':\n",
        "      if prediction[i][0] == 1:\n",
        "        TP += 1\n",
        "      else:\n",
        "        FN += 1\n",
        "    if actual[i][0] == '0':\n",
        "      if prediction[i][0] == 0:\n",
        "        TN += 1\n",
        "      else: \n",
        "        FP += 1\n",
        "     \n",
        "  print(TP, TN, FP, FN)\n",
        "  return (TP+TN)/(TP+TN+FP+FN), TP/(TP+FP), TP/(TP+FN)\n",
        "\n",
        "accuracy, precision, recall = evaluation_metrics(stack_classPred, testTarget)\n",
        "\n",
        "print(accuracy, precision, recall)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16842 17744 7229 7237\n",
            "0.7050884775340455 0.6996801129990445 0.6994476514805432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_oPcglnlwW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "selected = []\n",
        "\n",
        "for i in range(len(rawtestTarget)):\n",
        "  if stack_classPred[i][0] == 1: \n",
        "    selected.append(rawtestTarget[i])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOWPN1_hwCR6",
        "colab_type": "text"
      },
      "source": [
        "## Results distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJBbaaNXnSoh",
        "colab_type": "code",
        "outputId": "bc2feb15-df7e-4544-a638-a5e207dde408",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.hist(selected,range=(-0.2,0.2), bins=200)\n",
        "plt.ylabel('Returns')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Returns')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAD8CAYAAACPWyg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzPCQJHVmeEiSOvv/SyKWIySRyoYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RldOXLPljO28",
        "colab_type": "code",
        "outputId": "e9dcb6ce-2610-4b50-b13e-5c979b78875e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1147
        }
      },
      "source": [
        "npselected = np.array(selected)\n",
        "selectreturns = np.log(npselected) \n",
        "plt.hist(selectreturns, range=(-10,0), bins=200)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in log\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/histograms.py:824: RuntimeWarning: invalid value encountered in greater_equal\n",
            "  keep = (tmp_a >= first_edge)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/histograms.py:825: RuntimeWarning: invalid value encountered in less_equal\n",
            "  keep &= (tmp_a <= last_edge)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  3.,   1.,   3.,   1.,   1.,   1.,   1.,   2.,   1.,   3.,   0.,\n",
              "          0.,   1.,   7.,   4.,   1.,   6.,   1.,   3.,   3.,   2.,   2.,\n",
              "          5.,   3.,   1.,   7.,  10.,   6.,   8.,   6.,   9.,  11.,   4.,\n",
              "          5.,   6.,  16.,   7.,   9.,   8.,  16.,   8.,   8.,   9.,  17.,\n",
              "         19.,  23.,  25.,  21.,  28.,  30.,  24.,  26.,  32.,  33.,  29.,\n",
              "         34.,  31.,  38.,  41.,  66.,  30.,  45.,  54.,  59.,  47.,  52.,\n",
              "         56.,  55.,  58.,  71.,  75.,  77.,  90.,  98.,  93.,  68.,  86.,\n",
              "        110.,  91., 102., 112., 117., 118., 122., 142., 146., 139., 165.,\n",
              "        170., 177., 176., 198., 212., 213., 246., 215., 227., 290., 289.,\n",
              "        287., 267., 295., 267., 282., 321., 304., 338., 370., 359., 342.,\n",
              "        373., 345., 360., 382., 383., 350., 355., 344., 314., 334., 337.,\n",
              "        312., 305., 294., 282., 236., 226., 210., 233., 196., 180., 169.,\n",
              "        157., 139.,  90., 106.,  87.,  98.,  82.,  67.,  63.,  48.,  43.,\n",
              "         38.,  35.,  34.,  30.,  18.,  16.,  19.,  11.,   9.,   7.,  11.,\n",
              "          7.,   3.,   6.,   1.,   4.,   3.,   4.,   2.,   3.,   1.,   1.,\n",
              "          3.,   2.,   1.,   0.,   1.,   0.,   0.,   0.,   1.,   1.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.]),\n",
              " array([-10.  ,  -9.95,  -9.9 ,  -9.85,  -9.8 ,  -9.75,  -9.7 ,  -9.65,\n",
              "         -9.6 ,  -9.55,  -9.5 ,  -9.45,  -9.4 ,  -9.35,  -9.3 ,  -9.25,\n",
              "         -9.2 ,  -9.15,  -9.1 ,  -9.05,  -9.  ,  -8.95,  -8.9 ,  -8.85,\n",
              "         -8.8 ,  -8.75,  -8.7 ,  -8.65,  -8.6 ,  -8.55,  -8.5 ,  -8.45,\n",
              "         -8.4 ,  -8.35,  -8.3 ,  -8.25,  -8.2 ,  -8.15,  -8.1 ,  -8.05,\n",
              "         -8.  ,  -7.95,  -7.9 ,  -7.85,  -7.8 ,  -7.75,  -7.7 ,  -7.65,\n",
              "         -7.6 ,  -7.55,  -7.5 ,  -7.45,  -7.4 ,  -7.35,  -7.3 ,  -7.25,\n",
              "         -7.2 ,  -7.15,  -7.1 ,  -7.05,  -7.  ,  -6.95,  -6.9 ,  -6.85,\n",
              "         -6.8 ,  -6.75,  -6.7 ,  -6.65,  -6.6 ,  -6.55,  -6.5 ,  -6.45,\n",
              "         -6.4 ,  -6.35,  -6.3 ,  -6.25,  -6.2 ,  -6.15,  -6.1 ,  -6.05,\n",
              "         -6.  ,  -5.95,  -5.9 ,  -5.85,  -5.8 ,  -5.75,  -5.7 ,  -5.65,\n",
              "         -5.6 ,  -5.55,  -5.5 ,  -5.45,  -5.4 ,  -5.35,  -5.3 ,  -5.25,\n",
              "         -5.2 ,  -5.15,  -5.1 ,  -5.05,  -5.  ,  -4.95,  -4.9 ,  -4.85,\n",
              "         -4.8 ,  -4.75,  -4.7 ,  -4.65,  -4.6 ,  -4.55,  -4.5 ,  -4.45,\n",
              "         -4.4 ,  -4.35,  -4.3 ,  -4.25,  -4.2 ,  -4.15,  -4.1 ,  -4.05,\n",
              "         -4.  ,  -3.95,  -3.9 ,  -3.85,  -3.8 ,  -3.75,  -3.7 ,  -3.65,\n",
              "         -3.6 ,  -3.55,  -3.5 ,  -3.45,  -3.4 ,  -3.35,  -3.3 ,  -3.25,\n",
              "         -3.2 ,  -3.15,  -3.1 ,  -3.05,  -3.  ,  -2.95,  -2.9 ,  -2.85,\n",
              "         -2.8 ,  -2.75,  -2.7 ,  -2.65,  -2.6 ,  -2.55,  -2.5 ,  -2.45,\n",
              "         -2.4 ,  -2.35,  -2.3 ,  -2.25,  -2.2 ,  -2.15,  -2.1 ,  -2.05,\n",
              "         -2.  ,  -1.95,  -1.9 ,  -1.85,  -1.8 ,  -1.75,  -1.7 ,  -1.65,\n",
              "         -1.6 ,  -1.55,  -1.5 ,  -1.45,  -1.4 ,  -1.35,  -1.3 ,  -1.25,\n",
              "         -1.2 ,  -1.15,  -1.1 ,  -1.05,  -1.  ,  -0.95,  -0.9 ,  -0.85,\n",
              "         -0.8 ,  -0.75,  -0.7 ,  -0.65,  -0.6 ,  -0.55,  -0.5 ,  -0.45,\n",
              "         -0.4 ,  -0.35,  -0.3 ,  -0.25,  -0.2 ,  -0.15,  -0.1 ,  -0.05,\n",
              "          0.  ]),\n",
              " <a list of 200 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl6TGGfSS1DiDXpIaZ9BLUuMMeklq3P8HQNjwUIADro0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T059hTP8wIbM",
        "colab_type": "text"
      },
      "source": [
        "## Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0bq67kHrnUF",
        "colab_type": "code",
        "outputId": "db92865b-5044-49a8-f782-fc6d8fc565de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "print(stats.describe(selected))\n",
        "plt.boxplot(selected)\n",
        "plt.tight_layout() \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DescribeResult(nobs=24071, minmax=(-0.3675407805079496, 0.2766503927383084), mean=0.007639775790836587, variance=0.0002687610447687108, skewness=1.2241130595329366, kurtosis=31.11039352347609)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuC4_NCVt6EZ",
        "colab_type": "code",
        "outputId": "df39cb4f-09c3-4617-82b8-e3a824995b3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "allreturns = returns.stack(dropna=False).reset_index(drop=True).to_frame('Returns Plot')\n",
        "listreturns = []\n",
        "for i in range (len(allreturns.values)):\n",
        "  listreturns.append(allreturns.values[i][0])\n",
        "\n",
        "cleanedreturns = [x for x in listreturns if str(x) != 'nan']\n",
        "  \n",
        "print(stats.describe(cleanedreturns))\n",
        "plt.boxplot(cleanedreturns)\n",
        "plt.tight_layout() \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DescribeResult(nobs=466938, minmax=(-0.7142857142857142, 7.098215153380195), mean=0.000389116523084825, variance=0.0005460152769445449, skewness=64.11406727112934, kurtosis=18474.17040683722)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdfWnWD_Ltfs",
        "colab_type": "text"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivAgZyBQ_y_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}